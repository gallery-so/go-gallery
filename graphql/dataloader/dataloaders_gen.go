// Code generated by github.com/mikeydub/go-gallery/cmd/dataloaders, DO NOT EDIT.

package dataloader

import (
	"context"
	"fmt"
	"time"

	"github.com/jackc/pgx/v4"
	"github.com/mikeydub/go-gallery/cmd/dataloaders/generator"

	"github.com/mikeydub/go-gallery/service/persist"

	"github.com/mikeydub/go-gallery/db/gen/coredb"
)

type autoCacheWithKey[TKey any, TResult any] interface {
	getKeyForResult(TResult) TKey
}

type autoCacheWithKeys[TKey any, TResult any] interface {
	getKeysForResult(TResult) []TKey
}

type PreFetchHook func(context.Context, string) context.Context
type PostFetchHook func(context.Context, string)

type NotFound[TKey any] struct {
	Key TKey
}

func (e NotFound[TKey]) Error() string {
	return fmt.Sprintf("result not found with key: %v", e.Key)
}

// CountAdmiresByFeedEventIDBatch batches and caches requests
type CountAdmiresByFeedEventIDBatch struct {
	generator.Dataloader[persist.DBID, int64]
}

// newCountAdmiresByFeedEventIDBatch creates a new CountAdmiresByFeedEventIDBatch with the given settings, functions, and options
func newCountAdmiresByFeedEventIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]int64, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountAdmiresByFeedEventIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]int64, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountAdmiresByFeedEventIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountAdmiresByFeedEventIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountAdmiresByFeedEventIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountAdmiresByFeedEventIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]int64, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]int64, []error) {
		results := make([]int64, len(params))
		errors := make([]error, len(params))

		b := q.CountAdmiresByFeedEventIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r int64, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountAdmiresByPostIDBatch batches and caches requests
type CountAdmiresByPostIDBatch struct {
	generator.Dataloader[persist.DBID, int64]
}

// newCountAdmiresByPostIDBatch creates a new CountAdmiresByPostIDBatch with the given settings, functions, and options
func newCountAdmiresByPostIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]int64, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountAdmiresByPostIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]int64, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountAdmiresByPostIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountAdmiresByPostIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountAdmiresByPostIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountAdmiresByPostIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]int64, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]int64, []error) {
		results := make([]int64, len(params))
		errors := make([]error, len(params))

		b := q.CountAdmiresByPostIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r int64, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountAdmiresByTokenIDBatch batches and caches requests
type CountAdmiresByTokenIDBatch struct {
	generator.Dataloader[persist.DBID, int64]
}

// newCountAdmiresByTokenIDBatch creates a new CountAdmiresByTokenIDBatch with the given settings, functions, and options
func newCountAdmiresByTokenIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]int64, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountAdmiresByTokenIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]int64, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountAdmiresByTokenIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountAdmiresByTokenIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountAdmiresByTokenIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountAdmiresByTokenIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]int64, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]int64, []error) {
		results := make([]int64, len(params))
		errors := make([]error, len(params))

		b := q.CountAdmiresByTokenIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r int64, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountCommentsByFeedEventIDBatch batches and caches requests
type CountCommentsByFeedEventIDBatch struct {
	generator.Dataloader[persist.DBID, int64]
}

// newCountCommentsByFeedEventIDBatch creates a new CountCommentsByFeedEventIDBatch with the given settings, functions, and options
func newCountCommentsByFeedEventIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]int64, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountCommentsByFeedEventIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]int64, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountCommentsByFeedEventIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountCommentsByFeedEventIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountCommentsByFeedEventIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountCommentsByFeedEventIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]int64, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]int64, []error) {
		results := make([]int64, len(params))
		errors := make([]error, len(params))

		b := q.CountCommentsByFeedEventIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r int64, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountCommentsByPostIDBatch batches and caches requests
type CountCommentsByPostIDBatch struct {
	generator.Dataloader[persist.DBID, int64]
}

// newCountCommentsByPostIDBatch creates a new CountCommentsByPostIDBatch with the given settings, functions, and options
func newCountCommentsByPostIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]int64, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountCommentsByPostIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]int64, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountCommentsByPostIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountCommentsByPostIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountCommentsByPostIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountCommentsByPostIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]int64, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]int64, []error) {
		results := make([]int64, len(params))
		errors := make([]error, len(params))

		b := q.CountCommentsByPostIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r int64, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountInteractionsByFeedEventIDBatch batches and caches requests
type CountInteractionsByFeedEventIDBatch struct {
	generator.Dataloader[coredb.CountInteractionsByFeedEventIDBatchParams, []coredb.CountInteractionsByFeedEventIDBatchRow]
}

// newCountInteractionsByFeedEventIDBatch creates a new CountInteractionsByFeedEventIDBatch with the given settings, functions, and options
func newCountInteractionsByFeedEventIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.CountInteractionsByFeedEventIDBatchParams) ([][]coredb.CountInteractionsByFeedEventIDBatchRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountInteractionsByFeedEventIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.CountInteractionsByFeedEventIDBatchParams) ([][]coredb.CountInteractionsByFeedEventIDBatchRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountInteractionsByFeedEventIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountInteractionsByFeedEventIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountInteractionsByFeedEventIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountInteractionsByFeedEventIDBatch(q *coredb.Queries) func(context.Context, []coredb.CountInteractionsByFeedEventIDBatchParams) ([][]coredb.CountInteractionsByFeedEventIDBatchRow, []error) {
	return func(ctx context.Context, params []coredb.CountInteractionsByFeedEventIDBatchParams) ([][]coredb.CountInteractionsByFeedEventIDBatchRow, []error) {
		results := make([][]coredb.CountInteractionsByFeedEventIDBatchRow, len(params))
		errors := make([]error, len(params))

		b := q.CountInteractionsByFeedEventIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.CountInteractionsByFeedEventIDBatchRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.CountInteractionsByFeedEventIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountInteractionsByPostIDBatch batches and caches requests
type CountInteractionsByPostIDBatch struct {
	generator.Dataloader[coredb.CountInteractionsByPostIDBatchParams, []coredb.CountInteractionsByPostIDBatchRow]
}

// newCountInteractionsByPostIDBatch creates a new CountInteractionsByPostIDBatch with the given settings, functions, and options
func newCountInteractionsByPostIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.CountInteractionsByPostIDBatchParams) ([][]coredb.CountInteractionsByPostIDBatchRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountInteractionsByPostIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.CountInteractionsByPostIDBatchParams) ([][]coredb.CountInteractionsByPostIDBatchRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountInteractionsByPostIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountInteractionsByPostIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountInteractionsByPostIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountInteractionsByPostIDBatch(q *coredb.Queries) func(context.Context, []coredb.CountInteractionsByPostIDBatchParams) ([][]coredb.CountInteractionsByPostIDBatchRow, []error) {
	return func(ctx context.Context, params []coredb.CountInteractionsByPostIDBatchParams) ([][]coredb.CountInteractionsByPostIDBatchRow, []error) {
		results := make([][]coredb.CountInteractionsByPostIDBatchRow, len(params))
		errors := make([]error, len(params))

		b := q.CountInteractionsByPostIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.CountInteractionsByPostIDBatchRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.CountInteractionsByPostIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// CountRepliesByCommentIDBatch batches and caches requests
type CountRepliesByCommentIDBatch struct {
	generator.Dataloader[persist.DBID, int64]
}

// newCountRepliesByCommentIDBatch creates a new CountRepliesByCommentIDBatch with the given settings, functions, and options
func newCountRepliesByCommentIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]int64, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *CountRepliesByCommentIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]int64, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "CountRepliesByCommentIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "CountRepliesByCommentIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &CountRepliesByCommentIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadCountRepliesByCommentIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]int64, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]int64, []error) {
		results := make([]int64, len(params))
		errors := make([]error, len(params))

		b := q.CountRepliesByCommentIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r int64, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetAdmireByActorIDAndFeedEventID batches and caches requests
type GetAdmireByActorIDAndFeedEventID struct {
	generator.Dataloader[coredb.GetAdmireByActorIDAndFeedEventIDParams, coredb.Admire]
}

// newGetAdmireByActorIDAndFeedEventID creates a new GetAdmireByActorIDAndFeedEventID with the given settings, functions, and options
func newGetAdmireByActorIDAndFeedEventID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetAdmireByActorIDAndFeedEventIDParams) ([]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetAdmireByActorIDAndFeedEventID {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetAdmireByActorIDAndFeedEventIDParams) ([]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetAdmireByActorIDAndFeedEventID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetAdmireByActorIDAndFeedEventID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetAdmireByActorIDAndFeedEventID{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetAdmireByActorIDAndFeedEventID(q *coredb.Queries) func(context.Context, []coredb.GetAdmireByActorIDAndFeedEventIDParams) ([]coredb.Admire, []error) {
	return func(ctx context.Context, params []coredb.GetAdmireByActorIDAndFeedEventIDParams) ([]coredb.Admire, []error) {
		results := make([]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.GetAdmireByActorIDAndFeedEventID(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetAdmireByActorIDAndFeedEventIDParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetAdmireByActorIDAndPostID batches and caches requests
type GetAdmireByActorIDAndPostID struct {
	generator.Dataloader[coredb.GetAdmireByActorIDAndPostIDParams, coredb.Admire]
}

// newGetAdmireByActorIDAndPostID creates a new GetAdmireByActorIDAndPostID with the given settings, functions, and options
func newGetAdmireByActorIDAndPostID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetAdmireByActorIDAndPostIDParams) ([]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetAdmireByActorIDAndPostID {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetAdmireByActorIDAndPostIDParams) ([]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetAdmireByActorIDAndPostID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetAdmireByActorIDAndPostID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetAdmireByActorIDAndPostID{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetAdmireByActorIDAndPostID(q *coredb.Queries) func(context.Context, []coredb.GetAdmireByActorIDAndPostIDParams) ([]coredb.Admire, []error) {
	return func(ctx context.Context, params []coredb.GetAdmireByActorIDAndPostIDParams) ([]coredb.Admire, []error) {
		results := make([]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.GetAdmireByActorIDAndPostID(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetAdmireByActorIDAndPostIDParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetAdmireByActorIDAndTokenID batches and caches requests
type GetAdmireByActorIDAndTokenID struct {
	generator.Dataloader[coredb.GetAdmireByActorIDAndTokenIDParams, coredb.Admire]
}

// newGetAdmireByActorIDAndTokenID creates a new GetAdmireByActorIDAndTokenID with the given settings, functions, and options
func newGetAdmireByActorIDAndTokenID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetAdmireByActorIDAndTokenIDParams) ([]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetAdmireByActorIDAndTokenID {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetAdmireByActorIDAndTokenIDParams) ([]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetAdmireByActorIDAndTokenID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetAdmireByActorIDAndTokenID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetAdmireByActorIDAndTokenID{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetAdmireByActorIDAndTokenID(q *coredb.Queries) func(context.Context, []coredb.GetAdmireByActorIDAndTokenIDParams) ([]coredb.Admire, []error) {
	return func(ctx context.Context, params []coredb.GetAdmireByActorIDAndTokenIDParams) ([]coredb.Admire, []error) {
		results := make([]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.GetAdmireByActorIDAndTokenID(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetAdmireByActorIDAndTokenIDParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetAdmireByAdmireIDBatch batches and caches requests
type GetAdmireByAdmireIDBatch struct {
	generator.Dataloader[persist.DBID, coredb.Admire]
}

// newGetAdmireByAdmireIDBatch creates a new GetAdmireByAdmireIDBatch with the given settings, functions, and options
func newGetAdmireByAdmireIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetAdmireByAdmireIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetAdmireByAdmireIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetAdmireByAdmireIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetAdmireByAdmireIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetAdmireByAdmireIDBatch) getKeyForResult(result coredb.Admire) persist.DBID {
	return result.ID
}

func loadGetAdmireByAdmireIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Admire, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Admire, []error) {
		results := make([]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.GetAdmireByAdmireIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetAdmiresByActorIDBatch batches and caches requests
type GetAdmiresByActorIDBatch struct {
	generator.Dataloader[persist.DBID, []coredb.Admire]
}

// newGetAdmiresByActorIDBatch creates a new GetAdmiresByActorIDBatch with the given settings, functions, and options
func newGetAdmiresByActorIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetAdmiresByActorIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetAdmiresByActorIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetAdmiresByActorIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetAdmiresByActorIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetAdmiresByActorIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Admire, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Admire, []error) {
		results := make([][]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.GetAdmiresByActorIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetChildContractsByParentIDBatchPaginate batches and caches requests
type GetChildContractsByParentIDBatchPaginate struct {
	generator.Dataloader[coredb.GetChildContractsByParentIDBatchPaginateParams, []coredb.Contract]
}

// newGetChildContractsByParentIDBatchPaginate creates a new GetChildContractsByParentIDBatchPaginate with the given settings, functions, and options
func newGetChildContractsByParentIDBatchPaginate(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetChildContractsByParentIDBatchPaginateParams) ([][]coredb.Contract, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetChildContractsByParentIDBatchPaginate {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetChildContractsByParentIDBatchPaginateParams) ([][]coredb.Contract, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetChildContractsByParentIDBatchPaginate")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetChildContractsByParentIDBatchPaginate")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetChildContractsByParentIDBatchPaginate{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetChildContractsByParentIDBatchPaginate(q *coredb.Queries) func(context.Context, []coredb.GetChildContractsByParentIDBatchPaginateParams) ([][]coredb.Contract, []error) {
	return func(ctx context.Context, params []coredb.GetChildContractsByParentIDBatchPaginateParams) ([][]coredb.Contract, []error) {
		results := make([][]coredb.Contract, len(params))
		errors := make([]error, len(params))

		b := q.GetChildContractsByParentIDBatchPaginate(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Contract, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetChildContractsByParentIDBatchPaginateParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetCollectionByIdBatch batches and caches requests
type GetCollectionByIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.Collection]
}

// newGetCollectionByIdBatch creates a new GetCollectionByIdBatch with the given settings, functions, and options
func newGetCollectionByIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Collection, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetCollectionByIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Collection, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetCollectionByIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetCollectionByIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetCollectionByIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetCollectionByIdBatch) getKeyForResult(result coredb.Collection) persist.DBID {
	return result.ID
}

func loadGetCollectionByIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Collection, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Collection, []error) {
		results := make([]coredb.Collection, len(params))
		errors := make([]error, len(params))

		b := q.GetCollectionByIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Collection, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetCollectionsByGalleryIdBatch batches and caches requests
type GetCollectionsByGalleryIdBatch struct {
	generator.Dataloader[persist.DBID, []coredb.Collection]
}

// newGetCollectionsByGalleryIdBatch creates a new GetCollectionsByGalleryIdBatch with the given settings, functions, and options
func newGetCollectionsByGalleryIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Collection, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetCollectionsByGalleryIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Collection, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetCollectionsByGalleryIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetCollectionsByGalleryIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetCollectionsByGalleryIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetCollectionsByGalleryIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Collection, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Collection, []error) {
		results := make([][]coredb.Collection, len(params))
		errors := make([]error, len(params))

		b := q.GetCollectionsByGalleryIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Collection, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetCommentByCommentIDBatch batches and caches requests
type GetCommentByCommentIDBatch struct {
	generator.Dataloader[persist.DBID, coredb.Comment]
}

// newGetCommentByCommentIDBatch creates a new GetCommentByCommentIDBatch with the given settings, functions, and options
func newGetCommentByCommentIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Comment, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetCommentByCommentIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Comment, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetCommentByCommentIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetCommentByCommentIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetCommentByCommentIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetCommentByCommentIDBatch) getKeyForResult(result coredb.Comment) persist.DBID {
	return result.ID
}

func loadGetCommentByCommentIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Comment, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Comment, []error) {
		results := make([]coredb.Comment, len(params))
		errors := make([]error, len(params))

		b := q.GetCommentByCommentIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Comment, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetContractByChainAddressBatch batches and caches requests
type GetContractByChainAddressBatch struct {
	generator.Dataloader[coredb.GetContractByChainAddressBatchParams, coredb.Contract]
}

// newGetContractByChainAddressBatch creates a new GetContractByChainAddressBatch with the given settings, functions, and options
func newGetContractByChainAddressBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetContractByChainAddressBatchParams) ([]coredb.Contract, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetContractByChainAddressBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetContractByChainAddressBatchParams) ([]coredb.Contract, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetContractByChainAddressBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetContractByChainAddressBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetContractByChainAddressBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetContractByChainAddressBatch(q *coredb.Queries) func(context.Context, []coredb.GetContractByChainAddressBatchParams) ([]coredb.Contract, []error) {
	return func(ctx context.Context, params []coredb.GetContractByChainAddressBatchParams) ([]coredb.Contract, []error) {
		results := make([]coredb.Contract, len(params))
		errors := make([]error, len(params))

		b := q.GetContractByChainAddressBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Contract, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetContractByChainAddressBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetContractsDisplayedByUserIDBatch batches and caches requests
type GetContractsDisplayedByUserIDBatch struct {
	generator.Dataloader[persist.DBID, []coredb.Contract]
}

// newGetContractsDisplayedByUserIDBatch creates a new GetContractsDisplayedByUserIDBatch with the given settings, functions, and options
func newGetContractsDisplayedByUserIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Contract, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetContractsDisplayedByUserIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Contract, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetContractsDisplayedByUserIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetContractsDisplayedByUserIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetContractsDisplayedByUserIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetContractsDisplayedByUserIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Contract, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Contract, []error) {
		results := make([][]coredb.Contract, len(params))
		errors := make([]error, len(params))

		b := q.GetContractsDisplayedByUserIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Contract, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetCreatedContractsBatchPaginate batches and caches requests
type GetCreatedContractsBatchPaginate struct {
	generator.Dataloader[coredb.GetCreatedContractsBatchPaginateParams, []coredb.Contract]
}

// newGetCreatedContractsBatchPaginate creates a new GetCreatedContractsBatchPaginate with the given settings, functions, and options
func newGetCreatedContractsBatchPaginate(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetCreatedContractsBatchPaginateParams) ([][]coredb.Contract, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetCreatedContractsBatchPaginate {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetCreatedContractsBatchPaginateParams) ([][]coredb.Contract, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetCreatedContractsBatchPaginate")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetCreatedContractsBatchPaginate")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetCreatedContractsBatchPaginate{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetCreatedContractsBatchPaginate(q *coredb.Queries) func(context.Context, []coredb.GetCreatedContractsBatchPaginateParams) ([][]coredb.Contract, []error) {
	return func(ctx context.Context, params []coredb.GetCreatedContractsBatchPaginateParams) ([][]coredb.Contract, []error) {
		results := make([][]coredb.Contract, len(params))
		errors := make([]error, len(params))

		b := q.GetCreatedContractsBatchPaginate(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Contract, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetCreatedContractsBatchPaginateParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetEventByIdBatch batches and caches requests
type GetEventByIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.FeedEvent]
}

// newGetEventByIdBatch creates a new GetEventByIdBatch with the given settings, functions, and options
func newGetEventByIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.FeedEvent, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetEventByIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.FeedEvent, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetEventByIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetEventByIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetEventByIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetEventByIdBatch) getKeyForResult(result coredb.FeedEvent) persist.DBID {
	return result.ID
}

func loadGetEventByIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.FeedEvent, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.FeedEvent, []error) {
		results := make([]coredb.FeedEvent, len(params))
		errors := make([]error, len(params))

		b := q.GetEventByIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.FeedEvent, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetFollowersByUserIdBatch batches and caches requests
type GetFollowersByUserIdBatch struct {
	generator.Dataloader[persist.DBID, []coredb.User]
}

// newGetFollowersByUserIdBatch creates a new GetFollowersByUserIdBatch with the given settings, functions, and options
func newGetFollowersByUserIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetFollowersByUserIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetFollowersByUserIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetFollowersByUserIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetFollowersByUserIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetFollowersByUserIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.User, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.User, []error) {
		results := make([][]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetFollowersByUserIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetFollowingByUserIdBatch batches and caches requests
type GetFollowingByUserIdBatch struct {
	generator.Dataloader[persist.DBID, []coredb.User]
}

// newGetFollowingByUserIdBatch creates a new GetFollowingByUserIdBatch with the given settings, functions, and options
func newGetFollowingByUserIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetFollowingByUserIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetFollowingByUserIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetFollowingByUserIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetFollowingByUserIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetFollowingByUserIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.User, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.User, []error) {
		results := make([][]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetFollowingByUserIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetGalleriesByUserIdBatch batches and caches requests
type GetGalleriesByUserIdBatch struct {
	generator.Dataloader[persist.DBID, []coredb.Gallery]
}

// newGetGalleriesByUserIdBatch creates a new GetGalleriesByUserIdBatch with the given settings, functions, and options
func newGetGalleriesByUserIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Gallery, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetGalleriesByUserIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Gallery, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetGalleriesByUserIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetGalleriesByUserIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetGalleriesByUserIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetGalleriesByUserIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Gallery, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Gallery, []error) {
		results := make([][]coredb.Gallery, len(params))
		errors := make([]error, len(params))

		b := q.GetGalleriesByUserIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Gallery, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetGalleryByCollectionIdBatch batches and caches requests
type GetGalleryByCollectionIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.Gallery]
}

// newGetGalleryByCollectionIdBatch creates a new GetGalleryByCollectionIdBatch with the given settings, functions, and options
func newGetGalleryByCollectionIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Gallery, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetGalleryByCollectionIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Gallery, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetGalleryByCollectionIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetGalleryByCollectionIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetGalleryByCollectionIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetGalleryByCollectionIdBatch) getKeyForResult(result coredb.Gallery) persist.DBID {
	return result.ID
}

func loadGetGalleryByCollectionIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Gallery, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Gallery, []error) {
		results := make([]coredb.Gallery, len(params))
		errors := make([]error, len(params))

		b := q.GetGalleryByCollectionIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Gallery, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetGalleryByIdBatch batches and caches requests
type GetGalleryByIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.Gallery]
}

// newGetGalleryByIdBatch creates a new GetGalleryByIdBatch with the given settings, functions, and options
func newGetGalleryByIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Gallery, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetGalleryByIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Gallery, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetGalleryByIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetGalleryByIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetGalleryByIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetGalleryByIdBatch) getKeyForResult(result coredb.Gallery) persist.DBID {
	return result.ID
}

func loadGetGalleryByIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Gallery, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Gallery, []error) {
		results := make([]coredb.Gallery, len(params))
		errors := make([]error, len(params))

		b := q.GetGalleryByIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Gallery, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetGalleryTokenMediasByGalleryIDBatch batches and caches requests
type GetGalleryTokenMediasByGalleryIDBatch struct {
	generator.Dataloader[persist.DBID, []coredb.TokenMedia]
}

// newGetGalleryTokenMediasByGalleryIDBatch creates a new GetGalleryTokenMediasByGalleryIDBatch with the given settings, functions, and options
func newGetGalleryTokenMediasByGalleryIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.TokenMedia, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetGalleryTokenMediasByGalleryIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.TokenMedia, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetGalleryTokenMediasByGalleryIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetGalleryTokenMediasByGalleryIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetGalleryTokenMediasByGalleryIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetGalleryTokenMediasByGalleryIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.TokenMedia, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.TokenMedia, []error) {
		results := make([][]coredb.TokenMedia, len(params))
		errors := make([]error, len(params))

		b := q.GetGalleryTokenMediasByGalleryIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.TokenMedia, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetMediaByMediaIDIgnoringStatus batches and caches requests
type GetMediaByMediaIDIgnoringStatus struct {
	generator.Dataloader[persist.DBID, coredb.TokenMedia]
}

// newGetMediaByMediaIDIgnoringStatus creates a new GetMediaByMediaIDIgnoringStatus with the given settings, functions, and options
func newGetMediaByMediaIDIgnoringStatus(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.TokenMedia, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetMediaByMediaIDIgnoringStatus {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.TokenMedia, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetMediaByMediaIDIgnoringStatus")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetMediaByMediaIDIgnoringStatus")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetMediaByMediaIDIgnoringStatus{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetMediaByMediaIDIgnoringStatus) getKeyForResult(result coredb.TokenMedia) persist.DBID {
	return result.ID
}

func loadGetMediaByMediaIDIgnoringStatus(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.TokenMedia, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.TokenMedia, []error) {
		results := make([]coredb.TokenMedia, len(params))
		errors := make([]error, len(params))

		b := q.GetMediaByMediaIDIgnoringStatus(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.TokenMedia, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetMembershipByMembershipIdBatch batches and caches requests
type GetMembershipByMembershipIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.Membership]
}

// newGetMembershipByMembershipIdBatch creates a new GetMembershipByMembershipIdBatch with the given settings, functions, and options
func newGetMembershipByMembershipIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Membership, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetMembershipByMembershipIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Membership, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetMembershipByMembershipIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetMembershipByMembershipIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetMembershipByMembershipIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetMembershipByMembershipIdBatch) getKeyForResult(result coredb.Membership) persist.DBID {
	return result.ID
}

func loadGetMembershipByMembershipIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Membership, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Membership, []error) {
		results := make([]coredb.Membership, len(params))
		errors := make([]error, len(params))

		b := q.GetMembershipByMembershipIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Membership, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetMentionsByCommentID batches and caches requests
type GetMentionsByCommentID struct {
	generator.Dataloader[persist.DBID, []coredb.Mention]
}

// newGetMentionsByCommentID creates a new GetMentionsByCommentID with the given settings, functions, and options
func newGetMentionsByCommentID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Mention, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetMentionsByCommentID {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Mention, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetMentionsByCommentID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetMentionsByCommentID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetMentionsByCommentID{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetMentionsByCommentID(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Mention, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Mention, []error) {
		results := make([][]coredb.Mention, len(params))
		errors := make([]error, len(params))

		b := q.GetMentionsByCommentID(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Mention, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetMentionsByPostID batches and caches requests
type GetMentionsByPostID struct {
	generator.Dataloader[persist.DBID, []coredb.Mention]
}

// newGetMentionsByPostID creates a new GetMentionsByPostID with the given settings, functions, and options
func newGetMentionsByPostID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Mention, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetMentionsByPostID {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Mention, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetMentionsByPostID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetMentionsByPostID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetMentionsByPostID{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetMentionsByPostID(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Mention, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Mention, []error) {
		results := make([][]coredb.Mention, len(params))
		errors := make([]error, len(params))

		b := q.GetMentionsByPostID(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Mention, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetNewTokensByFeedEventIdBatch batches and caches requests
type GetNewTokensByFeedEventIdBatch struct {
	generator.Dataloader[persist.DBID, []coredb.Token]
}

// newGetNewTokensByFeedEventIdBatch creates a new GetNewTokensByFeedEventIdBatch with the given settings, functions, and options
func newGetNewTokensByFeedEventIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetNewTokensByFeedEventIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetNewTokensByFeedEventIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetNewTokensByFeedEventIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetNewTokensByFeedEventIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetNewTokensByFeedEventIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Token, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Token, []error) {
		results := make([][]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetNewTokensByFeedEventIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetNotificationByIDBatch batches and caches requests
type GetNotificationByIDBatch struct {
	generator.Dataloader[persist.DBID, coredb.Notification]
}

// newGetNotificationByIDBatch creates a new GetNotificationByIDBatch with the given settings, functions, and options
func newGetNotificationByIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Notification, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetNotificationByIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Notification, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetNotificationByIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetNotificationByIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetNotificationByIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetNotificationByIDBatch) getKeyForResult(result coredb.Notification) persist.DBID {
	return result.ID
}

func loadGetNotificationByIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Notification, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Notification, []error) {
		results := make([]coredb.Notification, len(params))
		errors := make([]error, len(params))

		b := q.GetNotificationByIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Notification, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetOwnersByContractIdBatchPaginate batches and caches requests
type GetOwnersByContractIdBatchPaginate struct {
	generator.Dataloader[coredb.GetOwnersByContractIdBatchPaginateParams, []coredb.User]
}

// newGetOwnersByContractIdBatchPaginate creates a new GetOwnersByContractIdBatchPaginate with the given settings, functions, and options
func newGetOwnersByContractIdBatchPaginate(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetOwnersByContractIdBatchPaginateParams) ([][]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetOwnersByContractIdBatchPaginate {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetOwnersByContractIdBatchPaginateParams) ([][]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetOwnersByContractIdBatchPaginate")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetOwnersByContractIdBatchPaginate")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetOwnersByContractIdBatchPaginate{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetOwnersByContractIdBatchPaginate(q *coredb.Queries) func(context.Context, []coredb.GetOwnersByContractIdBatchPaginateParams) ([][]coredb.User, []error) {
	return func(ctx context.Context, params []coredb.GetOwnersByContractIdBatchPaginateParams) ([][]coredb.User, []error) {
		results := make([][]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetOwnersByContractIdBatchPaginate(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetOwnersByContractIdBatchPaginateParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetPostByIdBatch batches and caches requests
type GetPostByIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.Post]
}

// newGetPostByIdBatch creates a new GetPostByIdBatch with the given settings, functions, and options
func newGetPostByIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Post, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetPostByIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Post, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetPostByIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetPostByIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetPostByIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetPostByIdBatch) getKeyForResult(result coredb.Post) persist.DBID {
	return result.ID
}

func loadGetPostByIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Post, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Post, []error) {
		results := make([]coredb.Post, len(params))
		errors := make([]error, len(params))

		b := q.GetPostByIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Post, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetProfileImageByID batches and caches requests
type GetProfileImageByID struct {
	generator.Dataloader[coredb.GetProfileImageByIDParams, coredb.ProfileImage]
}

// newGetProfileImageByID creates a new GetProfileImageByID with the given settings, functions, and options
func newGetProfileImageByID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetProfileImageByIDParams) ([]coredb.ProfileImage, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetProfileImageByID {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetProfileImageByIDParams) ([]coredb.ProfileImage, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetProfileImageByID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetProfileImageByID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetProfileImageByID{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetProfileImageByID(q *coredb.Queries) func(context.Context, []coredb.GetProfileImageByIDParams) ([]coredb.ProfileImage, []error) {
	return func(ctx context.Context, params []coredb.GetProfileImageByIDParams) ([]coredb.ProfileImage, []error) {
		results := make([]coredb.ProfileImage, len(params))
		errors := make([]error, len(params))

		b := q.GetProfileImageByID(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.ProfileImage, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetProfileImageByIDParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetSharedContractsBatchPaginate batches and caches requests
type GetSharedContractsBatchPaginate struct {
	generator.Dataloader[coredb.GetSharedContractsBatchPaginateParams, []coredb.GetSharedContractsBatchPaginateRow]
}

// newGetSharedContractsBatchPaginate creates a new GetSharedContractsBatchPaginate with the given settings, functions, and options
func newGetSharedContractsBatchPaginate(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetSharedContractsBatchPaginateParams) ([][]coredb.GetSharedContractsBatchPaginateRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetSharedContractsBatchPaginate {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetSharedContractsBatchPaginateParams) ([][]coredb.GetSharedContractsBatchPaginateRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetSharedContractsBatchPaginate")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetSharedContractsBatchPaginate")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetSharedContractsBatchPaginate{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetSharedContractsBatchPaginate(q *coredb.Queries) func(context.Context, []coredb.GetSharedContractsBatchPaginateParams) ([][]coredb.GetSharedContractsBatchPaginateRow, []error) {
	return func(ctx context.Context, params []coredb.GetSharedContractsBatchPaginateParams) ([][]coredb.GetSharedContractsBatchPaginateRow, []error) {
		results := make([][]coredb.GetSharedContractsBatchPaginateRow, len(params))
		errors := make([]error, len(params))

		b := q.GetSharedContractsBatchPaginate(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.GetSharedContractsBatchPaginateRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetSharedContractsBatchPaginateParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetSharedFollowersBatchPaginate batches and caches requests
type GetSharedFollowersBatchPaginate struct {
	generator.Dataloader[coredb.GetSharedFollowersBatchPaginateParams, []coredb.GetSharedFollowersBatchPaginateRow]
}

// newGetSharedFollowersBatchPaginate creates a new GetSharedFollowersBatchPaginate with the given settings, functions, and options
func newGetSharedFollowersBatchPaginate(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetSharedFollowersBatchPaginateParams) ([][]coredb.GetSharedFollowersBatchPaginateRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetSharedFollowersBatchPaginate {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetSharedFollowersBatchPaginateParams) ([][]coredb.GetSharedFollowersBatchPaginateRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetSharedFollowersBatchPaginate")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetSharedFollowersBatchPaginate")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetSharedFollowersBatchPaginate{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetSharedFollowersBatchPaginate(q *coredb.Queries) func(context.Context, []coredb.GetSharedFollowersBatchPaginateParams) ([][]coredb.GetSharedFollowersBatchPaginateRow, []error) {
	return func(ctx context.Context, params []coredb.GetSharedFollowersBatchPaginateParams) ([][]coredb.GetSharedFollowersBatchPaginateRow, []error) {
		results := make([][]coredb.GetSharedFollowersBatchPaginateRow, len(params))
		errors := make([]error, len(params))

		b := q.GetSharedFollowersBatchPaginate(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.GetSharedFollowersBatchPaginateRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetSharedFollowersBatchPaginateParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokenByIdBatch batches and caches requests
type GetTokenByIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.Token]
}

// newGetTokenByIdBatch creates a new GetTokenByIdBatch with the given settings, functions, and options
func newGetTokenByIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokenByIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokenByIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokenByIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokenByIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetTokenByIdBatch) getKeyForResult(result coredb.Token) persist.DBID {
	return result.ID
}

func loadGetTokenByIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Token, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Token, []error) {
		results := make([]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetTokenByIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokenByIdIgnoreDisplayableBatch batches and caches requests
type GetTokenByIdIgnoreDisplayableBatch struct {
	generator.Dataloader[persist.DBID, coredb.Token]
}

// newGetTokenByIdIgnoreDisplayableBatch creates a new GetTokenByIdIgnoreDisplayableBatch with the given settings, functions, and options
func newGetTokenByIdIgnoreDisplayableBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokenByIdIgnoreDisplayableBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokenByIdIgnoreDisplayableBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokenByIdIgnoreDisplayableBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokenByIdIgnoreDisplayableBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetTokenByIdIgnoreDisplayableBatch) getKeyForResult(result coredb.Token) persist.DBID {
	return result.ID
}

func loadGetTokenByIdIgnoreDisplayableBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Token, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Token, []error) {
		results := make([]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetTokenByIdIgnoreDisplayableBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokenByUserTokenIdentifiersBatch batches and caches requests
type GetTokenByUserTokenIdentifiersBatch struct {
	generator.Dataloader[coredb.GetTokenByUserTokenIdentifiersBatchParams, coredb.Token]
}

// newGetTokenByUserTokenIdentifiersBatch creates a new GetTokenByUserTokenIdentifiersBatch with the given settings, functions, and options
func newGetTokenByUserTokenIdentifiersBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetTokenByUserTokenIdentifiersBatchParams) ([]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokenByUserTokenIdentifiersBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetTokenByUserTokenIdentifiersBatchParams) ([]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokenByUserTokenIdentifiersBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokenByUserTokenIdentifiersBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokenByUserTokenIdentifiersBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetTokenByUserTokenIdentifiersBatch(q *coredb.Queries) func(context.Context, []coredb.GetTokenByUserTokenIdentifiersBatchParams) ([]coredb.Token, []error) {
	return func(ctx context.Context, params []coredb.GetTokenByUserTokenIdentifiersBatchParams) ([]coredb.Token, []error) {
		results := make([]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetTokenByUserTokenIdentifiersBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetTokenByUserTokenIdentifiersBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokenOwnerByIDBatch batches and caches requests
type GetTokenOwnerByIDBatch struct {
	generator.Dataloader[persist.DBID, coredb.User]
}

// newGetTokenOwnerByIDBatch creates a new GetTokenOwnerByIDBatch with the given settings, functions, and options
func newGetTokenOwnerByIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokenOwnerByIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokenOwnerByIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokenOwnerByIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokenOwnerByIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetTokenOwnerByIDBatch) getKeyForResult(result coredb.User) persist.DBID {
	return result.ID
}

func loadGetTokenOwnerByIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.User, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.User, []error) {
		results := make([]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetTokenOwnerByIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokensByCollectionIdBatch batches and caches requests
type GetTokensByCollectionIdBatch struct {
	generator.Dataloader[coredb.GetTokensByCollectionIdBatchParams, []coredb.Token]
}

// newGetTokensByCollectionIdBatch creates a new GetTokensByCollectionIdBatch with the given settings, functions, and options
func newGetTokensByCollectionIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetTokensByCollectionIdBatchParams) ([][]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokensByCollectionIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetTokensByCollectionIdBatchParams) ([][]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokensByCollectionIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokensByCollectionIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokensByCollectionIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetTokensByCollectionIdBatch(q *coredb.Queries) func(context.Context, []coredb.GetTokensByCollectionIdBatchParams) ([][]coredb.Token, []error) {
	return func(ctx context.Context, params []coredb.GetTokensByCollectionIdBatchParams) ([][]coredb.Token, []error) {
		results := make([][]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetTokensByCollectionIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetTokensByCollectionIdBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokensByUserIdAndChainBatch batches and caches requests
type GetTokensByUserIdAndChainBatch struct {
	generator.Dataloader[coredb.GetTokensByUserIdAndChainBatchParams, []coredb.Token]
}

// newGetTokensByUserIdAndChainBatch creates a new GetTokensByUserIdAndChainBatch with the given settings, functions, and options
func newGetTokensByUserIdAndChainBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetTokensByUserIdAndChainBatchParams) ([][]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokensByUserIdAndChainBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetTokensByUserIdAndChainBatchParams) ([][]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokensByUserIdAndChainBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokensByUserIdAndChainBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokensByUserIdAndChainBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetTokensByUserIdAndChainBatch(q *coredb.Queries) func(context.Context, []coredb.GetTokensByUserIdAndChainBatchParams) ([][]coredb.Token, []error) {
	return func(ctx context.Context, params []coredb.GetTokensByUserIdAndChainBatchParams) ([][]coredb.Token, []error) {
		results := make([][]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetTokensByUserIdAndChainBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetTokensByUserIdAndChainBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokensByUserIdBatch batches and caches requests
type GetTokensByUserIdBatch struct {
	generator.Dataloader[coredb.GetTokensByUserIdBatchParams, []coredb.GetTokensByUserIdBatchRow]
}

// newGetTokensByUserIdBatch creates a new GetTokensByUserIdBatch with the given settings, functions, and options
func newGetTokensByUserIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetTokensByUserIdBatchParams) ([][]coredb.GetTokensByUserIdBatchRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokensByUserIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetTokensByUserIdBatchParams) ([][]coredb.GetTokensByUserIdBatchRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokensByUserIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokensByUserIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokensByUserIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetTokensByUserIdBatch(q *coredb.Queries) func(context.Context, []coredb.GetTokensByUserIdBatchParams) ([][]coredb.GetTokensByUserIdBatchRow, []error) {
	return func(ctx context.Context, params []coredb.GetTokensByUserIdBatchParams) ([][]coredb.GetTokensByUserIdBatchRow, []error) {
		results := make([][]coredb.GetTokensByUserIdBatchRow, len(params))
		errors := make([]error, len(params))

		b := q.GetTokensByUserIdBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.GetTokensByUserIdBatchRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetTokensByUserIdBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetTokensByWalletIdsBatch batches and caches requests
type GetTokensByWalletIdsBatch struct {
	generator.Dataloader[persist.DBIDList, []coredb.Token]
}

// newGetTokensByWalletIdsBatch creates a new GetTokensByWalletIdsBatch with the given settings, functions, and options
func newGetTokensByWalletIdsBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBIDList) ([][]coredb.Token, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetTokensByWalletIdsBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBIDList) ([][]coredb.Token, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetTokensByWalletIdsBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetTokensByWalletIdsBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloaderWithNonComparableKey(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetTokensByWalletIdsBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetTokensByWalletIdsBatch(q *coredb.Queries) func(context.Context, []persist.DBIDList) ([][]coredb.Token, []error) {
	return func(ctx context.Context, params []persist.DBIDList) ([][]coredb.Token, []error) {
		results := make([][]coredb.Token, len(params))
		errors := make([]error, len(params))

		b := q.GetTokensByWalletIdsBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Token, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBIDList]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetUserByAddressAndL1Batch batches and caches requests
type GetUserByAddressAndL1Batch struct {
	generator.Dataloader[coredb.GetUserByAddressAndL1BatchParams, coredb.User]
}

// newGetUserByAddressAndL1Batch creates a new GetUserByAddressAndL1Batch with the given settings, functions, and options
func newGetUserByAddressAndL1Batch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetUserByAddressAndL1BatchParams) ([]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetUserByAddressAndL1Batch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetUserByAddressAndL1BatchParams) ([]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetUserByAddressAndL1Batch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetUserByAddressAndL1Batch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetUserByAddressAndL1Batch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetUserByAddressAndL1Batch(q *coredb.Queries) func(context.Context, []coredb.GetUserByAddressAndL1BatchParams) ([]coredb.User, []error) {
	return func(ctx context.Context, params []coredb.GetUserByAddressAndL1BatchParams) ([]coredb.User, []error) {
		results := make([]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetUserByAddressAndL1Batch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetUserByAddressAndL1BatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetUserByIdBatch batches and caches requests
type GetUserByIdBatch struct {
	generator.Dataloader[persist.DBID, coredb.User]
}

// newGetUserByIdBatch creates a new GetUserByIdBatch with the given settings, functions, and options
func newGetUserByIdBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetUserByIdBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetUserByIdBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetUserByIdBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetUserByIdBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetUserByIdBatch) getKeyForResult(result coredb.User) persist.DBID {
	return result.ID
}

func loadGetUserByIdBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.User, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.User, []error) {
		results := make([]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetUserByIdBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetUserByUsernameBatch batches and caches requests
type GetUserByUsernameBatch struct {
	generator.Dataloader[string, coredb.User]
}

// newGetUserByUsernameBatch creates a new GetUserByUsernameBatch with the given settings, functions, and options
func newGetUserByUsernameBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []string) ([]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetUserByUsernameBatch {
	fetchWithHooks := func(ctx context.Context, keys []string) ([]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetUserByUsernameBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetUserByUsernameBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetUserByUsernameBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetUserByUsernameBatch(q *coredb.Queries) func(context.Context, []string) ([]coredb.User, []error) {
	return func(ctx context.Context, params []string) ([]coredb.User, []error) {
		results := make([]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetUserByUsernameBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[string]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetUserNotificationsBatch batches and caches requests
type GetUserNotificationsBatch struct {
	generator.Dataloader[coredb.GetUserNotificationsBatchParams, []coredb.Notification]
}

// newGetUserNotificationsBatch creates a new GetUserNotificationsBatch with the given settings, functions, and options
func newGetUserNotificationsBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.GetUserNotificationsBatchParams) ([][]coredb.Notification, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetUserNotificationsBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.GetUserNotificationsBatchParams) ([][]coredb.Notification, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetUserNotificationsBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetUserNotificationsBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetUserNotificationsBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetUserNotificationsBatch(q *coredb.Queries) func(context.Context, []coredb.GetUserNotificationsBatchParams) ([][]coredb.Notification, []error) {
	return func(ctx context.Context, params []coredb.GetUserNotificationsBatchParams) ([][]coredb.Notification, []error) {
		results := make([][]coredb.Notification, len(params))
		errors := make([]error, len(params))

		b := q.GetUserNotificationsBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Notification, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.GetUserNotificationsBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetUsersWithTraitBatch batches and caches requests
type GetUsersWithTraitBatch struct {
	generator.Dataloader[string, []coredb.User]
}

// newGetUsersWithTraitBatch creates a new GetUsersWithTraitBatch with the given settings, functions, and options
func newGetUsersWithTraitBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []string) ([][]coredb.User, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetUsersWithTraitBatch {
	fetchWithHooks := func(ctx context.Context, keys []string) ([][]coredb.User, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetUsersWithTraitBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetUsersWithTraitBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetUsersWithTraitBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetUsersWithTraitBatch(q *coredb.Queries) func(context.Context, []string) ([][]coredb.User, []error) {
	return func(ctx context.Context, params []string) ([][]coredb.User, []error) {
		results := make([][]coredb.User, len(params))
		errors := make([]error, len(params))

		b := q.GetUsersWithTraitBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.User, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[string]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetWalletByIDBatch batches and caches requests
type GetWalletByIDBatch struct {
	generator.Dataloader[persist.DBID, coredb.Wallet]
}

// newGetWalletByIDBatch creates a new GetWalletByIDBatch with the given settings, functions, and options
func newGetWalletByIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([]coredb.Wallet, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetWalletByIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([]coredb.Wallet, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetWalletByIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetWalletByIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetWalletByIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func (*GetWalletByIDBatch) getKeyForResult(result coredb.Wallet) persist.DBID {
	return result.ID
}

func loadGetWalletByIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([]coredb.Wallet, []error) {
	return func(ctx context.Context, params []persist.DBID) ([]coredb.Wallet, []error) {
		results := make([]coredb.Wallet, len(params))
		errors := make([]error, len(params))

		b := q.GetWalletByIDBatch(ctx, params)
		defer b.Close()

		b.QueryRow(func(i int, r coredb.Wallet, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetWalletsByUserIDBatch batches and caches requests
type GetWalletsByUserIDBatch struct {
	generator.Dataloader[persist.DBID, []coredb.Wallet]
}

// newGetWalletsByUserIDBatch creates a new GetWalletsByUserIDBatch with the given settings, functions, and options
func newGetWalletsByUserIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []persist.DBID) ([][]coredb.Wallet, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetWalletsByUserIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []persist.DBID) ([][]coredb.Wallet, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetWalletsByUserIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetWalletsByUserIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetWalletsByUserIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetWalletsByUserIDBatch(q *coredb.Queries) func(context.Context, []persist.DBID) ([][]coredb.Wallet, []error) {
	return func(ctx context.Context, params []persist.DBID) ([][]coredb.Wallet, []error) {
		results := make([][]coredb.Wallet, len(params))
		errors := make([]error, len(params))

		b := q.GetWalletsByUserIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Wallet, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[persist.DBID]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateAdmiresByFeedEventIDBatch batches and caches requests
type PaginateAdmiresByFeedEventIDBatch struct {
	generator.Dataloader[coredb.PaginateAdmiresByFeedEventIDBatchParams, []coredb.Admire]
}

// newPaginateAdmiresByFeedEventIDBatch creates a new PaginateAdmiresByFeedEventIDBatch with the given settings, functions, and options
func newPaginateAdmiresByFeedEventIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateAdmiresByFeedEventIDBatchParams) ([][]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateAdmiresByFeedEventIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateAdmiresByFeedEventIDBatchParams) ([][]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateAdmiresByFeedEventIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateAdmiresByFeedEventIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateAdmiresByFeedEventIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateAdmiresByFeedEventIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateAdmiresByFeedEventIDBatchParams) ([][]coredb.Admire, []error) {
	return func(ctx context.Context, params []coredb.PaginateAdmiresByFeedEventIDBatchParams) ([][]coredb.Admire, []error) {
		results := make([][]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.PaginateAdmiresByFeedEventIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateAdmiresByFeedEventIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateAdmiresByPostIDBatch batches and caches requests
type PaginateAdmiresByPostIDBatch struct {
	generator.Dataloader[coredb.PaginateAdmiresByPostIDBatchParams, []coredb.Admire]
}

// newPaginateAdmiresByPostIDBatch creates a new PaginateAdmiresByPostIDBatch with the given settings, functions, and options
func newPaginateAdmiresByPostIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateAdmiresByPostIDBatchParams) ([][]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateAdmiresByPostIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateAdmiresByPostIDBatchParams) ([][]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateAdmiresByPostIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateAdmiresByPostIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateAdmiresByPostIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateAdmiresByPostIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateAdmiresByPostIDBatchParams) ([][]coredb.Admire, []error) {
	return func(ctx context.Context, params []coredb.PaginateAdmiresByPostIDBatchParams) ([][]coredb.Admire, []error) {
		results := make([][]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.PaginateAdmiresByPostIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateAdmiresByPostIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateAdmiresByTokenIDBatch batches and caches requests
type PaginateAdmiresByTokenIDBatch struct {
	generator.Dataloader[coredb.PaginateAdmiresByTokenIDBatchParams, []coredb.Admire]
}

// newPaginateAdmiresByTokenIDBatch creates a new PaginateAdmiresByTokenIDBatch with the given settings, functions, and options
func newPaginateAdmiresByTokenIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateAdmiresByTokenIDBatchParams) ([][]coredb.Admire, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateAdmiresByTokenIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateAdmiresByTokenIDBatchParams) ([][]coredb.Admire, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateAdmiresByTokenIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateAdmiresByTokenIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateAdmiresByTokenIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateAdmiresByTokenIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateAdmiresByTokenIDBatchParams) ([][]coredb.Admire, []error) {
	return func(ctx context.Context, params []coredb.PaginateAdmiresByTokenIDBatchParams) ([][]coredb.Admire, []error) {
		results := make([][]coredb.Admire, len(params))
		errors := make([]error, len(params))

		b := q.PaginateAdmiresByTokenIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Admire, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateAdmiresByTokenIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateCommentsByFeedEventIDBatch batches and caches requests
type PaginateCommentsByFeedEventIDBatch struct {
	generator.Dataloader[coredb.PaginateCommentsByFeedEventIDBatchParams, []coredb.Comment]
}

// newPaginateCommentsByFeedEventIDBatch creates a new PaginateCommentsByFeedEventIDBatch with the given settings, functions, and options
func newPaginateCommentsByFeedEventIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateCommentsByFeedEventIDBatchParams) ([][]coredb.Comment, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateCommentsByFeedEventIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateCommentsByFeedEventIDBatchParams) ([][]coredb.Comment, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateCommentsByFeedEventIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateCommentsByFeedEventIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateCommentsByFeedEventIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateCommentsByFeedEventIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateCommentsByFeedEventIDBatchParams) ([][]coredb.Comment, []error) {
	return func(ctx context.Context, params []coredb.PaginateCommentsByFeedEventIDBatchParams) ([][]coredb.Comment, []error) {
		results := make([][]coredb.Comment, len(params))
		errors := make([]error, len(params))

		b := q.PaginateCommentsByFeedEventIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Comment, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateCommentsByFeedEventIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateCommentsByPostIDBatch batches and caches requests
type PaginateCommentsByPostIDBatch struct {
	generator.Dataloader[coredb.PaginateCommentsByPostIDBatchParams, []coredb.Comment]
}

// newPaginateCommentsByPostIDBatch creates a new PaginateCommentsByPostIDBatch with the given settings, functions, and options
func newPaginateCommentsByPostIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateCommentsByPostIDBatchParams) ([][]coredb.Comment, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateCommentsByPostIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateCommentsByPostIDBatchParams) ([][]coredb.Comment, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateCommentsByPostIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateCommentsByPostIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateCommentsByPostIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateCommentsByPostIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateCommentsByPostIDBatchParams) ([][]coredb.Comment, []error) {
	return func(ctx context.Context, params []coredb.PaginateCommentsByPostIDBatchParams) ([][]coredb.Comment, []error) {
		results := make([][]coredb.Comment, len(params))
		errors := make([]error, len(params))

		b := q.PaginateCommentsByPostIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Comment, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateCommentsByPostIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateInteractionsByFeedEventIDBatch batches and caches requests
type PaginateInteractionsByFeedEventIDBatch struct {
	generator.Dataloader[coredb.PaginateInteractionsByFeedEventIDBatchParams, []coredb.PaginateInteractionsByFeedEventIDBatchRow]
}

// newPaginateInteractionsByFeedEventIDBatch creates a new PaginateInteractionsByFeedEventIDBatch with the given settings, functions, and options
func newPaginateInteractionsByFeedEventIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateInteractionsByFeedEventIDBatchParams) ([][]coredb.PaginateInteractionsByFeedEventIDBatchRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateInteractionsByFeedEventIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateInteractionsByFeedEventIDBatchParams) ([][]coredb.PaginateInteractionsByFeedEventIDBatchRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateInteractionsByFeedEventIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateInteractionsByFeedEventIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateInteractionsByFeedEventIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateInteractionsByFeedEventIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateInteractionsByFeedEventIDBatchParams) ([][]coredb.PaginateInteractionsByFeedEventIDBatchRow, []error) {
	return func(ctx context.Context, params []coredb.PaginateInteractionsByFeedEventIDBatchParams) ([][]coredb.PaginateInteractionsByFeedEventIDBatchRow, []error) {
		results := make([][]coredb.PaginateInteractionsByFeedEventIDBatchRow, len(params))
		errors := make([]error, len(params))

		b := q.PaginateInteractionsByFeedEventIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.PaginateInteractionsByFeedEventIDBatchRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateInteractionsByFeedEventIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateInteractionsByPostIDBatch batches and caches requests
type PaginateInteractionsByPostIDBatch struct {
	generator.Dataloader[coredb.PaginateInteractionsByPostIDBatchParams, []coredb.PaginateInteractionsByPostIDBatchRow]
}

// newPaginateInteractionsByPostIDBatch creates a new PaginateInteractionsByPostIDBatch with the given settings, functions, and options
func newPaginateInteractionsByPostIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateInteractionsByPostIDBatchParams) ([][]coredb.PaginateInteractionsByPostIDBatchRow, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateInteractionsByPostIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateInteractionsByPostIDBatchParams) ([][]coredb.PaginateInteractionsByPostIDBatchRow, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateInteractionsByPostIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateInteractionsByPostIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateInteractionsByPostIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateInteractionsByPostIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateInteractionsByPostIDBatchParams) ([][]coredb.PaginateInteractionsByPostIDBatchRow, []error) {
	return func(ctx context.Context, params []coredb.PaginateInteractionsByPostIDBatchParams) ([][]coredb.PaginateInteractionsByPostIDBatchRow, []error) {
		results := make([][]coredb.PaginateInteractionsByPostIDBatchRow, len(params))
		errors := make([]error, len(params))

		b := q.PaginateInteractionsByPostIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.PaginateInteractionsByPostIDBatchRow, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateInteractionsByPostIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginatePostsByContractID batches and caches requests
type PaginatePostsByContractID struct {
	generator.Dataloader[coredb.PaginatePostsByContractIDParams, []coredb.Post]
}

// newPaginatePostsByContractID creates a new PaginatePostsByContractID with the given settings, functions, and options
func newPaginatePostsByContractID(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginatePostsByContractIDParams) ([][]coredb.Post, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginatePostsByContractID {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginatePostsByContractIDParams) ([][]coredb.Post, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginatePostsByContractID")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginatePostsByContractID")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginatePostsByContractID{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginatePostsByContractID(q *coredb.Queries) func(context.Context, []coredb.PaginatePostsByContractIDParams) ([][]coredb.Post, []error) {
	return func(ctx context.Context, params []coredb.PaginatePostsByContractIDParams) ([][]coredb.Post, []error) {
		results := make([][]coredb.Post, len(params))
		errors := make([]error, len(params))

		b := q.PaginatePostsByContractID(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Post, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginatePostsByContractIDParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// PaginateRepliesByCommentIDBatch batches and caches requests
type PaginateRepliesByCommentIDBatch struct {
	generator.Dataloader[coredb.PaginateRepliesByCommentIDBatchParams, []coredb.Comment]
}

// newPaginateRepliesByCommentIDBatch creates a new PaginateRepliesByCommentIDBatch with the given settings, functions, and options
func newPaginateRepliesByCommentIDBatch(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []coredb.PaginateRepliesByCommentIDBatchParams) ([][]coredb.Comment, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *PaginateRepliesByCommentIDBatch {
	fetchWithHooks := func(ctx context.Context, keys []coredb.PaginateRepliesByCommentIDBatchParams) ([][]coredb.Comment, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "PaginateRepliesByCommentIDBatch")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "PaginateRepliesByCommentIDBatch")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &PaginateRepliesByCommentIDBatch{
		Dataloader: *dataloader,
	}

	return d
}

func loadPaginateRepliesByCommentIDBatch(q *coredb.Queries) func(context.Context, []coredb.PaginateRepliesByCommentIDBatchParams) ([][]coredb.Comment, []error) {
	return func(ctx context.Context, params []coredb.PaginateRepliesByCommentIDBatchParams) ([][]coredb.Comment, []error) {
		results := make([][]coredb.Comment, len(params))
		errors := make([]error, len(params))

		b := q.PaginateRepliesByCommentIDBatch(ctx, params)
		defer b.Close()

		b.Query(func(i int, r []coredb.Comment, err error) {
			results[i], errors[i] = r, err
			if errors[i] == pgx.ErrNoRows {
				errors[i] = NotFound[coredb.PaginateRepliesByCommentIDBatchParams]{Key: params[i]}
			}
		})

		return results, errors
	}
}

// GetContractCreatorsByIds batches and caches requests
type GetContractCreatorsByIds struct {
	generator.Dataloader[string, coredb.ContractCreator]
}

// newGetContractCreatorsByIds creates a new GetContractCreatorsByIds with the given settings, functions, and options
func newGetContractCreatorsByIds(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []string) ([]coredb.ContractCreator, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetContractCreatorsByIds {
	fetchWithHooks := func(ctx context.Context, keys []string) ([]coredb.ContractCreator, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetContractCreatorsByIds")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetContractCreatorsByIds")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetContractCreatorsByIds{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetContractCreatorsByIds(q *coredb.Queries) func(context.Context, []string) ([]coredb.ContractCreator, []error) {
	return func(ctx context.Context, params []string) ([]coredb.ContractCreator, []error) {
		queryResults, err := q.GetContractCreatorsByIds(ctx, params)

		results := make([]coredb.ContractCreator, len(params))
		errors := make([]error, len(params))

		if err != nil {
			for i := range errors {
				errors[i] = err
			}

			return results, errors
		}

		hasResults := make([]bool, len(params))

		for _, result := range queryResults {
			results[result.BatchKeyIndex-1] = result.ContractCreator
			hasResults[result.BatchKeyIndex-1] = true
		}

		for i, hasResult := range hasResults {
			if !hasResult {
				errors[i] = NotFound[string]{Key: params[i]}
			}
		}

		return results, errors
	}
}

// GetContractsByIDs batches and caches requests
type GetContractsByIDs struct {
	generator.Dataloader[string, coredb.Contract]
}

// newGetContractsByIDs creates a new GetContractsByIDs with the given settings, functions, and options
func newGetContractsByIDs(
	ctx context.Context,
	maxBatchSize int,
	batchTimeout time.Duration,
	cacheResults bool,
	publishResults bool,
	fetch func(context.Context, []string) ([]coredb.Contract, []error),
	preFetchHook PreFetchHook,
	postFetchHook PostFetchHook,
) *GetContractsByIDs {
	fetchWithHooks := func(ctx context.Context, keys []string) ([]coredb.Contract, []error) {
		// Allow the preFetchHook to modify and return a new context
		if preFetchHook != nil {
			ctx = preFetchHook(ctx, "GetContractsByIDs")
		}

		results, errors := fetch(ctx, keys)

		if postFetchHook != nil {
			postFetchHook(ctx, "GetContractsByIDs")
		}

		return results, errors
	}

	dataloader := generator.NewDataloader(ctx, maxBatchSize, batchTimeout, cacheResults, publishResults, fetchWithHooks)

	d := &GetContractsByIDs{
		Dataloader: *dataloader,
	}

	return d
}

func loadGetContractsByIDs(q *coredb.Queries) func(context.Context, []string) ([]coredb.Contract, []error) {
	return func(ctx context.Context, params []string) ([]coredb.Contract, []error) {
		queryResults, err := q.GetContractsByIDs(ctx, params)

		results := make([]coredb.Contract, len(params))
		errors := make([]error, len(params))

		if err != nil {
			for i := range errors {
				errors[i] = err
			}

			return results, errors
		}

		hasResults := make([]bool, len(params))

		for _, result := range queryResults {
			results[result.BatchKeyIndex-1] = result.Contract
			hasResults[result.BatchKeyIndex-1] = true
		}

		for i, hasResult := range hasResults {
			if !hasResult {
				errors[i] = NotFound[string]{Key: params[i]}
			}
		}

		return results, errors
	}
}
