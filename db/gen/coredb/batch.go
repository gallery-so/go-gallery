// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.18.0
// source: batch.go

package coredb

import (
	"context"
	"database/sql"
	"errors"
	"time"

	"github.com/jackc/pgtype"
	"github.com/jackc/pgx/v4"
	"github.com/mikeydub/go-gallery/service/persist"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const countAdmiresByFeedEventIDBatch = `-- name: CountAdmiresByFeedEventIDBatch :batchone
SELECT count(*) FROM admires WHERE feed_event_id = $1 AND deleted = false
`

type CountAdmiresByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByFeedEventIDBatch(ctx context.Context, feedEventID []persist.DBID) *CountAdmiresByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range feedEventID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByFeedEventIDBatchBatchResults{br, len(feedEventID), false}
}

func (b *CountAdmiresByFeedEventIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countAdmiresByPostIDBatch = `-- name: CountAdmiresByPostIDBatch :batchone
SELECT count(*) FROM admires WHERE post_id = $1 AND deleted = false
`

type CountAdmiresByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByPostIDBatch(ctx context.Context, postID []persist.DBID) *CountAdmiresByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByPostIDBatchBatchResults{br, len(postID), false}
}

func (b *CountAdmiresByPostIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countCommentsByFeedEventIDBatch = `-- name: CountCommentsByFeedEventIDBatch :batchone
SELECT count(*) FROM comments WHERE feed_event_id = $1 AND deleted = false
`

type CountCommentsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountCommentsByFeedEventIDBatch(ctx context.Context, feedEventID []persist.DBID) *CountCommentsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range feedEventID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countCommentsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountCommentsByFeedEventIDBatchBatchResults{br, len(feedEventID), false}
}

func (b *CountCommentsByFeedEventIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountCommentsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countCommentsByPostIDBatch = `-- name: CountCommentsByPostIDBatch :batchone
SELECT count(*) FROM comments WHERE post_id = $1 AND deleted = false
`

type CountCommentsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountCommentsByPostIDBatch(ctx context.Context, postID []persist.DBID) *CountCommentsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countCommentsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountCommentsByPostIDBatchBatchResults{br, len(postID), false}
}

func (b *CountCommentsByPostIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountCommentsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countInteractionsByFeedEventIDBatch = `-- name: CountInteractionsByFeedEventIDBatch :batchmany
SELECT count(*), $1::int as tag FROM admires t WHERE $1 != 0 AND t.feed_event_id = $2 AND t.deleted = false
                                                        UNION
SELECT count(*), $3::int as tag FROM comments t WHERE $3 != 0 AND t.feed_event_id = $2 AND t.deleted = false
`

type CountInteractionsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CountInteractionsByFeedEventIDBatchParams struct {
	AdmireTag   int32        `json:"admire_tag"`
	FeedEventID persist.DBID `json:"feed_event_id"`
	CommentTag  int32        `json:"comment_tag"`
}

type CountInteractionsByFeedEventIDBatchRow struct {
	Count int64 `json:"count"`
	Tag   int32 `json:"tag"`
}

func (q *Queries) CountInteractionsByFeedEventIDBatch(ctx context.Context, arg []CountInteractionsByFeedEventIDBatchParams) *CountInteractionsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.FeedEventID,
			a.CommentTag,
		}
		batch.Queue(countInteractionsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountInteractionsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *CountInteractionsByFeedEventIDBatchBatchResults) Query(f func(int, []CountInteractionsByFeedEventIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []CountInteractionsByFeedEventIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i CountInteractionsByFeedEventIDBatchRow
				if err := rows.Scan(&i.Count, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *CountInteractionsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countInteractionsByPostIDBatch = `-- name: CountInteractionsByPostIDBatch :batchmany
SELECT count(*), $1::int as tag FROM admires t WHERE $1 != 0 AND t.post_id = $2 AND t.deleted = false
                                                        UNION
SELECT count(*), $3::int as tag FROM comments t WHERE $3 != 0 AND t.post_id = $2 AND t.deleted = false
`

type CountInteractionsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CountInteractionsByPostIDBatchParams struct {
	AdmireTag  int32        `json:"admire_tag"`
	PostID     persist.DBID `json:"post_id"`
	CommentTag int32        `json:"comment_tag"`
}

type CountInteractionsByPostIDBatchRow struct {
	Count int64 `json:"count"`
	Tag   int32 `json:"tag"`
}

func (q *Queries) CountInteractionsByPostIDBatch(ctx context.Context, arg []CountInteractionsByPostIDBatchParams) *CountInteractionsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.PostID,
			a.CommentTag,
		}
		batch.Queue(countInteractionsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountInteractionsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *CountInteractionsByPostIDBatchBatchResults) Query(f func(int, []CountInteractionsByPostIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []CountInteractionsByPostIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i CountInteractionsByPostIDBatchRow
				if err := rows.Scan(&i.Count, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *CountInteractionsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndFeedEventID = `-- name: GetAdmireByActorIDAndFeedEventID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id FROM admires WHERE actor_id = $1 AND feed_event_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndFeedEventIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndFeedEventIDParams struct {
	ActorID     persist.DBID `json:"actor_id"`
	FeedEventID persist.DBID `json:"feed_event_id"`
}

func (q *Queries) GetAdmireByActorIDAndFeedEventID(ctx context.Context, arg []GetAdmireByActorIDAndFeedEventIDParams) *GetAdmireByActorIDAndFeedEventIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.FeedEventID,
		}
		batch.Queue(getAdmireByActorIDAndFeedEventID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndFeedEventIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndFeedEventIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndFeedEventIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndPostID = `-- name: GetAdmireByActorIDAndPostID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id FROM admires WHERE actor_id = $1 AND post_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndPostIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndPostIDParams struct {
	ActorID persist.DBID `json:"actor_id"`
	PostID  persist.DBID `json:"post_id"`
}

func (q *Queries) GetAdmireByActorIDAndPostID(ctx context.Context, arg []GetAdmireByActorIDAndPostIDParams) *GetAdmireByActorIDAndPostIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.PostID,
		}
		batch.Queue(getAdmireByActorIDAndPostID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndPostIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndPostIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndPostIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByAdmireIDBatch = `-- name: GetAdmireByAdmireIDBatch :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id FROM admires WHERE id = $1 AND deleted = false
`

type GetAdmireByAdmireIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetAdmireByAdmireIDBatch(ctx context.Context, id []persist.DBID) *GetAdmireByAdmireIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getAdmireByAdmireIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByAdmireIDBatchBatchResults{br, len(id), false}
}

func (b *GetAdmireByAdmireIDBatchBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByAdmireIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmiresByActorIDBatch = `-- name: GetAdmiresByActorIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id FROM admires WHERE actor_id = $1 AND deleted = false ORDER BY created_at DESC
`

type GetAdmiresByActorIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetAdmiresByActorIDBatch(ctx context.Context, actorID []persist.DBID) *GetAdmiresByActorIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range actorID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getAdmiresByActorIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmiresByActorIDBatchBatchResults{br, len(actorID), false}
}

func (b *GetAdmiresByActorIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetAdmiresByActorIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getChildContractsByParentIDBatchPaginate = `-- name: GetChildContractsByParentIDBatchPaginate :batchmany
select c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id
from contracts c
where c.parent_id = $1
  and c.deleted = false
  and (c.created_at, c.id) < ($2, $3)
  and (c.created_at, c.id) > ( $4, $5)
order by case when $6::bool then (c.created_at, c.id) end asc,
        case when not $6::bool then (c.created_at, c.id) end desc
limit $7
`

type GetChildContractsByParentIDBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetChildContractsByParentIDBatchPaginateParams struct {
	ParentID      persist.DBID `json:"parent_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) GetChildContractsByParentIDBatchPaginate(ctx context.Context, arg []GetChildContractsByParentIDBatchPaginateParams) *GetChildContractsByParentIDBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ParentID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getChildContractsByParentIDBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetChildContractsByParentIDBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetChildContractsByParentIDBatchPaginateBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetChildContractsByParentIDBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCollectionByIdBatch = `-- name: GetCollectionByIdBatch :batchone
SELECT id, deleted, owner_user_id, nfts, version, last_updated, created_at, hidden, collectors_note, name, layout, token_settings, gallery_id FROM collections WHERE id = $1 AND deleted = false
`

type GetCollectionByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCollectionByIdBatch(ctx context.Context, id []persist.DBID) *GetCollectionByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCollectionByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCollectionByIdBatchBatchResults{br, len(id), false}
}

func (b *GetCollectionByIdBatchBatchResults) QueryRow(f func(int, Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Collection
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.OwnerUserID,
			&i.Nfts,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Hidden,
			&i.CollectorsNote,
			&i.Name,
			&i.Layout,
			&i.TokenSettings,
			&i.GalleryID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCollectionByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCollectionsByGalleryIdBatch = `-- name: GetCollectionsByGalleryIdBatch :batchmany
SELECT c.id, c.deleted, c.owner_user_id, c.nfts, c.version, c.last_updated, c.created_at, c.hidden, c.collectors_note, c.name, c.layout, c.token_settings, c.gallery_id FROM galleries g, unnest(g.collections)
    WITH ORDINALITY AS x(coll_id, coll_ord)
    INNER JOIN collections c ON c.id = x.coll_id
    WHERE g.id = $1 AND g.deleted = false AND c.deleted = false ORDER BY x.coll_ord
`

type GetCollectionsByGalleryIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCollectionsByGalleryIdBatch(ctx context.Context, id []persist.DBID) *GetCollectionsByGalleryIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCollectionsByGalleryIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCollectionsByGalleryIdBatchBatchResults{br, len(id), false}
}

func (b *GetCollectionsByGalleryIdBatchBatchResults) Query(f func(int, []Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Collection
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Collection
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerUserID,
					&i.Nfts,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Hidden,
					&i.CollectorsNote,
					&i.Name,
					&i.Layout,
					&i.TokenSettings,
					&i.GalleryID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCollectionsByGalleryIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommentByCommentIDBatch = `-- name: GetCommentByCommentIDBatch :batchone
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id FROM comments WHERE id = $1 AND deleted = false
`

type GetCommentByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCommentByCommentIDBatch(ctx context.Context, id []persist.DBID) *GetCommentByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCommentByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommentByCommentIDBatchBatchResults{br, len(id), false}
}

func (b *GetCommentByCommentIDBatchBatchResults) QueryRow(f func(int, Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Comment
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.ReplyTo,
			&i.Comment,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCommentByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommentsByActorIDBatch = `-- name: GetCommentsByActorIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id FROM comments WHERE actor_id = $1 AND deleted = false ORDER BY created_at DESC
`

type GetCommentsByActorIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCommentsByActorIDBatch(ctx context.Context, actorID []persist.DBID) *GetCommentsByActorIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range actorID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCommentsByActorIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommentsByActorIDBatchBatchResults{br, len(actorID), false}
}

func (b *GetCommentsByActorIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCommentsByActorIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getContractByChainAddressBatch = `-- name: GetContractByChainAddressBatch :batchone
select id, deleted, version, created_at, last_updated, name, symbol, address, creator_address, chain, profile_banner_url, profile_image_url, badge_url, description, owner_address, is_provider_marked_spam, parent_id, override_creator_user_id FROM contracts WHERE address = $1 AND chain = $2 AND deleted = false
`

type GetContractByChainAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetContractByChainAddressBatchParams struct {
	Address persist.Address `json:"address"`
	Chain   persist.Chain   `json:"chain"`
}

func (q *Queries) GetContractByChainAddressBatch(ctx context.Context, arg []GetContractByChainAddressBatchParams) *GetContractByChainAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getContractByChainAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetContractByChainAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetContractByChainAddressBatchBatchResults) QueryRow(f func(int, Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Contract
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Name,
			&i.Symbol,
			&i.Address,
			&i.CreatorAddress,
			&i.Chain,
			&i.ProfileBannerUrl,
			&i.ProfileImageUrl,
			&i.BadgeUrl,
			&i.Description,
			&i.OwnerAddress,
			&i.IsProviderMarkedSpam,
			&i.ParentID,
			&i.OverrideCreatorUserID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetContractByChainAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getContractsDisplayedByUserIDBatch = `-- name: GetContractsDisplayedByUserIDBatch :batchmany
with last_refreshed as (
  select last_updated from owned_contracts limit 1
),
displayed as (
  select contract_id
  from owned_contracts
  where owned_contracts.user_id = $1 and displayed = true
  union
  select contracts.id
  from last_refreshed, galleries, contracts, tokens
  join collections on tokens.id = any(collections.nfts) and collections.deleted = false
  where tokens.owner_user_id = $1
    and tokens.contract = contracts.id
    and collections.owner_user_id = tokens.owner_user_id
    and galleries.owner_user_id = tokens.owner_user_id
    and tokens.deleted = false
    and galleries.deleted = false
    and contracts.deleted = false
    and galleries.last_updated > last_refreshed.last_updated
    and collections.last_updated > last_refreshed.last_updated
)
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id from contracts, displayed
where contracts.id = displayed.contract_id and contracts.deleted = false
`

type GetContractsDisplayedByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetContractsDisplayedByUserIDBatch(ctx context.Context, userID []persist.DBID) *GetContractsDisplayedByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range userID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getContractsDisplayedByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetContractsDisplayedByUserIDBatchBatchResults{br, len(userID), false}
}

func (b *GetContractsDisplayedByUserIDBatchBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetContractsDisplayedByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCreatedContractsBatchPaginate = `-- name: GetCreatedContractsBatchPaginate :batchmany
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id
from contracts
    join contract_creators on contracts.id = contract_creators.contract_id and contract_creators.creator_user_id = $1
where ($2::bool or contracts.chain = any(string_to_array($3, ',')::int[]))
  and (contracts.created_at, contracts.id) < ($4, $5)
  and (contracts.created_at, contracts.id) > ( $6, $7)
order by case when $8::bool then (contracts.created_at, contracts.id) end asc,
        case when not $8::bool then (contracts.created_at, contracts.id) end desc
limit $9
`

type GetCreatedContractsBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetCreatedContractsBatchPaginateParams struct {
	UserID           persist.DBID `json:"user_id"`
	IncludeAllChains bool         `json:"include_all_chains"`
	Chains           string       `json:"chains"`
	CurBeforeTime    time.Time    `json:"cur_before_time"`
	CurBeforeID      persist.DBID `json:"cur_before_id"`
	CurAfterTime     time.Time    `json:"cur_after_time"`
	CurAfterID       persist.DBID `json:"cur_after_id"`
	PagingForward    bool         `json:"paging_forward"`
	Limit            int32        `json:"limit"`
}

func (q *Queries) GetCreatedContractsBatchPaginate(ctx context.Context, arg []GetCreatedContractsBatchPaginateParams) *GetCreatedContractsBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserID,
			a.IncludeAllChains,
			a.Chains,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getCreatedContractsBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCreatedContractsBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetCreatedContractsBatchPaginateBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCreatedContractsBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getEventByIdBatch = `-- name: GetEventByIdBatch :batchone
SELECT id, version, owner_id, action, data, event_time, event_ids, deleted, last_updated, created_at, caption, group_id FROM feed_events WHERE id = $1 AND deleted = false
`

type GetEventByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetEventByIdBatch(ctx context.Context, id []persist.DBID) *GetEventByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getEventByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetEventByIdBatchBatchResults{br, len(id), false}
}

func (b *GetEventByIdBatchBatchResults) QueryRow(f func(int, FeedEvent, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i FeedEvent
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.OwnerID,
			&i.Action,
			&i.Data,
			&i.EventTime,
			&i.EventIds,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Caption,
			&i.GroupID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetEventByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFollowersByUserIdBatch = `-- name: GetFollowersByUserIdBatch :batchmany
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id FROM follows f
    INNER JOIN users u ON f.follower = u.id
    WHERE f.followee = $1 AND f.deleted = false
    ORDER BY f.last_updated DESC
`

type GetFollowersByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetFollowersByUserIdBatch(ctx context.Context, followee []persist.DBID) *GetFollowersByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range followee {
		vals := []interface{}{
			a,
		}
		batch.Queue(getFollowersByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFollowersByUserIdBatchBatchResults{br, len(followee), false}
}

func (b *GetFollowersByUserIdBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFollowersByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFollowingByUserIdBatch = `-- name: GetFollowingByUserIdBatch :batchmany
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id FROM follows f
    INNER JOIN users u ON f.followee = u.id
    WHERE f.follower = $1 AND f.deleted = false
    ORDER BY f.last_updated DESC
`

type GetFollowingByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetFollowingByUserIdBatch(ctx context.Context, follower []persist.DBID) *GetFollowingByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range follower {
		vals := []interface{}{
			a,
		}
		batch.Queue(getFollowingByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFollowingByUserIdBatchBatchResults{br, len(follower), false}
}

func (b *GetFollowingByUserIdBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFollowingByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleriesByUserIdBatch = `-- name: GetGalleriesByUserIdBatch :batchmany
SELECT id, deleted, last_updated, created_at, version, owner_user_id, collections, name, description, hidden, position FROM galleries WHERE owner_user_id = $1 AND deleted = false order by position
`

type GetGalleriesByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleriesByUserIdBatch(ctx context.Context, ownerUserID []persist.DBID) *GetGalleriesByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range ownerUserID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleriesByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleriesByUserIdBatchBatchResults{br, len(ownerUserID), false}
}

func (b *GetGalleriesByUserIdBatchBatchResults) Query(f func(int, []Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Gallery
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Gallery
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Version,
					&i.OwnerUserID,
					&i.Collections,
					&i.Name,
					&i.Description,
					&i.Hidden,
					&i.Position,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetGalleriesByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryByCollectionIdBatch = `-- name: GetGalleryByCollectionIdBatch :batchone
SELECT g.id, g.deleted, g.last_updated, g.created_at, g.version, g.owner_user_id, g.collections, g.name, g.description, g.hidden, g.position FROM galleries g, collections c WHERE c.id = $1 AND c.deleted = false AND $1 = ANY(g.collections) AND g.deleted = false
`

type GetGalleryByCollectionIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryByCollectionIdBatch(ctx context.Context, id []persist.DBID) *GetGalleryByCollectionIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryByCollectionIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryByCollectionIdBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryByCollectionIdBatchBatchResults) QueryRow(f func(int, Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Gallery
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Version,
			&i.OwnerUserID,
			&i.Collections,
			&i.Name,
			&i.Description,
			&i.Hidden,
			&i.Position,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetGalleryByCollectionIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryByIdBatch = `-- name: GetGalleryByIdBatch :batchone
SELECT id, deleted, last_updated, created_at, version, owner_user_id, collections, name, description, hidden, position FROM galleries WHERE id = $1 AND deleted = false
`

type GetGalleryByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryByIdBatch(ctx context.Context, id []persist.DBID) *GetGalleryByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryByIdBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryByIdBatchBatchResults) QueryRow(f func(int, Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Gallery
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Version,
			&i.OwnerUserID,
			&i.Collections,
			&i.Name,
			&i.Description,
			&i.Hidden,
			&i.Position,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetGalleryByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMediaByTokenID = `-- name: GetMediaByTokenID :batchone
select m.id, m.created_at, m.last_updated, m.version, m.contract_id, m.token_id, m.chain, m.active, m.metadata, m.media, m.name, m.description, m.processing_job_id, m.deleted
from token_medias m
where m.id = (select token_media_id from tokens where tokens.id = $1) and m.active and not m.deleted
`

type GetMediaByTokenIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMediaByTokenID(ctx context.Context, id []persist.DBID) *GetMediaByTokenIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMediaByTokenID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMediaByTokenIDBatchResults{br, len(id), false}
}

func (b *GetMediaByTokenIDBatchResults) QueryRow(f func(int, TokenMedia, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenMedia
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Version,
			&i.ContractID,
			&i.TokenID,
			&i.Chain,
			&i.Active,
			&i.Metadata,
			&i.Media,
			&i.Name,
			&i.Description,
			&i.ProcessingJobID,
			&i.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMediaByTokenIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMembershipByMembershipIdBatch = `-- name: GetMembershipByMembershipIdBatch :batchone
SELECT id, deleted, version, created_at, last_updated, token_id, name, asset_url, owners FROM membership WHERE id = $1 AND deleted = false
`

type GetMembershipByMembershipIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMembershipByMembershipIdBatch(ctx context.Context, id []persist.DBID) *GetMembershipByMembershipIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMembershipByMembershipIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMembershipByMembershipIdBatchBatchResults{br, len(id), false}
}

func (b *GetMembershipByMembershipIdBatchBatchResults) QueryRow(f func(int, Membership, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Membership
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.TokenID,
			&i.Name,
			&i.AssetUrl,
			&i.Owners,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMembershipByMembershipIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getNewTokensByFeedEventIdBatch = `-- name: GetNewTokensByFeedEventIdBatch :batchmany
WITH new_tokens AS (
    SELECT added.id, row_number() OVER () added_order
    FROM (SELECT jsonb_array_elements_text(data -> 'collection_new_token_ids') id FROM feed_events f WHERE f.id = $1 AND f.deleted = false) added
)
SELECT t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name, t.description, t.collectors_note, t.media, t.token_uri, t.token_type, t.token_id, t.quantity, t.ownership_history, t.token_metadata, t.external_url, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract, t.is_user_marked_spam, t.is_provider_marked_spam, t.last_synced, t.fallback_media, t.token_media_id FROM new_tokens a JOIN tokens t ON a.id = t.id AND t.deleted = false ORDER BY a.added_order
`

type GetNewTokensByFeedEventIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetNewTokensByFeedEventIdBatch(ctx context.Context, id []persist.DBID) *GetNewTokensByFeedEventIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getNewTokensByFeedEventIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetNewTokensByFeedEventIdBatchBatchResults{br, len(id), false}
}

func (b *GetNewTokensByFeedEventIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Description,
					&i.CollectorsNote,
					&i.Media,
					&i.TokenUri,
					&i.TokenType,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistory,
					&i.TokenMetadata,
					&i.ExternalUrl,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.Contract,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpam,
					&i.LastSynced,
					&i.FallbackMedia,
					&i.TokenMediaID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetNewTokensByFeedEventIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getNotificationByIDBatch = `-- name: GetNotificationByIDBatch :batchone
SELECT id, deleted, owner_id, version, last_updated, created_at, action, data, event_ids, feed_event_id, comment_id, gallery_id, seen, amount FROM notifications WHERE id = $1 AND deleted = false
`

type GetNotificationByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetNotificationByIDBatch(ctx context.Context, id []persist.DBID) *GetNotificationByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getNotificationByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetNotificationByIDBatchBatchResults{br, len(id), false}
}

func (b *GetNotificationByIDBatchBatchResults) QueryRow(f func(int, Notification, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Notification
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.OwnerID,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Action,
			&i.Data,
			&i.EventIds,
			&i.FeedEventID,
			&i.CommentID,
			&i.GalleryID,
			&i.Seen,
			&i.Amount,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetNotificationByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getOwnersByContractIdBatchPaginate = `-- name: GetOwnersByContractIdBatchPaginate :batchmany
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_verified, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id from (
    select distinct on (u.id) u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id from users u, tokens t, contracts c
        where t.owner_user_id = u.id
        and t.contract = c.id and (c.id = $1 or c.parent_id = $1)
        and (not $2::bool or u.universal = false)
        and t.deleted = false and u.deleted = false and c.deleted = false
    ) as users
    where (users.universal,users.created_at,users.id) < ($3, $4::timestamptz, $5)
    and (users.universal,users.created_at,users.id) > ($6, $7::timestamptz, $8)
    order by case when $9::bool then (users.universal,users.created_at,users.id) end asc,
         case when not $9::bool then (users.universal,users.created_at,users.id) end desc limit $10
`

type GetOwnersByContractIdBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetOwnersByContractIdBatchPaginateParams struct {
	ID                 persist.DBID  `json:"id"`
	GalleryUsersOnly   bool          `json:"gallery_users_only"`
	CurBeforeUniversal bool          `json:"cur_before_universal"`
	CurBeforeTime      time.Time     `json:"cur_before_time"`
	CurBeforeID        persist.DBID  `json:"cur_before_id"`
	CurAfterUniversal  bool          `json:"cur_after_universal"`
	CurAfterTime       time.Time     `json:"cur_after_time"`
	CurAfterID         persist.DBID  `json:"cur_after_id"`
	PagingForward      bool          `json:"paging_forward"`
	Limit              sql.NullInt32 `json:"limit"`
}

// Note: sqlc has trouble recognizing that the output of the "select distinct" subquery below will
//
//	return complete rows from the users table. As a workaround, aliasing the subquery to
//	"users" seems to fix the issue (along with aliasing the users table inside the subquery
//	to "u" to avoid confusion -- otherwise, sqlc creates a custom row type that includes
//	all users.* fields twice).
func (q *Queries) GetOwnersByContractIdBatchPaginate(ctx context.Context, arg []GetOwnersByContractIdBatchPaginateParams) *GetOwnersByContractIdBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.GalleryUsersOnly,
			a.CurBeforeUniversal,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterUniversal,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getOwnersByContractIdBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetOwnersByContractIdBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetOwnersByContractIdBatchPaginateBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetOwnersByContractIdBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getPostByIdBatch = `-- name: GetPostByIdBatch :batchone
SELECT id, version, token_ids, actor_id, caption, created_at, last_updated, deleted FROM posts WHERE id = $1 AND deleted = false
`

type GetPostByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetPostByIdBatch(ctx context.Context, id []persist.DBID) *GetPostByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getPostByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetPostByIdBatchBatchResults{br, len(id), false}
}

func (b *GetPostByIdBatchBatchResults) QueryRow(f func(int, Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Post
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.TokenIds,
			&i.ActorID,
			&i.Caption,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetPostByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getProfileImageByID = `-- name: GetProfileImageByID :batchone
select id, user_id, token_id, source_type, deleted, created_at, last_updated, wallet_id, ens_avatar_uri, ens_domain from profile_images pfp
where pfp.id = $1
	and not deleted
	and case
		when source_type = $2
		then exists(select 1 from wallets w where w.id = wallet_id and not w.deleted)
		when source_type = $3
		then exists(select 1 from tokens t where t.id = token_id and not t.deleted)
		else
		0 = 1
	end
`

type GetProfileImageByIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetProfileImageByIDParams struct {
	ID              persist.DBID               `json:"id"`
	EnsSourceType   persist.ProfileImageSource `json:"ens_source_type"`
	TokenSourceType persist.ProfileImageSource `json:"token_source_type"`
}

func (q *Queries) GetProfileImageByID(ctx context.Context, arg []GetProfileImageByIDParams) *GetProfileImageByIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.EnsSourceType,
			a.TokenSourceType,
		}
		batch.Queue(getProfileImageByID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetProfileImageByIDBatchResults{br, len(arg), false}
}

func (b *GetProfileImageByIDBatchResults) QueryRow(f func(int, ProfileImage, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i ProfileImage
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.UserID,
			&i.TokenID,
			&i.SourceType,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.WalletID,
			&i.EnsAvatarUri,
			&i.EnsDomain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetProfileImageByIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getSharedContractsBatchPaginate = `-- name: GetSharedContractsBatchPaginate :batchmany
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id, a.displayed as displayed_by_user_a, b.displayed as displayed_by_user_b, a.owned_count
from owned_contracts a, owned_contracts b, contracts
left join marketplace_contracts on contracts.id = marketplace_contracts.contract_id
where a.user_id = $1
  and b.user_id = $2
  and a.contract_id = b.contract_id
  and a.contract_id = contracts.id
  and marketplace_contracts.contract_id is null
  and contracts.name is not null
  and contracts.name != ''
  and contracts.name != 'Unidentified contract'
  and (
    a.displayed,
    b.displayed,
    a.owned_count,
    contracts.id
  ) > (
    $3,
    $4,
    $5::int,
    $6
  )
  and (
    a.displayed,
    b.displayed,
    a.owned_count,
    contracts.id
  ) < (
    $7,
    $8,
    $9::int,
    $10
  )
order by case when $11::bool then (a.displayed, b.displayed, a.owned_count, contracts.id) end desc,
        case when not $11::bool then (a.displayed, b.displayed, a.owned_count, contracts.id) end asc
limit $12
`

type GetSharedContractsBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetSharedContractsBatchPaginateParams struct {
	UserAID                   persist.DBID `json:"user_a_id"`
	UserBID                   persist.DBID `json:"user_b_id"`
	CurBeforeDisplayedByUserA bool         `json:"cur_before_displayed_by_user_a"`
	CurBeforeDisplayedByUserB bool         `json:"cur_before_displayed_by_user_b"`
	CurBeforeOwnedCount       int32        `json:"cur_before_owned_count"`
	CurBeforeContractID       persist.DBID `json:"cur_before_contract_id"`
	CurAfterDisplayedByUserA  bool         `json:"cur_after_displayed_by_user_a"`
	CurAfterDisplayedByUserB  bool         `json:"cur_after_displayed_by_user_b"`
	CurAfterOwnedCount        int32        `json:"cur_after_owned_count"`
	CurAfterContractID        persist.DBID `json:"cur_after_contract_id"`
	PagingForward             bool         `json:"paging_forward"`
	Limit                     int32        `json:"limit"`
}

type GetSharedContractsBatchPaginateRow struct {
	ID                    persist.DBID    `json:"id"`
	Deleted               bool            `json:"deleted"`
	Version               sql.NullInt32   `json:"version"`
	CreatedAt             time.Time       `json:"created_at"`
	LastUpdated           time.Time       `json:"last_updated"`
	Name                  sql.NullString  `json:"name"`
	Symbol                sql.NullString  `json:"symbol"`
	Address               persist.Address `json:"address"`
	CreatorAddress        persist.Address `json:"creator_address"`
	Chain                 persist.Chain   `json:"chain"`
	ProfileBannerUrl      sql.NullString  `json:"profile_banner_url"`
	ProfileImageUrl       sql.NullString  `json:"profile_image_url"`
	BadgeUrl              sql.NullString  `json:"badge_url"`
	Description           sql.NullString  `json:"description"`
	OwnerAddress          persist.Address `json:"owner_address"`
	IsProviderMarkedSpam  bool            `json:"is_provider_marked_spam"`
	ParentID              persist.DBID    `json:"parent_id"`
	OverrideCreatorUserID persist.DBID    `json:"override_creator_user_id"`
	DisplayedByUserA      bool            `json:"displayed_by_user_a"`
	DisplayedByUserB      bool            `json:"displayed_by_user_b"`
	OwnedCount            int64           `json:"owned_count"`
}

func (q *Queries) GetSharedContractsBatchPaginate(ctx context.Context, arg []GetSharedContractsBatchPaginateParams) *GetSharedContractsBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserAID,
			a.UserBID,
			a.CurBeforeDisplayedByUserA,
			a.CurBeforeDisplayedByUserB,
			a.CurBeforeOwnedCount,
			a.CurBeforeContractID,
			a.CurAfterDisplayedByUserA,
			a.CurAfterDisplayedByUserB,
			a.CurAfterOwnedCount,
			a.CurAfterContractID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getSharedContractsBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetSharedContractsBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetSharedContractsBatchPaginateBatchResults) Query(f func(int, []GetSharedContractsBatchPaginateRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetSharedContractsBatchPaginateRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetSharedContractsBatchPaginateRow
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
					&i.DisplayedByUserA,
					&i.DisplayedByUserB,
					&i.OwnedCount,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetSharedContractsBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getSharedFollowersBatchPaginate = `-- name: GetSharedFollowersBatchPaginate :batchmany
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_verified, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id, a.created_at followed_on
from users, follows a, follows b
where a.follower = $1
	and a.followee = b.follower
	and b.followee = $2
	and users.id = b.follower
	and a.deleted = false
	and b.deleted = false
	and users.deleted = false
  and (a.created_at, users.id) > ($3, $4)
  and (a.created_at, users.id) < ($5, $6)
order by case when $7::bool then (a.created_at, users.id) end desc,
        case when not $7::bool then (a.created_at, users.id) end asc
limit $8
`

type GetSharedFollowersBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetSharedFollowersBatchPaginateParams struct {
	Follower      persist.DBID `json:"follower"`
	Followee      persist.DBID `json:"followee"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

type GetSharedFollowersBatchPaginateRow struct {
	ID                   persist.DBID                     `json:"id"`
	Deleted              bool                             `json:"deleted"`
	Version              sql.NullInt32                    `json:"version"`
	LastUpdated          time.Time                        `json:"last_updated"`
	CreatedAt            time.Time                        `json:"created_at"`
	Username             sql.NullString                   `json:"username"`
	UsernameIdempotent   sql.NullString                   `json:"username_idempotent"`
	Wallets              persist.WalletList               `json:"wallets"`
	Bio                  sql.NullString                   `json:"bio"`
	Traits               pgtype.JSONB                     `json:"traits"`
	Universal            bool                             `json:"universal"`
	NotificationSettings persist.UserNotificationSettings `json:"notification_settings"`
	EmailVerified        persist.EmailVerificationStatus  `json:"email_verified"`
	EmailUnsubscriptions persist.EmailUnsubscriptions     `json:"email_unsubscriptions"`
	FeaturedGallery      *persist.DBID                    `json:"featured_gallery"`
	PrimaryWalletID      persist.DBID                     `json:"primary_wallet_id"`
	UserExperiences      pgtype.JSONB                     `json:"user_experiences"`
	ProfileImageID       persist.DBID                     `json:"profile_image_id"`
	FollowedOn           time.Time                        `json:"followed_on"`
}

func (q *Queries) GetSharedFollowersBatchPaginate(ctx context.Context, arg []GetSharedFollowersBatchPaginateParams) *GetSharedFollowersBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Follower,
			a.Followee,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getSharedFollowersBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetSharedFollowersBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetSharedFollowersBatchPaginateBatchResults) Query(f func(int, []GetSharedFollowersBatchPaginateRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetSharedFollowersBatchPaginateRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetSharedFollowersBatchPaginateRow
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.FollowedOn,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetSharedFollowersBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByHolderIdContractAddressAndTokenIdBatch = `-- name: GetTokenByHolderIdContractAddressAndTokenIdBatch :batchone
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name, t.description, t.collectors_note, t.media, t.token_uri, t.token_type, t.token_id, t.quantity, t.ownership_history, t.token_metadata, t.external_url, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract, t.is_user_marked_spam, t.is_provider_marked_spam, t.last_synced, t.fallback_media, t.token_media_id
from tokens t
join contracts c on t.contract = c.id
where t.owner_user_id = $1 and t.token_id = $2 and c.address = $3 and c.chain = $4 and not t.deleted and not c.deleted
`

type GetTokenByHolderIdContractAddressAndTokenIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokenByHolderIdContractAddressAndTokenIdBatchParams struct {
	HolderID        persist.DBID    `json:"holder_id"`
	TokenID         persist.TokenID `json:"token_id"`
	ContractAddress persist.Address `json:"contract_address"`
	Chain           persist.Chain   `json:"chain"`
}

func (q *Queries) GetTokenByHolderIdContractAddressAndTokenIdBatch(ctx context.Context, arg []GetTokenByHolderIdContractAddressAndTokenIdBatchParams) *GetTokenByHolderIdContractAddressAndTokenIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.HolderID,
			a.TokenID,
			a.ContractAddress,
			a.Chain,
		}
		batch.Queue(getTokenByHolderIdContractAddressAndTokenIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByHolderIdContractAddressAndTokenIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokenByHolderIdContractAddressAndTokenIdBatchBatchResults) QueryRow(f func(int, Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Token
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Name,
			&i.Description,
			&i.CollectorsNote,
			&i.Media,
			&i.TokenUri,
			&i.TokenType,
			&i.TokenID,
			&i.Quantity,
			&i.OwnershipHistory,
			&i.TokenMetadata,
			&i.ExternalUrl,
			&i.BlockNumber,
			&i.OwnerUserID,
			&i.OwnedByWallets,
			&i.Chain,
			&i.Contract,
			&i.IsUserMarkedSpam,
			&i.IsProviderMarkedSpam,
			&i.LastSynced,
			&i.FallbackMedia,
			&i.TokenMediaID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByHolderIdContractAddressAndTokenIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByIdBatch = `-- name: GetTokenByIdBatch :batchone
SELECT id, deleted, version, created_at, last_updated, name, description, collectors_note, media, token_uri, token_type, token_id, quantity, ownership_history, token_metadata, external_url, block_number, owner_user_id, owned_by_wallets, chain, contract, is_user_marked_spam, is_provider_marked_spam, last_synced, fallback_media, token_media_id FROM tokens WHERE id = $1 AND deleted = false
`

type GetTokenByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenByIdBatch(ctx context.Context, id []persist.DBID) *GetTokenByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByIdBatchBatchResults{br, len(id), false}
}

func (b *GetTokenByIdBatchBatchResults) QueryRow(f func(int, Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Token
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Name,
			&i.Description,
			&i.CollectorsNote,
			&i.Media,
			&i.TokenUri,
			&i.TokenType,
			&i.TokenID,
			&i.Quantity,
			&i.OwnershipHistory,
			&i.TokenMetadata,
			&i.ExternalUrl,
			&i.BlockNumber,
			&i.OwnerUserID,
			&i.OwnedByWallets,
			&i.Chain,
			&i.Contract,
			&i.IsUserMarkedSpam,
			&i.IsProviderMarkedSpam,
			&i.LastSynced,
			&i.FallbackMedia,
			&i.TokenMediaID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenOwnerByIDBatch = `-- name: GetTokenOwnerByIDBatch :batchone
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id FROM tokens t
    JOIN users u ON u.id = t.owner_user_id
    WHERE t.id = $1 AND t.deleted = false AND u.deleted = false
`

type GetTokenOwnerByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenOwnerByIDBatch(ctx context.Context, id []persist.DBID) *GetTokenOwnerByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenOwnerByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenOwnerByIDBatchBatchResults{br, len(id), false}
}

func (b *GetTokenOwnerByIDBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenOwnerByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByCollectionIdBatch = `-- name: GetTokensByCollectionIdBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name, t.description, t.collectors_note, t.media, t.token_uri, t.token_type, t.token_id, t.quantity, t.ownership_history, t.token_metadata, t.external_url, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract, t.is_user_marked_spam, t.is_provider_marked_spam, t.last_synced, t.fallback_media, t.token_media_id from collections c,
    unnest(c.nfts) with ordinality as u(nft_id, nft_ord)
    join tokens t on t.id = u.nft_id
    join token_ownership o on o.token_id = u.nft_id
    where c.id = $1
      and c.owner_user_id = t.owner_user_id
      and c.owner_user_id = o.owner_user_id
      and c.deleted = false
      and t.deleted = false
    order by u.nft_ord
    limit $2
`

type GetTokensByCollectionIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByCollectionIdBatchParams struct {
	CollectionID persist.DBID  `json:"collection_id"`
	Limit        sql.NullInt32 `json:"limit"`
}

func (q *Queries) GetTokensByCollectionIdBatch(ctx context.Context, arg []GetTokensByCollectionIdBatchParams) *GetTokensByCollectionIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CollectionID,
			a.Limit,
		}
		batch.Queue(getTokensByCollectionIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByCollectionIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByCollectionIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Description,
					&i.CollectorsNote,
					&i.Media,
					&i.TokenUri,
					&i.TokenType,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistory,
					&i.TokenMetadata,
					&i.ExternalUrl,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.Contract,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpam,
					&i.LastSynced,
					&i.FallbackMedia,
					&i.TokenMediaID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByCollectionIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByUserIdAndChainBatch = `-- name: GetTokensByUserIdAndChainBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name, t.description, t.collectors_note, t.media, t.token_uri, t.token_type, t.token_id, t.quantity, t.ownership_history, t.token_metadata, t.external_url, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract, t.is_user_marked_spam, t.is_provider_marked_spam, t.last_synced, t.fallback_media, t.token_media_id from tokens t
    join token_ownership o on t.id = o.token_id and t.owner_user_id = o.owner_user_id
    where t.owner_user_id = $1
      and t.chain = $2
      and t.deleted = false
    order by t.created_at desc, t.name desc, t.id desc
`

type GetTokensByUserIdAndChainBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByUserIdAndChainBatchParams struct {
	OwnerUserID persist.DBID  `json:"owner_user_id"`
	Chain       persist.Chain `json:"chain"`
}

func (q *Queries) GetTokensByUserIdAndChainBatch(ctx context.Context, arg []GetTokensByUserIdAndChainBatchParams) *GetTokensByUserIdAndChainBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerUserID,
			a.Chain,
		}
		batch.Queue(getTokensByUserIdAndChainBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByUserIdAndChainBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByUserIdAndChainBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Description,
					&i.CollectorsNote,
					&i.Media,
					&i.TokenUri,
					&i.TokenType,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistory,
					&i.TokenMetadata,
					&i.ExternalUrl,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.Contract,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpam,
					&i.LastSynced,
					&i.FallbackMedia,
					&i.TokenMediaID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByUserIdAndChainBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByUserIdBatch = `-- name: GetTokensByUserIdBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name, t.description, t.collectors_note, t.media, t.token_uri, t.token_type, t.token_id, t.quantity, t.ownership_history, t.token_metadata, t.external_url, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract, t.is_user_marked_spam, t.is_provider_marked_spam, t.last_synced, t.fallback_media, t.token_media_id from tokens t
    join token_ownership o on t.id = o.token_id and t.owner_user_id = o.owner_user_id
    where t.owner_user_id = $1
      and t.deleted = false
      and (($2::bool and o.is_holder) or ($3::bool and o.is_creator))
    order by t.created_at desc, t.name desc, t.id desc
`

type GetTokensByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByUserIdBatchParams struct {
	OwnerUserID    persist.DBID `json:"owner_user_id"`
	IncludeHolder  bool         `json:"include_holder"`
	IncludeCreator bool         `json:"include_creator"`
}

func (q *Queries) GetTokensByUserIdBatch(ctx context.Context, arg []GetTokensByUserIdBatchParams) *GetTokensByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerUserID,
			a.IncludeHolder,
			a.IncludeCreator,
		}
		batch.Queue(getTokensByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByUserIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByUserIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Description,
					&i.CollectorsNote,
					&i.Media,
					&i.TokenUri,
					&i.TokenType,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistory,
					&i.TokenMetadata,
					&i.ExternalUrl,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.Contract,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpam,
					&i.LastSynced,
					&i.FallbackMedia,
					&i.TokenMediaID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByWalletIdsBatch = `-- name: GetTokensByWalletIdsBatch :batchmany
SELECT id, deleted, version, created_at, last_updated, name, description, collectors_note, media, token_uri, token_type, token_id, quantity, ownership_history, token_metadata, external_url, block_number, owner_user_id, owned_by_wallets, chain, contract, is_user_marked_spam, is_provider_marked_spam, last_synced, fallback_media, token_media_id FROM tokens WHERE owned_by_wallets && $1 AND deleted = false
    ORDER BY tokens.created_at DESC, tokens.name DESC, tokens.id DESC
`

type GetTokensByWalletIdsBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokensByWalletIdsBatch(ctx context.Context, ownedByWallets []persist.DBIDList) *GetTokensByWalletIdsBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range ownedByWallets {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokensByWalletIdsBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByWalletIdsBatchBatchResults{br, len(ownedByWallets), false}
}

func (b *GetTokensByWalletIdsBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Description,
					&i.CollectorsNote,
					&i.Media,
					&i.TokenUri,
					&i.TokenType,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistory,
					&i.TokenMetadata,
					&i.ExternalUrl,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.Contract,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpam,
					&i.LastSynced,
					&i.FallbackMedia,
					&i.TokenMediaID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByWalletIdsBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByAddressBatch = `-- name: GetUserByAddressBatch :batchone
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_verified, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id
from users, wallets
where wallets.address = $1
	and wallets.chain = $2::int
	and array[wallets.id] <@ users.wallets
	and wallets.deleted = false
	and users.deleted = false
`

type GetUserByAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUserByAddressBatchParams struct {
	Address persist.Address `json:"address"`
	Chain   int32           `json:"chain"`
}

func (q *Queries) GetUserByAddressBatch(ctx context.Context, arg []GetUserByAddressBatchParams) *GetUserByAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getUserByAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetUserByAddressBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByIdBatch = `-- name: GetUserByIdBatch :batchone
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_verified, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id FROM users WHERE id = $1 AND deleted = false
`

type GetUserByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUserByIdBatch(ctx context.Context, id []persist.DBID) *GetUserByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUserByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByIdBatchBatchResults{br, len(id), false}
}

func (b *GetUserByIdBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByUsernameBatch = `-- name: GetUserByUsernameBatch :batchone
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_verified, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id FROM users WHERE username_idempotent = lower($1) AND deleted = false
`

type GetUserByUsernameBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUserByUsernameBatch(ctx context.Context, lower []string) *GetUserByUsernameBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range lower {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUserByUsernameBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByUsernameBatchBatchResults{br, len(lower), false}
}

func (b *GetUserByUsernameBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByUsernameBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserNotificationsBatch = `-- name: GetUserNotificationsBatch :batchmany
SELECT id, deleted, owner_id, version, last_updated, created_at, action, data, event_ids, feed_event_id, comment_id, gallery_id, seen, amount FROM notifications WHERE owner_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type GetUserNotificationsBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUserNotificationsBatchParams struct {
	OwnerID       persist.DBID `json:"owner_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) GetUserNotificationsBatch(ctx context.Context, arg []GetUserNotificationsBatchParams) *GetUserNotificationsBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getUserNotificationsBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserNotificationsBatchBatchResults{br, len(arg), false}
}

func (b *GetUserNotificationsBatchBatchResults) Query(f func(int, []Notification, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Notification
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Notification
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerID,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Action,
					&i.Data,
					&i.EventIds,
					&i.FeedEventID,
					&i.CommentID,
					&i.GalleryID,
					&i.Seen,
					&i.Amount,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUserNotificationsBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUsersWithTraitBatch = `-- name: GetUsersWithTraitBatch :batchmany
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_verified, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id FROM users WHERE (traits->$1::string) IS NOT NULL AND deleted = false
`

type GetUsersWithTraitBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUsersWithTraitBatch(ctx context.Context, dollar_1 []string) *GetUsersWithTraitBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range dollar_1 {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUsersWithTraitBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUsersWithTraitBatchBatchResults{br, len(dollar_1), false}
}

func (b *GetUsersWithTraitBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUsersWithTraitBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletByChainAddressBatch = `-- name: GetWalletByChainAddressBatch :batchone
SELECT wallets.id, wallets.created_at, wallets.last_updated, wallets.deleted, wallets.version, wallets.address, wallets.wallet_type, wallets.chain FROM wallets WHERE address = $1 AND chain = $2 AND deleted = false
`

type GetWalletByChainAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetWalletByChainAddressBatchParams struct {
	Address persist.Address `json:"address"`
	Chain   persist.Chain   `json:"chain"`
}

func (q *Queries) GetWalletByChainAddressBatch(ctx context.Context, arg []GetWalletByChainAddressBatchParams) *GetWalletByChainAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getWalletByChainAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletByChainAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetWalletByChainAddressBatchBatchResults) QueryRow(f func(int, Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Wallet
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Version,
			&i.Address,
			&i.WalletType,
			&i.Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetWalletByChainAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletByIDBatch = `-- name: GetWalletByIDBatch :batchone
SELECT id, created_at, last_updated, deleted, version, address, wallet_type, chain FROM wallets WHERE id = $1 AND deleted = false
`

type GetWalletByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetWalletByIDBatch(ctx context.Context, id []persist.DBID) *GetWalletByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getWalletByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletByIDBatchBatchResults{br, len(id), false}
}

func (b *GetWalletByIDBatchBatchResults) QueryRow(f func(int, Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Wallet
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Version,
			&i.Address,
			&i.WalletType,
			&i.Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetWalletByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletsByUserIDBatch = `-- name: GetWalletsByUserIDBatch :batchmany
SELECT w.id, w.created_at, w.last_updated, w.deleted, w.version, w.address, w.wallet_type, w.chain FROM users u, unnest(u.wallets) WITH ORDINALITY AS a(wallet_id, wallet_ord)INNER JOIN wallets w on w.id = a.wallet_id WHERE u.id = $1 AND u.deleted = false AND w.deleted = false ORDER BY a.wallet_ord
`

type GetWalletsByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetWalletsByUserIDBatch(ctx context.Context, id []persist.DBID) *GetWalletsByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getWalletsByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletsByUserIDBatchBatchResults{br, len(id), false}
}

func (b *GetWalletsByUserIDBatchBatchResults) Query(f func(int, []Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Wallet
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Wallet
				if err := rows.Scan(
					&i.ID,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.Version,
					&i.Address,
					&i.WalletType,
					&i.Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetWalletsByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByFeedEventIDBatch = `-- name: PaginateAdmiresByFeedEventIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id FROM admires WHERE feed_event_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3) AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateAdmiresByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByFeedEventIDBatchParams struct {
	FeedEventID   persist.DBID `json:"feed_event_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateAdmiresByFeedEventIDBatch(ctx context.Context, arg []PaginateAdmiresByFeedEventIDBatchParams) *PaginateAdmiresByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.FeedEventID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByFeedEventIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByPostIDBatch = `-- name: PaginateAdmiresByPostIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id FROM admires WHERE post_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3) AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateAdmiresByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByPostIDBatchParams struct {
	PostID        persist.DBID `json:"post_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateAdmiresByPostIDBatch(ctx context.Context, arg []PaginateAdmiresByPostIDBatchParams) *PaginateAdmiresByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByPostIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateCommentsByFeedEventIDBatch = `-- name: PaginateCommentsByFeedEventIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id FROM comments WHERE feed_event_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateCommentsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateCommentsByFeedEventIDBatchParams struct {
	FeedEventID   persist.DBID `json:"feed_event_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateCommentsByFeedEventIDBatch(ctx context.Context, arg []PaginateCommentsByFeedEventIDBatchParams) *PaginateCommentsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.FeedEventID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateCommentsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateCommentsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateCommentsByFeedEventIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateCommentsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateCommentsByPostIDBatch = `-- name: PaginateCommentsByPostIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id FROM comments WHERE post_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateCommentsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateCommentsByPostIDBatchParams struct {
	PostID        persist.DBID `json:"post_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateCommentsByPostIDBatch(ctx context.Context, arg []PaginateCommentsByPostIDBatchParams) *PaginateCommentsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateCommentsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateCommentsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateCommentsByPostIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateCommentsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateInteractionsByFeedEventIDBatch = `-- name: PaginateInteractionsByFeedEventIDBatch :batchmany
SELECT interactions.created_At, interactions.id, interactions.tag FROM (
    SELECT t.created_at, t.id, $1::int as tag FROM admires t WHERE $1 != 0 AND t.feed_event_id = $2 AND t.deleted = false
        AND ($1, t.created_at, t.id) < ($3::int, $4, $5) AND ($1, t.created_at, t.id) > ($6::int, $7, $8)
                                                                    UNION
    SELECT t.created_at, t.id, $9::int as tag FROM comments t WHERE $9 != 0 AND t.feed_event_id = $2 AND t.deleted = false
        AND ($9, t.created_at, t.id) < ($3::int, $4, $5) AND ($9, t.created_at, t.id) > ($6::int, $7, $8)
) as interactions

ORDER BY CASE WHEN $10::bool THEN (tag, created_at, id) END ASC,
         CASE WHEN NOT $10::bool THEN (tag, created_at, id) END DESC
LIMIT $11
`

type PaginateInteractionsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateInteractionsByFeedEventIDBatchParams struct {
	AdmireTag     int32        `json:"admire_tag"`
	FeedEventID   persist.DBID `json:"feed_event_id"`
	CurBeforeTag  int32        `json:"cur_before_tag"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTag   int32        `json:"cur_after_tag"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	CommentTag    int32        `json:"comment_tag"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

type PaginateInteractionsByFeedEventIDBatchRow struct {
	CreatedAt time.Time    `json:"created_at"`
	ID        persist.DBID `json:"id"`
	Tag       int32        `json:"tag"`
}

func (q *Queries) PaginateInteractionsByFeedEventIDBatch(ctx context.Context, arg []PaginateInteractionsByFeedEventIDBatchParams) *PaginateInteractionsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.FeedEventID,
			a.CurBeforeTag,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTag,
			a.CurAfterTime,
			a.CurAfterID,
			a.CommentTag,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateInteractionsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateInteractionsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateInteractionsByFeedEventIDBatchBatchResults) Query(f func(int, []PaginateInteractionsByFeedEventIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateInteractionsByFeedEventIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateInteractionsByFeedEventIDBatchRow
				if err := rows.Scan(&i.CreatedAt, &i.ID, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateInteractionsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateInteractionsByPostIDBatch = `-- name: PaginateInteractionsByPostIDBatch :batchmany
SELECT interactions.created_At, interactions.id, interactions.tag FROM (
    SELECT t.created_at, t.id, $1::int as tag FROM admires t WHERE $1 != 0 AND t.post_id = $2 AND t.deleted = false
        AND ($1, t.created_at, t.id) < ($3::int, $4, $5) AND ($1, t.created_at, t.id) > ($6::int, $7, $8)
                                                                    UNION
    SELECT t.created_at, t.id, $9::int as tag FROM comments t WHERE $9 != 0 AND t.post_id = $2 AND t.deleted = false
        AND ($9, t.created_at, t.id) < ($3::int, $4, $5) AND ($9, t.created_at, t.id) > ($6::int, $7, $8)
) as interactions

ORDER BY CASE WHEN $10::bool THEN (tag, created_at, id) END ASC,
         CASE WHEN NOT $10::bool THEN (tag, created_at, id) END DESC
LIMIT $11
`

type PaginateInteractionsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateInteractionsByPostIDBatchParams struct {
	AdmireTag     int32        `json:"admire_tag"`
	PostID        persist.DBID `json:"post_id"`
	CurBeforeTag  int32        `json:"cur_before_tag"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTag   int32        `json:"cur_after_tag"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	CommentTag    int32        `json:"comment_tag"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

type PaginateInteractionsByPostIDBatchRow struct {
	CreatedAt time.Time    `json:"created_at"`
	ID        persist.DBID `json:"id"`
	Tag       int32        `json:"tag"`
}

func (q *Queries) PaginateInteractionsByPostIDBatch(ctx context.Context, arg []PaginateInteractionsByPostIDBatchParams) *PaginateInteractionsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.PostID,
			a.CurBeforeTag,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTag,
			a.CurAfterTime,
			a.CurAfterID,
			a.CommentTag,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateInteractionsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateInteractionsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateInteractionsByPostIDBatchBatchResults) Query(f func(int, []PaginateInteractionsByPostIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateInteractionsByPostIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateInteractionsByPostIDBatchRow
				if err := rows.Scan(&i.CreatedAt, &i.ID, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateInteractionsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginatePostsByContractID = `-- name: PaginatePostsByContractID :batchmany
WITH unnest_post_ids AS (
    SELECT posts.id, unnest(token_ids) AS post_token_id
    FROM posts
    WHERE posts.deleted = false
    AND (posts.created_at, posts.id) < ($4, $5)
    AND (posts.created_at, posts.id) > ($6, $7)
)
SELECT posts.id, posts.version, posts.token_ids, posts.actor_id, posts.caption, posts.created_at, posts.last_updated, posts.deleted
FROM unnest_post_ids
JOIN posts ON unnest_post_ids.id = posts.id
JOIN tokens ON tokens.id = unnest_post_ids.post_token_id
WHERE tokens.contract = $1
ORDER BY 
    CASE WHEN $2::bool THEN (posts.created_at, posts.id) END ASC,
    CASE WHEN NOT $2::bool THEN (posts.created_at, posts.id) END DESC
LIMIT $3
`

type PaginatePostsByContractIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginatePostsByContractIDParams struct {
	Contract      persist.DBID `json:"contract"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
}

func (q *Queries) PaginatePostsByContractID(ctx context.Context, arg []PaginatePostsByContractIDParams) *PaginatePostsByContractIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Contract,
			a.PagingForward,
			a.Limit,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
		}
		batch.Queue(paginatePostsByContractID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginatePostsByContractIDBatchResults{br, len(arg), false}
}

func (b *PaginatePostsByContractIDBatchResults) Query(f func(int, []Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Post
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Post
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.TokenIds,
					&i.ActorID,
					&i.Caption,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginatePostsByContractIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
