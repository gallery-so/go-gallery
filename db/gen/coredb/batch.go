// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.18.0
// source: batch.go

package coredb

import (
	"context"
	"database/sql"
	"errors"
	"time"

	"github.com/jackc/pgx/v4"
	"github.com/mikeydub/go-gallery/service/persist"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const countAdmiresByCommentIDBatch = `-- name: CountAdmiresByCommentIDBatch :batchone
select count(*) from admires where comment_id = $1 and deleted = false
`

type CountAdmiresByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByCommentIDBatch(ctx context.Context, commentID []persist.DBID) *CountAdmiresByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range commentID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByCommentIDBatchBatchResults{br, len(commentID), false}
}

func (b *CountAdmiresByCommentIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countAdmiresByFeedEventIDBatch = `-- name: CountAdmiresByFeedEventIDBatch :batchone
SELECT count(*) FROM admires WHERE feed_event_id = $1 AND deleted = false
`

type CountAdmiresByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByFeedEventIDBatch(ctx context.Context, feedEventID []persist.DBID) *CountAdmiresByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range feedEventID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByFeedEventIDBatchBatchResults{br, len(feedEventID), false}
}

func (b *CountAdmiresByFeedEventIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countAdmiresByPostIDBatch = `-- name: CountAdmiresByPostIDBatch :batchone
SELECT count(*) FROM admires WHERE post_id = $1 AND deleted = false
`

type CountAdmiresByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByPostIDBatch(ctx context.Context, postID []persist.DBID) *CountAdmiresByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByPostIDBatchBatchResults{br, len(postID), false}
}

func (b *CountAdmiresByPostIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countAdmiresByTokenIDBatch = `-- name: CountAdmiresByTokenIDBatch :batchone
SELECT count(*) FROM admires WHERE token_id = $1 AND deleted = false
`

type CountAdmiresByTokenIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByTokenIDBatch(ctx context.Context, tokenID []persist.DBID) *CountAdmiresByTokenIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range tokenID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByTokenIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByTokenIDBatchBatchResults{br, len(tokenID), false}
}

func (b *CountAdmiresByTokenIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByTokenIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countCommentsByFeedEventIDBatch = `-- name: CountCommentsByFeedEventIDBatch :batchone
SELECT count(*) FROM comments WHERE feed_event_id = $1 AND reply_to is null AND deleted = false
`

type CountCommentsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountCommentsByFeedEventIDBatch(ctx context.Context, feedEventID []persist.DBID) *CountCommentsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range feedEventID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countCommentsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountCommentsByFeedEventIDBatchBatchResults{br, len(feedEventID), false}
}

func (b *CountCommentsByFeedEventIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountCommentsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countCommentsByPostIDBatch = `-- name: CountCommentsByPostIDBatch :batchone
SELECT count(*) FROM comments WHERE post_id = $1 AND reply_to is null AND deleted = false
`

type CountCommentsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountCommentsByPostIDBatch(ctx context.Context, postID []persist.DBID) *CountCommentsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countCommentsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountCommentsByPostIDBatchBatchResults{br, len(postID), false}
}

func (b *CountCommentsByPostIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountCommentsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countGalleriesDisplayingCommunityIDBatch = `-- name: CountGalleriesDisplayingCommunityIDBatch :batchone
select count(*) from community_galleries cg
    join galleries g on cg.gallery_id = g.id and not g.deleted and not g.hidden
where cg.community_id = $1
`

type CountGalleriesDisplayingCommunityIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountGalleriesDisplayingCommunityIDBatch(ctx context.Context, communityID []persist.DBID) *CountGalleriesDisplayingCommunityIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range communityID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countGalleriesDisplayingCommunityIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountGalleriesDisplayingCommunityIDBatchBatchResults{br, len(communityID), false}
}

func (b *CountGalleriesDisplayingCommunityIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountGalleriesDisplayingCommunityIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countInteractionsByFeedEventIDBatch = `-- name: CountInteractionsByFeedEventIDBatch :batchmany
SELECT count(*), $1::int as tag FROM admires t WHERE $1 != 0 AND t.feed_event_id = $2 AND t.deleted = false
                                                        UNION
SELECT count(*), $3::int as tag FROM comments t WHERE $3 != 0 AND t.feed_event_id = $2 AND t.reply_to is null AND t.deleted = false
`

type CountInteractionsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CountInteractionsByFeedEventIDBatchParams struct {
	AdmireTag   int32        `db:"admire_tag" json:"admire_tag"`
	FeedEventID persist.DBID `db:"feed_event_id" json:"feed_event_id"`
	CommentTag  int32        `db:"comment_tag" json:"comment_tag"`
}

type CountInteractionsByFeedEventIDBatchRow struct {
	Count int64 `db:"count" json:"count"`
	Tag   int32 `db:"tag" json:"tag"`
}

func (q *Queries) CountInteractionsByFeedEventIDBatch(ctx context.Context, arg []CountInteractionsByFeedEventIDBatchParams) *CountInteractionsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.FeedEventID,
			a.CommentTag,
		}
		batch.Queue(countInteractionsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountInteractionsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *CountInteractionsByFeedEventIDBatchBatchResults) Query(f func(int, []CountInteractionsByFeedEventIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []CountInteractionsByFeedEventIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i CountInteractionsByFeedEventIDBatchRow
				if err := rows.Scan(&i.Count, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *CountInteractionsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countInteractionsByPostIDBatch = `-- name: CountInteractionsByPostIDBatch :batchmany
SELECT count(*), $1::int as tag FROM admires t WHERE $1 != 0 AND t.post_id = $2 AND t.deleted = false
                                                        UNION
SELECT count(*), $3::int as tag FROM comments t WHERE $3 != 0 AND t.post_id = $2 AND t.reply_to is null AND t.deleted = false
`

type CountInteractionsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CountInteractionsByPostIDBatchParams struct {
	AdmireTag  int32        `db:"admire_tag" json:"admire_tag"`
	PostID     persist.DBID `db:"post_id" json:"post_id"`
	CommentTag int32        `db:"comment_tag" json:"comment_tag"`
}

type CountInteractionsByPostIDBatchRow struct {
	Count int64 `db:"count" json:"count"`
	Tag   int32 `db:"tag" json:"tag"`
}

func (q *Queries) CountInteractionsByPostIDBatch(ctx context.Context, arg []CountInteractionsByPostIDBatchParams) *CountInteractionsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.PostID,
			a.CommentTag,
		}
		batch.Queue(countInteractionsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountInteractionsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *CountInteractionsByPostIDBatchBatchResults) Query(f func(int, []CountInteractionsByPostIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []CountInteractionsByPostIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i CountInteractionsByPostIDBatchRow
				if err := rows.Scan(&i.Count, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *CountInteractionsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countRepliesByCommentIDBatch = `-- name: CountRepliesByCommentIDBatch :batchone
SELECT count(*) FROM comments c 
WHERE 
    CASE 
        WHEN (SELECT reply_to FROM comments cc WHERE cc.id = $1) IS NULL 
        THEN c.top_level_comment_id = $1 
        ELSE c.reply_to = $1 
    END
    AND c.deleted = false
`

type CountRepliesByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountRepliesByCommentIDBatch(ctx context.Context, commentID []persist.DBID) *CountRepliesByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range commentID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countRepliesByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountRepliesByCommentIDBatchBatchResults{br, len(commentID), false}
}

func (b *CountRepliesByCommentIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountRepliesByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndCommentID = `-- name: GetAdmireByActorIDAndCommentID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE actor_id = $1 AND comment_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndCommentIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndCommentIDParams struct {
	ActorID   persist.DBID `db:"actor_id" json:"actor_id"`
	CommentID persist.DBID `db:"comment_id" json:"comment_id"`
}

func (q *Queries) GetAdmireByActorIDAndCommentID(ctx context.Context, arg []GetAdmireByActorIDAndCommentIDParams) *GetAdmireByActorIDAndCommentIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.CommentID,
		}
		batch.Queue(getAdmireByActorIDAndCommentID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndCommentIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndCommentIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
			&i.CommentID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndCommentIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndFeedEventID = `-- name: GetAdmireByActorIDAndFeedEventID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE actor_id = $1 AND feed_event_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndFeedEventIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndFeedEventIDParams struct {
	ActorID     persist.DBID `db:"actor_id" json:"actor_id"`
	FeedEventID persist.DBID `db:"feed_event_id" json:"feed_event_id"`
}

func (q *Queries) GetAdmireByActorIDAndFeedEventID(ctx context.Context, arg []GetAdmireByActorIDAndFeedEventIDParams) *GetAdmireByActorIDAndFeedEventIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.FeedEventID,
		}
		batch.Queue(getAdmireByActorIDAndFeedEventID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndFeedEventIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndFeedEventIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
			&i.CommentID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndFeedEventIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndPostID = `-- name: GetAdmireByActorIDAndPostID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE actor_id = $1 AND post_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndPostIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndPostIDParams struct {
	ActorID persist.DBID `db:"actor_id" json:"actor_id"`
	PostID  persist.DBID `db:"post_id" json:"post_id"`
}

func (q *Queries) GetAdmireByActorIDAndPostID(ctx context.Context, arg []GetAdmireByActorIDAndPostIDParams) *GetAdmireByActorIDAndPostIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.PostID,
		}
		batch.Queue(getAdmireByActorIDAndPostID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndPostIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndPostIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
			&i.CommentID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndPostIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndTokenID = `-- name: GetAdmireByActorIDAndTokenID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE actor_id = $1 AND token_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndTokenIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndTokenIDParams struct {
	ActorID persist.DBID `db:"actor_id" json:"actor_id"`
	TokenID persist.DBID `db:"token_id" json:"token_id"`
}

func (q *Queries) GetAdmireByActorIDAndTokenID(ctx context.Context, arg []GetAdmireByActorIDAndTokenIDParams) *GetAdmireByActorIDAndTokenIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.TokenID,
		}
		batch.Queue(getAdmireByActorIDAndTokenID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndTokenIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndTokenIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
			&i.CommentID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndTokenIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByAdmireIDBatch = `-- name: GetAdmireByAdmireIDBatch :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE id = $1 AND deleted = false
`

type GetAdmireByAdmireIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetAdmireByAdmireIDBatch(ctx context.Context, id []persist.DBID) *GetAdmireByAdmireIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getAdmireByAdmireIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByAdmireIDBatchBatchResults{br, len(id), false}
}

func (b *GetAdmireByAdmireIDBatchBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
			&i.CommentID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByAdmireIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmiresByActorIDBatch = `-- name: GetAdmiresByActorIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE actor_id = $1 AND deleted = false ORDER BY created_at DESC
`

type GetAdmiresByActorIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetAdmiresByActorIDBatch(ctx context.Context, actorID []persist.DBID) *GetAdmiresByActorIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range actorID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getAdmiresByActorIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmiresByActorIDBatchBatchResults{br, len(actorID), false}
}

func (b *GetAdmiresByActorIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
					&i.CommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetAdmiresByActorIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getChildContractsByParentIDBatchPaginate = `-- name: GetChildContractsByParentIDBatchPaginate :batchmany
select c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain
from contracts c
where c.parent_id = $1
  and c.deleted = false
  and (c.created_at, c.id) < ($2, $3)
  and (c.created_at, c.id) > ( $4, $5)
order by case when $6::bool then (c.created_at, c.id) end asc,
        case when not $6::bool then (c.created_at, c.id) end desc
limit $7
`

type GetChildContractsByParentIDBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetChildContractsByParentIDBatchPaginateParams struct {
	ParentID      persist.DBID `db:"parent_id" json:"parent_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) GetChildContractsByParentIDBatchPaginate(ctx context.Context, arg []GetChildContractsByParentIDBatchPaginateParams) *GetChildContractsByParentIDBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ParentID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getChildContractsByParentIDBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetChildContractsByParentIDBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetChildContractsByParentIDBatchPaginateBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
					&i.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetChildContractsByParentIDBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCollectionByIdBatch = `-- name: GetCollectionByIdBatch :batchone
SELECT id, deleted, owner_user_id, nfts, version, last_updated, created_at, hidden, collectors_note, name, layout, token_settings, gallery_id FROM collections WHERE id = $1 AND deleted = false
`

type GetCollectionByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCollectionByIdBatch(ctx context.Context, id []persist.DBID) *GetCollectionByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCollectionByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCollectionByIdBatchBatchResults{br, len(id), false}
}

func (b *GetCollectionByIdBatchBatchResults) QueryRow(f func(int, Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Collection
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.OwnerUserID,
			&i.Nfts,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Hidden,
			&i.CollectorsNote,
			&i.Name,
			&i.Layout,
			&i.TokenSettings,
			&i.GalleryID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCollectionByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCollectionsByGalleryIdBatch = `-- name: GetCollectionsByGalleryIdBatch :batchmany
SELECT c.id, c.deleted, c.owner_user_id, c.nfts, c.version, c.last_updated, c.created_at, c.hidden, c.collectors_note, c.name, c.layout, c.token_settings, c.gallery_id FROM galleries g, unnest(g.collections)
    WITH ORDINALITY AS x(coll_id, coll_ord)
    INNER JOIN collections c ON c.id = x.coll_id
    WHERE g.id = $1 AND g.deleted = false AND c.deleted = false ORDER BY x.coll_ord
`

type GetCollectionsByGalleryIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCollectionsByGalleryIdBatch(ctx context.Context, id []persist.DBID) *GetCollectionsByGalleryIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCollectionsByGalleryIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCollectionsByGalleryIdBatchBatchResults{br, len(id), false}
}

func (b *GetCollectionsByGalleryIdBatchBatchResults) Query(f func(int, []Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Collection
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Collection
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerUserID,
					&i.Nfts,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Hidden,
					&i.CollectorsNote,
					&i.Name,
					&i.Layout,
					&i.TokenSettings,
					&i.GalleryID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCollectionsByGalleryIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommentByCommentIDBatch = `-- name: GetCommentByCommentIDBatch :batchone
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed, top_level_comment_id FROM comments WHERE id = $1 AND deleted = false
`

type GetCommentByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCommentByCommentIDBatch(ctx context.Context, id []persist.DBID) *GetCommentByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCommentByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommentByCommentIDBatchBatchResults{br, len(id), false}
}

func (b *GetCommentByCommentIDBatchBatchResults) QueryRow(f func(int, Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Comment
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.ReplyTo,
			&i.Comment,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.Removed,
			&i.TopLevelCommentID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCommentByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommunitiesByTokenDefinitionID = `-- name: GetCommunitiesByTokenDefinitionID :batchmany
select communities.id, communities.version, communities.community_type, communities.key1, communities.key2, communities.key3, communities.key4, communities.name, communities.override_name, communities.description, communities.override_description, communities.profile_image_url, communities.override_profile_image_url, communities.badge_url, communities.override_badge_url, communities.contract_id, communities.created_at, communities.last_updated, communities.deleted, communities.website_url, communities.override_website_url, communities.mint_url, communities.override_mint_url from communities
    join token_definitions on token_definitions.contract_id = communities.contract_id
    where community_type = 0
        and token_definitions.id = $1
        and not communities.deleted
        and not token_definitions.deleted

union all

select communities.id, communities.version, communities.community_type, communities.key1, communities.key2, communities.key3, communities.key4, communities.name, communities.override_name, communities.description, communities.override_description, communities.profile_image_url, communities.override_profile_image_url, communities.badge_url, communities.override_badge_url, communities.contract_id, communities.created_at, communities.last_updated, communities.deleted, communities.website_url, communities.override_website_url, communities.mint_url, communities.override_mint_url from communities
    join token_community_memberships on token_community_memberships.community_id = communities.id
    where community_type != 0
        and token_community_memberships.token_definition_id = $1
        and not communities.deleted
        and not token_community_memberships.deleted
`

type GetCommunitiesByTokenDefinitionIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCommunitiesByTokenDefinitionID(ctx context.Context, tokenDefinitionID []persist.DBID) *GetCommunitiesByTokenDefinitionIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range tokenDefinitionID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCommunitiesByTokenDefinitionID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommunitiesByTokenDefinitionIDBatchResults{br, len(tokenDefinitionID), false}
}

func (b *GetCommunitiesByTokenDefinitionIDBatchResults) Query(f func(int, []Community, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Community
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Community
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.CommunityType,
					&i.Key1,
					&i.Key2,
					&i.Key3,
					&i.Key4,
					&i.Name,
					&i.OverrideName,
					&i.Description,
					&i.OverrideDescription,
					&i.ProfileImageUrl,
					&i.OverrideProfileImageUrl,
					&i.BadgeUrl,
					&i.OverrideBadgeUrl,
					&i.ContractID,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.WebsiteUrl,
					&i.OverrideWebsiteUrl,
					&i.MintUrl,
					&i.OverrideMintUrl,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCommunitiesByTokenDefinitionIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommunityByIDBatch = `-- name: GetCommunityByIDBatch :batchone
select id, version, community_type, key1, key2, key3, key4, name, override_name, description, override_description, profile_image_url, override_profile_image_url, badge_url, override_badge_url, contract_id, created_at, last_updated, deleted, website_url, override_website_url, mint_url, override_mint_url from communities
    where id = $1
        and not deleted
`

type GetCommunityByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCommunityByIDBatch(ctx context.Context, id []persist.DBID) *GetCommunityByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCommunityByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommunityByIDBatchBatchResults{br, len(id), false}
}

func (b *GetCommunityByIDBatchBatchResults) QueryRow(f func(int, Community, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Community
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.CommunityType,
			&i.Key1,
			&i.Key2,
			&i.Key3,
			&i.Key4,
			&i.Name,
			&i.OverrideName,
			&i.Description,
			&i.OverrideDescription,
			&i.ProfileImageUrl,
			&i.OverrideProfileImageUrl,
			&i.BadgeUrl,
			&i.OverrideBadgeUrl,
			&i.ContractID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.WebsiteUrl,
			&i.OverrideWebsiteUrl,
			&i.MintUrl,
			&i.OverrideMintUrl,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCommunityByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommunityByKey = `-- name: GetCommunityByKey :batchone
select id, version, community_type, key1, key2, key3, key4, name, override_name, description, override_description, profile_image_url, override_profile_image_url, badge_url, override_badge_url, contract_id, created_at, last_updated, deleted, website_url, override_website_url, mint_url, override_mint_url from communities
    where $1 = community_type
        and $2 = key1
        and $3 = key2
        and $4 = key3
        and $5 = key4
        and not deleted
`

type GetCommunityByKeyBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetCommunityByKeyParams struct {
	Type int32  `db:"type" json:"type"`
	Key1 string `db:"key1" json:"key1"`
	Key2 string `db:"key2" json:"key2"`
	Key3 string `db:"key3" json:"key3"`
	Key4 string `db:"key4" json:"key4"`
}

func (q *Queries) GetCommunityByKey(ctx context.Context, arg []GetCommunityByKeyParams) *GetCommunityByKeyBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Type,
			a.Key1,
			a.Key2,
			a.Key3,
			a.Key4,
		}
		batch.Queue(getCommunityByKey, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommunityByKeyBatchResults{br, len(arg), false}
}

func (b *GetCommunityByKeyBatchResults) QueryRow(f func(int, Community, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Community
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.CommunityType,
			&i.Key1,
			&i.Key2,
			&i.Key3,
			&i.Key4,
			&i.Name,
			&i.OverrideName,
			&i.Description,
			&i.OverrideDescription,
			&i.ProfileImageUrl,
			&i.OverrideProfileImageUrl,
			&i.BadgeUrl,
			&i.OverrideBadgeUrl,
			&i.ContractID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.WebsiteUrl,
			&i.OverrideWebsiteUrl,
			&i.MintUrl,
			&i.OverrideMintUrl,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCommunityByKeyBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getContractByChainAddressBatch = `-- name: GetContractByChainAddressBatch :batchone
select id, deleted, version, created_at, last_updated, name, symbol, address, creator_address, chain, profile_banner_url, profile_image_url, badge_url, description, owner_address, is_provider_marked_spam, parent_id, override_creator_user_id, l1_chain FROM contracts WHERE address = $1 AND chain = $2 AND deleted = false
`

type GetContractByChainAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetContractByChainAddressBatchParams struct {
	Address persist.Address `db:"address" json:"address"`
	Chain   persist.Chain   `db:"chain" json:"chain"`
}

func (q *Queries) GetContractByChainAddressBatch(ctx context.Context, arg []GetContractByChainAddressBatchParams) *GetContractByChainAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getContractByChainAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetContractByChainAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetContractByChainAddressBatchBatchResults) QueryRow(f func(int, Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Contract
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Name,
			&i.Symbol,
			&i.Address,
			&i.CreatorAddress,
			&i.Chain,
			&i.ProfileBannerUrl,
			&i.ProfileImageUrl,
			&i.BadgeUrl,
			&i.Description,
			&i.OwnerAddress,
			&i.IsProviderMarkedSpam,
			&i.ParentID,
			&i.OverrideCreatorUserID,
			&i.L1Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetContractByChainAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getContractsDisplayedByUserIDBatch = `-- name: GetContractsDisplayedByUserIDBatch :batchmany
with last_refreshed as (
  select last_updated from owned_contracts limit 1
),
displayed as (
  select contract_id
  from owned_contracts
  where owned_contracts.user_id = $1 and displayed = true
  union
  select contracts.id
  from last_refreshed, galleries, contracts, tokens
  join collections on tokens.id = any(collections.nfts) and collections.deleted = false
  where tokens.owner_user_id = $1
    and tokens.contract_id = contracts.id
    and collections.owner_user_id = tokens.owner_user_id
    and galleries.owner_user_id = tokens.owner_user_id
    and tokens.displayable
    and tokens.deleted = false
    and galleries.deleted = false
    and contracts.deleted = false
    and galleries.last_updated > last_refreshed.last_updated
    and collections.last_updated > last_refreshed.last_updated
)
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id, contracts.l1_chain from contracts, displayed
where contracts.id = displayed.contract_id and contracts.deleted = false
`

type GetContractsDisplayedByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetContractsDisplayedByUserIDBatch(ctx context.Context, userID []persist.DBID) *GetContractsDisplayedByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range userID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getContractsDisplayedByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetContractsDisplayedByUserIDBatchBatchResults{br, len(userID), false}
}

func (b *GetContractsDisplayedByUserIDBatchBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
					&i.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetContractsDisplayedByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCreatedContractsBatchPaginate = `-- name: GetCreatedContractsBatchPaginate :batchmany
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id, contracts.l1_chain
from contracts
    join contract_creators on contracts.id = contract_creators.contract_id and contract_creators.creator_user_id = $1
where ($2::bool or contracts.chain = any(string_to_array($3, ',')::int[]))
  and (contracts.created_at, contracts.id) < ($4, $5)
  and (contracts.created_at, contracts.id) > ( $6, $7)
order by case when $8::bool then (contracts.created_at, contracts.id) end asc,
        case when not $8::bool then (contracts.created_at, contracts.id) end desc
limit $9
`

type GetCreatedContractsBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetCreatedContractsBatchPaginateParams struct {
	UserID           persist.DBID `db:"user_id" json:"user_id"`
	IncludeAllChains bool         `db:"include_all_chains" json:"include_all_chains"`
	Chains           string       `db:"chains" json:"chains"`
	CurBeforeTime    time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID      persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime     time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID       persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward    bool         `db:"paging_forward" json:"paging_forward"`
	Limit            int32        `db:"limit" json:"limit"`
}

func (q *Queries) GetCreatedContractsBatchPaginate(ctx context.Context, arg []GetCreatedContractsBatchPaginateParams) *GetCreatedContractsBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserID,
			a.IncludeAllChains,
			a.Chains,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getCreatedContractsBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCreatedContractsBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetCreatedContractsBatchPaginateBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
					&i.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCreatedContractsBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCreatorsByCommunityID = `-- name: GetCreatorsByCommunityID :batchmany
select
    cc.community_id as community_id,
    u.id as creator_user_id,
    cc.creator_address as creator_address,
    cc.creator_address_chain as creator_address_chain
    from community_creators cc
        left join wallets w on
            w.deleted = false and
            w.l1_chain = cc.creator_address_l1_chain and
            cc.creator_address = w.address
        left join users u on
            u.deleted = false and
            u.universal = false and
            (
                (cc.creator_user_id is not null and cc.creator_user_id = u.id)
                or
                (cc.creator_user_id is null and w.address is not null and array[w.id] <@ u.wallets)
            )
    where cc.community_id = $1
        and cc.deleted = false
    order by (cc.creator_type, cc.creator_user_id, cc.creator_address)
`

type GetCreatorsByCommunityIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetCreatorsByCommunityIDRow struct {
	CommunityID         persist.DBID    `db:"community_id" json:"community_id"`
	CreatorUserID       persist.DBID    `db:"creator_user_id" json:"creator_user_id"`
	CreatorAddress      persist.Address `db:"creator_address" json:"creator_address"`
	CreatorAddressChain persist.Chain   `db:"creator_address_chain" json:"creator_address_chain"`
}

func (q *Queries) GetCreatorsByCommunityID(ctx context.Context, communityID []persist.DBID) *GetCreatorsByCommunityIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range communityID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCreatorsByCommunityID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCreatorsByCommunityIDBatchResults{br, len(communityID), false}
}

func (b *GetCreatorsByCommunityIDBatchResults) Query(f func(int, []GetCreatorsByCommunityIDRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetCreatorsByCommunityIDRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetCreatorsByCommunityIDRow
				if err := rows.Scan(
					&i.CommunityID,
					&i.CreatorUserID,
					&i.CreatorAddress,
					&i.CreatorAddressChain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCreatorsByCommunityIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getEventByIdBatch = `-- name: GetEventByIdBatch :batchone
SELECT id, version, owner_id, action, data, event_time, event_ids, deleted, last_updated, created_at, caption, group_id FROM feed_events WHERE id = $1 AND deleted = false
`

type GetEventByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetEventByIdBatch(ctx context.Context, id []persist.DBID) *GetEventByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getEventByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetEventByIdBatchBatchResults{br, len(id), false}
}

func (b *GetEventByIdBatchBatchResults) QueryRow(f func(int, FeedEvent, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i FeedEvent
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.OwnerID,
			&i.Action,
			&i.Data,
			&i.EventTime,
			&i.EventIds,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Caption,
			&i.GroupID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetEventByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFollowersByUserIdBatch = `-- name: GetFollowersByUserIdBatch :batchmany
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id, u.persona FROM follows f
    INNER JOIN users u ON f.follower = u.id
    WHERE f.followee = $1 AND f.deleted = false
    ORDER BY f.last_updated DESC
`

type GetFollowersByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetFollowersByUserIdBatch(ctx context.Context, followee []persist.DBID) *GetFollowersByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range followee {
		vals := []interface{}{
			a,
		}
		batch.Queue(getFollowersByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFollowersByUserIdBatchBatchResults{br, len(followee), false}
}

func (b *GetFollowersByUserIdBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFollowersByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFollowingByUserIdBatch = `-- name: GetFollowingByUserIdBatch :batchmany
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id, u.persona FROM follows f
    INNER JOIN users u ON f.followee = u.id
    WHERE f.follower = $1 AND f.deleted = false
    ORDER BY f.last_updated DESC
`

type GetFollowingByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetFollowingByUserIdBatch(ctx context.Context, follower []persist.DBID) *GetFollowingByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range follower {
		vals := []interface{}{
			a,
		}
		batch.Queue(getFollowingByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFollowingByUserIdBatchBatchResults{br, len(follower), false}
}

func (b *GetFollowingByUserIdBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFollowingByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFrameTokensByCommunityID = `-- name: GetFrameTokensByCommunityID :batchmany
with community_data as (
    select id as community_id, community_type, contract_id
    from communities
    where communities.id = $1 and not deleted
    limit 1
)

(select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain from community_data cd
    join tokens t on t.contract_id = cd.contract_id
    join token_definitions td on t.token_definition_id = td.id
    join users u on u.id = t.owner_user_id
    join contracts c on t.contract_id = c.id
where cd.community_type = 0
    and t.displayable
    and t.deleted = false
    and c.deleted = false
    and td.deleted = false
    and u.deleted = false
    and u.universal = false
limit $2)

union all

(select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain from community_data cd, tokens t
    join token_community_memberships tcm on t.token_definition_id = tcm.token_definition_id
    join token_definitions td on td.id = t.token_definition_id
    join users u on u.id = t.owner_user_id
    join contracts c on t.contract_id = c.id
where cd.community_type != 0
    and tcm.community_id = cd.community_id
    and t.displayable
    and tcm.deleted = false
    and t.deleted = false
    and c.deleted = false
    and td.deleted = false
    and u.deleted = false
    and u.universal = false
limit $2)
`

type GetFrameTokensByCommunityIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetFrameTokensByCommunityIDParams struct {
	CommunityID persist.DBID `db:"community_id" json:"community_id"`
	Limit       int32        `db:"limit" json:"limit"`
}

type GetFrameTokensByCommunityIDRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
	Contract        Contract        `db:"contract" json:"contract"`
}

// This is a temporary query that gets tokens from a community without pagination or any specific
// ordering. It returns them very quickly, and is currently used to populate community frames.
// At present, a community is either entirely token-based or contract-based, so only
// one of these two union clauses will return any tokens (which means it's okay for each
// clause to have its own ordering). This query was originally written with a union
// of results from contract_memberships and token_memberships and a single outer
// select + join on the results of that union, but that prevented the query planner from
// using indexes correctly (since the referenced tables might be indexed, but the union
// of results is not). The current method is verbose and brittle, but it's fast!
func (q *Queries) GetFrameTokensByCommunityID(ctx context.Context, arg []GetFrameTokensByCommunityIDParams) *GetFrameTokensByCommunityIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommunityID,
			a.Limit,
		}
		batch.Queue(getFrameTokensByCommunityID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFrameTokensByCommunityIDBatchResults{br, len(arg), false}
}

func (b *GetFrameTokensByCommunityIDBatchResults) Query(f func(int, []GetFrameTokensByCommunityIDRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetFrameTokensByCommunityIDRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetFrameTokensByCommunityIDRow
				if err := rows.Scan(
					&i.Token.ID,
					&i.Token.Deleted,
					&i.Token.Version,
					&i.Token.CreatedAt,
					&i.Token.LastUpdated,
					&i.Token.CollectorsNote,
					&i.Token.Quantity,
					&i.Token.BlockNumber,
					&i.Token.OwnerUserID,
					&i.Token.OwnedByWallets,
					&i.Token.ContractID,
					&i.Token.IsUserMarkedSpam,
					&i.Token.LastSynced,
					&i.Token.IsCreatorToken,
					&i.Token.TokenDefinitionID,
					&i.Token.IsHolderToken,
					&i.Token.Displayable,
					&i.TokenDefinition.ID,
					&i.TokenDefinition.CreatedAt,
					&i.TokenDefinition.LastUpdated,
					&i.TokenDefinition.Deleted,
					&i.TokenDefinition.Name,
					&i.TokenDefinition.Description,
					&i.TokenDefinition.TokenType,
					&i.TokenDefinition.TokenID,
					&i.TokenDefinition.ExternalUrl,
					&i.TokenDefinition.Chain,
					&i.TokenDefinition.Metadata,
					&i.TokenDefinition.FallbackMedia,
					&i.TokenDefinition.ContractAddress,
					&i.TokenDefinition.ContractID,
					&i.TokenDefinition.TokenMediaID,
					&i.TokenDefinition.IsFxhash,
					&i.Contract.ID,
					&i.Contract.Deleted,
					&i.Contract.Version,
					&i.Contract.CreatedAt,
					&i.Contract.LastUpdated,
					&i.Contract.Name,
					&i.Contract.Symbol,
					&i.Contract.Address,
					&i.Contract.CreatorAddress,
					&i.Contract.Chain,
					&i.Contract.ProfileBannerUrl,
					&i.Contract.ProfileImageUrl,
					&i.Contract.BadgeUrl,
					&i.Contract.Description,
					&i.Contract.OwnerAddress,
					&i.Contract.IsProviderMarkedSpam,
					&i.Contract.ParentID,
					&i.Contract.OverrideCreatorUserID,
					&i.Contract.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFrameTokensByCommunityIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleriesByUserIdBatch = `-- name: GetGalleriesByUserIdBatch :batchmany
SELECT id, deleted, last_updated, created_at, version, owner_user_id, collections, name, description, hidden, position FROM galleries WHERE owner_user_id = $1 AND deleted = false order by position
`

type GetGalleriesByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleriesByUserIdBatch(ctx context.Context, ownerUserID []persist.DBID) *GetGalleriesByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range ownerUserID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleriesByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleriesByUserIdBatchBatchResults{br, len(ownerUserID), false}
}

func (b *GetGalleriesByUserIdBatchBatchResults) Query(f func(int, []Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Gallery
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Gallery
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Version,
					&i.OwnerUserID,
					&i.Collections,
					&i.Name,
					&i.Description,
					&i.Hidden,
					&i.Position,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetGalleriesByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleriesDisplayingCommunityIDPaginateBatch = `-- name: GetGalleriesDisplayingCommunityIDPaginateBatch :batchmany
select g.id, g.deleted, g.last_updated, g.created_at, g.version, g.owner_user_id, g.collections, g.name, g.description, g.hidden, g.position,
       cg.token_ids as community_token_ids,
       cg.token_medias as community_medias,
       cg.token_media_last_updated::timestamptz[] as community_media_last_updated,
       cg2.token_ids as all_token_ids,
       cg2.token_medias as all_medias,
       cg2.token_media_last_updated::timestamptz[] as all_media_last_updated,
       (-cg.gallery_relevance)::float8 as relevance from community_galleries cg
    join galleries g on cg.gallery_id = g.id and not g.deleted and not g.hidden
    join community_galleries cg2 on cg2.gallery_id = cg.gallery_id and cg2.community_id is null
where cg.community_id = $1
    and (cg.user_id != $2, cg.community_id, -cg.gallery_relevance, cg.gallery_id) < ($3::bool, $1, $4::float8, $5)
    and (cg.user_id != $2, cg.community_id, -cg.gallery_relevance, cg.gallery_id) > ($6::bool, $1, $7::float8, $8)
order by case when $9::bool then (cg.user_id != $2, cg.community_id, -cg.gallery_relevance, cg.gallery_id) end asc,
         case when not $9::bool then (cg.user_id != $2, cg.community_id, -cg.gallery_relevance, cg.gallery_id) end desc
limit $10
`

type GetGalleriesDisplayingCommunityIDPaginateBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetGalleriesDisplayingCommunityIDPaginateBatchParams struct {
	CommunityID                persist.DBID `db:"community_id" json:"community_id"`
	RelativeToUserID           persist.DBID `db:"relative_to_user_id" json:"relative_to_user_id"`
	CurBeforeIsNotRelativeUser bool         `db:"cur_before_is_not_relative_user" json:"cur_before_is_not_relative_user"`
	CurBeforeRelevance         float64      `db:"cur_before_relevance" json:"cur_before_relevance"`
	CurBeforeID                persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterIsNotRelativeUser  bool         `db:"cur_after_is_not_relative_user" json:"cur_after_is_not_relative_user"`
	CurAfterRelevance          float64      `db:"cur_after_relevance" json:"cur_after_relevance"`
	CurAfterID                 persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward              bool         `db:"paging_forward" json:"paging_forward"`
	Limit                      int32        `db:"limit" json:"limit"`
}

type GetGalleriesDisplayingCommunityIDPaginateBatchRow struct {
	Gallery                   Gallery           `db:"gallery" json:"gallery"`
	CommunityTokenIds         persist.DBIDList  `db:"community_token_ids" json:"community_token_ids"`
	CommunityMedias           persist.MediaList `db:"community_medias" json:"community_medias"`
	CommunityMediaLastUpdated []time.Time       `db:"community_media_last_updated" json:"community_media_last_updated"`
	AllTokenIds               persist.DBIDList  `db:"all_token_ids" json:"all_token_ids"`
	AllMedias                 persist.MediaList `db:"all_medias" json:"all_medias"`
	AllMediaLastUpdated       []time.Time       `db:"all_media_last_updated" json:"all_media_last_updated"`
	Relevance                 float64           `db:"relevance" json:"relevance"`
}

func (q *Queries) GetGalleriesDisplayingCommunityIDPaginateBatch(ctx context.Context, arg []GetGalleriesDisplayingCommunityIDPaginateBatchParams) *GetGalleriesDisplayingCommunityIDPaginateBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommunityID,
			a.RelativeToUserID,
			a.CurBeforeIsNotRelativeUser,
			a.CurBeforeRelevance,
			a.CurBeforeID,
			a.CurAfterIsNotRelativeUser,
			a.CurAfterRelevance,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getGalleriesDisplayingCommunityIDPaginateBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleriesDisplayingCommunityIDPaginateBatchBatchResults{br, len(arg), false}
}

func (b *GetGalleriesDisplayingCommunityIDPaginateBatchBatchResults) Query(f func(int, []GetGalleriesDisplayingCommunityIDPaginateBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetGalleriesDisplayingCommunityIDPaginateBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetGalleriesDisplayingCommunityIDPaginateBatchRow
				if err := rows.Scan(
					&i.Gallery.ID,
					&i.Gallery.Deleted,
					&i.Gallery.LastUpdated,
					&i.Gallery.CreatedAt,
					&i.Gallery.Version,
					&i.Gallery.OwnerUserID,
					&i.Gallery.Collections,
					&i.Gallery.Name,
					&i.Gallery.Description,
					&i.Gallery.Hidden,
					&i.Gallery.Position,
					&i.CommunityTokenIds,
					&i.CommunityMedias,
					&i.CommunityMediaLastUpdated,
					&i.AllTokenIds,
					&i.AllMedias,
					&i.AllMediaLastUpdated,
					&i.Relevance,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetGalleriesDisplayingCommunityIDPaginateBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryByCollectionIdBatch = `-- name: GetGalleryByCollectionIdBatch :batchone
SELECT g.id, g.deleted, g.last_updated, g.created_at, g.version, g.owner_user_id, g.collections, g.name, g.description, g.hidden, g.position FROM galleries g, collections c WHERE c.id = $1 AND c.deleted = false AND $1 = ANY(g.collections) AND g.deleted = false
`

type GetGalleryByCollectionIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryByCollectionIdBatch(ctx context.Context, id []persist.DBID) *GetGalleryByCollectionIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryByCollectionIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryByCollectionIdBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryByCollectionIdBatchBatchResults) QueryRow(f func(int, Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Gallery
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Version,
			&i.OwnerUserID,
			&i.Collections,
			&i.Name,
			&i.Description,
			&i.Hidden,
			&i.Position,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetGalleryByCollectionIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryByIdBatch = `-- name: GetGalleryByIdBatch :batchone
SELECT id, deleted, last_updated, created_at, version, owner_user_id, collections, name, description, hidden, position FROM galleries WHERE id = $1 AND deleted = false
`

type GetGalleryByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryByIdBatch(ctx context.Context, id []persist.DBID) *GetGalleryByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryByIdBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryByIdBatchBatchResults) QueryRow(f func(int, Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Gallery
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Version,
			&i.OwnerUserID,
			&i.Collections,
			&i.Name,
			&i.Description,
			&i.Hidden,
			&i.Position,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetGalleryByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryTokenMediasByGalleryIDBatch = `-- name: GetGalleryTokenMediasByGalleryIDBatch :batchmany
select tm.id, tm.created_at, tm.last_updated, tm.version, tm.active, tm.media, tm.processing_job_id, tm.deleted
from galleries g, collections c, tokens t, token_medias tm, token_definitions td
where
	g.id = $1
	and c.id = any(g.collections)
	and t.id = any(c.nfts)
    and t.owner_user_id = g.owner_user_id
    and t.displayable
    and t.token_definition_id = td.id
    and td.token_media_id = tm.id
    and not td.deleted
	and not g.deleted
	and not c.deleted
	and not t.deleted
	and not tm.deleted
	and (
		tm.media->>'thumbnail_url' is not null
		or ((tm.media->>'media_type' = 'image' or tm.media->>'media_type' = 'gif') and tm.media->>'media_url' is not null)
	)
order by array_position(g.collections, c.id) , array_position(c.nfts, t.id)
limit 4
`

type GetGalleryTokenMediasByGalleryIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryTokenMediasByGalleryIDBatch(ctx context.Context, id []persist.DBID) *GetGalleryTokenMediasByGalleryIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryTokenMediasByGalleryIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryTokenMediasByGalleryIDBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryTokenMediasByGalleryIDBatchBatchResults) Query(f func(int, []TokenMedia, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []TokenMedia
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i TokenMedia
				if err := rows.Scan(
					&i.ID,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Version,
					&i.Active,
					&i.Media,
					&i.ProcessingJobID,
					&i.Deleted,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetGalleryTokenMediasByGalleryIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMediaByMediaIdIgnoringStatusBatch = `-- name: GetMediaByMediaIdIgnoringStatusBatch :batchone
select m.id, m.created_at, m.last_updated, m.version, m.active, m.media, m.processing_job_id, m.deleted from token_medias m where m.id = $1 and not deleted
`

type GetMediaByMediaIdIgnoringStatusBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMediaByMediaIdIgnoringStatusBatch(ctx context.Context, id []persist.DBID) *GetMediaByMediaIdIgnoringStatusBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMediaByMediaIdIgnoringStatusBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMediaByMediaIdIgnoringStatusBatchBatchResults{br, len(id), false}
}

func (b *GetMediaByMediaIdIgnoringStatusBatchBatchResults) QueryRow(f func(int, TokenMedia, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenMedia
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Version,
			&i.Active,
			&i.Media,
			&i.ProcessingJobID,
			&i.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMediaByMediaIdIgnoringStatusBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMembershipByMembershipIdBatch = `-- name: GetMembershipByMembershipIdBatch :batchone
SELECT id, deleted, version, created_at, last_updated, token_id, name, asset_url, owners FROM membership WHERE id = $1 AND deleted = false
`

type GetMembershipByMembershipIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMembershipByMembershipIdBatch(ctx context.Context, id []persist.DBID) *GetMembershipByMembershipIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMembershipByMembershipIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMembershipByMembershipIdBatchBatchResults{br, len(id), false}
}

func (b *GetMembershipByMembershipIdBatchBatchResults) QueryRow(f func(int, Membership, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Membership
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.TokenID,
			&i.Name,
			&i.AssetUrl,
			&i.Owners,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMembershipByMembershipIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMentionsByCommentID = `-- name: GetMentionsByCommentID :batchmany
select id, post_id, comment_id, user_id, start, length, created_at, deleted, community_id from mentions where comment_id = $1 and not deleted
`

type GetMentionsByCommentIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMentionsByCommentID(ctx context.Context, commentID []persist.DBID) *GetMentionsByCommentIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range commentID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMentionsByCommentID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMentionsByCommentIDBatchResults{br, len(commentID), false}
}

func (b *GetMentionsByCommentIDBatchResults) Query(f func(int, []Mention, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Mention
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Mention
				if err := rows.Scan(
					&i.ID,
					&i.PostID,
					&i.CommentID,
					&i.UserID,
					&i.Start,
					&i.Length,
					&i.CreatedAt,
					&i.Deleted,
					&i.CommunityID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetMentionsByCommentIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMentionsByPostID = `-- name: GetMentionsByPostID :batchmany
select id, post_id, comment_id, user_id, start, length, created_at, deleted, community_id from mentions where post_id = $1 and not deleted
`

type GetMentionsByPostIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMentionsByPostID(ctx context.Context, postID []persist.DBID) *GetMentionsByPostIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMentionsByPostID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMentionsByPostIDBatchResults{br, len(postID), false}
}

func (b *GetMentionsByPostIDBatchResults) Query(f func(int, []Mention, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Mention
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Mention
				if err := rows.Scan(
					&i.ID,
					&i.PostID,
					&i.CommentID,
					&i.UserID,
					&i.Start,
					&i.Length,
					&i.CreatedAt,
					&i.Deleted,
					&i.CommunityID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetMentionsByPostIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getNewTokensByFeedEventIdBatch = `-- name: GetNewTokensByFeedEventIdBatch :batchmany
with new_tokens as (
    select added.id, row_number() over () added_order
    from (select jsonb_array_elements_text(data -> 'collection_new_token_ids') id from feed_events f where f.id = $1 and f.deleted = false) added
)
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable from new_tokens a join tokens t on a.id = t.id and t.displayable and t.deleted = false order by a.added_order
`

type GetNewTokensByFeedEventIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetNewTokensByFeedEventIdBatch(ctx context.Context, id []persist.DBID) *GetNewTokensByFeedEventIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getNewTokensByFeedEventIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetNewTokensByFeedEventIdBatchBatchResults{br, len(id), false}
}

func (b *GetNewTokensByFeedEventIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.CollectorsNote,
					&i.Quantity,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.LastSynced,
					&i.IsCreatorToken,
					&i.TokenDefinitionID,
					&i.IsHolderToken,
					&i.Displayable,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetNewTokensByFeedEventIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getNotificationByIDBatch = `-- name: GetNotificationByIDBatch :batchone
SELECT id, deleted, owner_id, version, last_updated, created_at, action, data, event_ids, feed_event_id, comment_id, gallery_id, seen, amount, post_id, token_id, mention_id, community_id, pinned FROM notifications WHERE id = $1 AND deleted = false
`

type GetNotificationByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetNotificationByIDBatch(ctx context.Context, id []persist.DBID) *GetNotificationByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getNotificationByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetNotificationByIDBatchBatchResults{br, len(id), false}
}

func (b *GetNotificationByIDBatchBatchResults) QueryRow(f func(int, Notification, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Notification
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.OwnerID,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Action,
			&i.Data,
			&i.EventIds,
			&i.FeedEventID,
			&i.CommentID,
			&i.GalleryID,
			&i.Seen,
			&i.Amount,
			&i.PostID,
			&i.TokenID,
			&i.MentionID,
			&i.CommunityID,
			&i.Pinned,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetNotificationByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getOwnersByContractIdBatchPaginate = `-- name: GetOwnersByContractIdBatchPaginate :batchmany
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id, users.persona from (
    select distinct on (u.id) u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id, u.persona from users u, tokens t, contracts c
        where t.owner_user_id = u.id
        and t.displayable
        and t.contract_id = c.id and (c.id = $1 or c.parent_id = $1)
        and (not $2::bool or u.universal = false)
        and t.deleted = false and u.deleted = false and c.deleted = false
    ) as users
    where (users.universal,users.created_at,users.id) < ($3, $4::timestamptz, $5)
    and (users.universal,users.created_at,users.id) > ($6, $7::timestamptz, $8)
    order by case when $9::bool then (users.universal,users.created_at,users.id) end asc,
         case when not $9::bool then (users.universal,users.created_at,users.id) end desc limit $10
`

type GetOwnersByContractIdBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetOwnersByContractIdBatchPaginateParams struct {
	ID                 persist.DBID  `db:"id" json:"id"`
	GalleryUsersOnly   bool          `db:"gallery_users_only" json:"gallery_users_only"`
	CurBeforeUniversal bool          `db:"cur_before_universal" json:"cur_before_universal"`
	CurBeforeTime      time.Time     `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID        persist.DBID  `db:"cur_before_id" json:"cur_before_id"`
	CurAfterUniversal  bool          `db:"cur_after_universal" json:"cur_after_universal"`
	CurAfterTime       time.Time     `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID         persist.DBID  `db:"cur_after_id" json:"cur_after_id"`
	PagingForward      bool          `db:"paging_forward" json:"paging_forward"`
	Limit              sql.NullInt32 `db:"limit" json:"limit"`
}

// Note: sqlc has trouble recognizing that the output of the "select distinct" subquery below will
//
//	return complete rows from the users table. As a workaround, aliasing the subquery to
//	"users" seems to fix the issue (along with aliasing the users table inside the subquery
//	to "u" to avoid confusion -- otherwise, sqlc creates a custom row type that includes
//	all users.* fields twice).
func (q *Queries) GetOwnersByContractIdBatchPaginate(ctx context.Context, arg []GetOwnersByContractIdBatchPaginateParams) *GetOwnersByContractIdBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.GalleryUsersOnly,
			a.CurBeforeUniversal,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterUniversal,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getOwnersByContractIdBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetOwnersByContractIdBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetOwnersByContractIdBatchPaginateBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetOwnersByContractIdBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getPostByIdBatch = `-- name: GetPostByIdBatch :batchone
SELECT id, version, token_ids, contract_ids, actor_id, caption, created_at, last_updated, deleted, is_first_post, user_mint_url FROM posts WHERE id = $1 AND deleted = false
`

type GetPostByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetPostByIdBatch(ctx context.Context, id []persist.DBID) *GetPostByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getPostByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetPostByIdBatchBatchResults{br, len(id), false}
}

func (b *GetPostByIdBatchBatchResults) QueryRow(f func(int, Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Post
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.TokenIds,
			&i.ContractIds,
			&i.ActorID,
			&i.Caption,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.IsFirstPost,
			&i.UserMintUrl,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetPostByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getPostsByIdsPaginateBatch = `-- name: GetPostsByIdsPaginateBatch :batchmany
select posts.id, posts.version, posts.token_ids, posts.contract_ids, posts.actor_id, posts.caption, posts.created_at, posts.last_updated, posts.deleted, posts.is_first_post, posts.user_mint_url
from posts
join unnest($1::varchar[]) with ordinality t(id, pos) using(id)
where not posts.deleted and t.pos > $2::int and t.pos < $3::int
order by t.pos asc
`

type GetPostsByIdsPaginateBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetPostsByIdsPaginateBatchParams struct {
	PostIds      []string `db:"post_ids" json:"post_ids"`
	CurAfterPos  int32    `db:"cur_after_pos" json:"cur_after_pos"`
	CurBeforePos int32    `db:"cur_before_pos" json:"cur_before_pos"`
}

func (q *Queries) GetPostsByIdsPaginateBatch(ctx context.Context, arg []GetPostsByIdsPaginateBatchParams) *GetPostsByIdsPaginateBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostIds,
			a.CurAfterPos,
			a.CurBeforePos,
		}
		batch.Queue(getPostsByIdsPaginateBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetPostsByIdsPaginateBatchBatchResults{br, len(arg), false}
}

func (b *GetPostsByIdsPaginateBatchBatchResults) Query(f func(int, []Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Post
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Post
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.TokenIds,
					&i.ContractIds,
					&i.ActorID,
					&i.Caption,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.IsFirstPost,
					&i.UserMintUrl,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetPostsByIdsPaginateBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getProfileImageByIdBatch = `-- name: GetProfileImageByIdBatch :batchone
select id, user_id, token_id, source_type, deleted, created_at, last_updated, wallet_id, ens_avatar_uri, ens_domain from profile_images pfp
where pfp.id = $1
	and not deleted
	and case
		when pfp.source_type = $2
		then exists(select 1 from wallets w where w.id = pfp.wallet_id and not w.deleted)
		when pfp.source_type = $3
		then exists(select 1 from tokens t where t.id = pfp.token_id and not t.deleted)
		else
		0 = 1
	end
`

type GetProfileImageByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetProfileImageByIdBatchParams struct {
	ID              persist.DBID               `db:"id" json:"id"`
	EnsSourceType   persist.ProfileImageSource `db:"ens_source_type" json:"ens_source_type"`
	TokenSourceType persist.ProfileImageSource `db:"token_source_type" json:"token_source_type"`
}

func (q *Queries) GetProfileImageByIdBatch(ctx context.Context, arg []GetProfileImageByIdBatchParams) *GetProfileImageByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.EnsSourceType,
			a.TokenSourceType,
		}
		batch.Queue(getProfileImageByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetProfileImageByIdBatchBatchResults{br, len(arg), false}
}

func (b *GetProfileImageByIdBatchBatchResults) QueryRow(f func(int, ProfileImage, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i ProfileImage
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.UserID,
			&i.TokenID,
			&i.SourceType,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.WalletID,
			&i.EnsAvatarUri,
			&i.EnsDomain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetProfileImageByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getSharedCommunitiesBatchPaginate = `-- name: GetSharedCommunitiesBatchPaginate :batchmany
select communities.id, communities.version, communities.community_type, communities.key1, communities.key2, communities.key3, communities.key4, communities.name, communities.override_name, communities.description, communities.override_description, communities.profile_image_url, communities.override_profile_image_url, communities.badge_url, communities.override_badge_url, communities.contract_id, communities.created_at, communities.last_updated, communities.deleted, communities.website_url, communities.override_website_url, communities.mint_url, communities.override_mint_url, a.displayed as displayed_by_user_a, b.displayed as displayed_by_user_b, a.owned_count
from owned_communities a, owned_communities b, communities
left join contracts on communities.contract_id = contracts.id
left join marketplace_contracts on communities.contract_id = marketplace_contracts.contract_id
where a.user_id = $1
  and b.user_id = $2
  and a.community_id = b.community_id
  and a.community_id = communities.id
  and marketplace_contracts.contract_id is null
  and communities.name != ''
  and communities.name != 'Unidentified contract'
  and (contracts.is_provider_marked_spam is null or contracts.is_provider_marked_spam = false)
  and (
    a.displayed,
    b.displayed,
    a.owned_count,
    communities.id
  ) > (
    $3,
    $4,
    $5::int,
    $6
  )
  and (
    a.displayed,
    b.displayed,
    a.owned_count,
    communities.id
  ) < (
    $7,
    $8,
    $9::int,
    $10
  )
order by case when $11::bool then (a.displayed, b.displayed, a.owned_count, communities.id) end desc,
        case when not $11::bool then (a.displayed, b.displayed, a.owned_count, communities.id) end asc
limit $12
`

type GetSharedCommunitiesBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetSharedCommunitiesBatchPaginateParams struct {
	UserAID                   persist.DBID `db:"user_a_id" json:"user_a_id"`
	UserBID                   persist.DBID `db:"user_b_id" json:"user_b_id"`
	CurBeforeDisplayedByUserA bool         `db:"cur_before_displayed_by_user_a" json:"cur_before_displayed_by_user_a"`
	CurBeforeDisplayedByUserB bool         `db:"cur_before_displayed_by_user_b" json:"cur_before_displayed_by_user_b"`
	CurBeforeOwnedCount       int32        `db:"cur_before_owned_count" json:"cur_before_owned_count"`
	CurBeforeContractID       persist.DBID `db:"cur_before_contract_id" json:"cur_before_contract_id"`
	CurAfterDisplayedByUserA  bool         `db:"cur_after_displayed_by_user_a" json:"cur_after_displayed_by_user_a"`
	CurAfterDisplayedByUserB  bool         `db:"cur_after_displayed_by_user_b" json:"cur_after_displayed_by_user_b"`
	CurAfterOwnedCount        int32        `db:"cur_after_owned_count" json:"cur_after_owned_count"`
	CurAfterContractID        persist.DBID `db:"cur_after_contract_id" json:"cur_after_contract_id"`
	PagingForward             bool         `db:"paging_forward" json:"paging_forward"`
	Limit                     int32        `db:"limit" json:"limit"`
}

type GetSharedCommunitiesBatchPaginateRow struct {
	Community        Community `db:"community" json:"community"`
	DisplayedByUserA bool      `db:"displayed_by_user_a" json:"displayed_by_user_a"`
	DisplayedByUserB bool      `db:"displayed_by_user_b" json:"displayed_by_user_b"`
	OwnedCount       int64     `db:"owned_count" json:"owned_count"`
}

func (q *Queries) GetSharedCommunitiesBatchPaginate(ctx context.Context, arg []GetSharedCommunitiesBatchPaginateParams) *GetSharedCommunitiesBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserAID,
			a.UserBID,
			a.CurBeforeDisplayedByUserA,
			a.CurBeforeDisplayedByUserB,
			a.CurBeforeOwnedCount,
			a.CurBeforeContractID,
			a.CurAfterDisplayedByUserA,
			a.CurAfterDisplayedByUserB,
			a.CurAfterOwnedCount,
			a.CurAfterContractID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getSharedCommunitiesBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetSharedCommunitiesBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetSharedCommunitiesBatchPaginateBatchResults) Query(f func(int, []GetSharedCommunitiesBatchPaginateRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetSharedCommunitiesBatchPaginateRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetSharedCommunitiesBatchPaginateRow
				if err := rows.Scan(
					&i.Community.ID,
					&i.Community.Version,
					&i.Community.CommunityType,
					&i.Community.Key1,
					&i.Community.Key2,
					&i.Community.Key3,
					&i.Community.Key4,
					&i.Community.Name,
					&i.Community.OverrideName,
					&i.Community.Description,
					&i.Community.OverrideDescription,
					&i.Community.ProfileImageUrl,
					&i.Community.OverrideProfileImageUrl,
					&i.Community.BadgeUrl,
					&i.Community.OverrideBadgeUrl,
					&i.Community.ContractID,
					&i.Community.CreatedAt,
					&i.Community.LastUpdated,
					&i.Community.Deleted,
					&i.Community.WebsiteUrl,
					&i.Community.OverrideWebsiteUrl,
					&i.Community.MintUrl,
					&i.Community.OverrideMintUrl,
					&i.DisplayedByUserA,
					&i.DisplayedByUserB,
					&i.OwnedCount,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetSharedCommunitiesBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getSharedFollowersBatchPaginate = `-- name: GetSharedFollowersBatchPaginate :batchmany
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id, users.persona, a.created_at followed_on
from users, follows a, follows b
where a.follower = $1
	and a.followee = b.follower
	and b.followee = $2
	and users.id = b.follower
	and a.deleted = false
	and b.deleted = false
	and users.deleted = false
  and (a.created_at, users.id) > ($3, $4)
  and (a.created_at, users.id) < ($5, $6)
order by case when $7::bool then (a.created_at, users.id) end desc,
        case when not $7::bool then (a.created_at, users.id) end asc
limit $8
`

type GetSharedFollowersBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetSharedFollowersBatchPaginateParams struct {
	Follower      persist.DBID `db:"follower" json:"follower"`
	Followee      persist.DBID `db:"followee" json:"followee"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

type GetSharedFollowersBatchPaginateRow struct {
	User       User      `db:"user" json:"user"`
	FollowedOn time.Time `db:"followed_on" json:"followed_on"`
}

func (q *Queries) GetSharedFollowersBatchPaginate(ctx context.Context, arg []GetSharedFollowersBatchPaginateParams) *GetSharedFollowersBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Follower,
			a.Followee,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getSharedFollowersBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetSharedFollowersBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetSharedFollowersBatchPaginateBatchResults) Query(f func(int, []GetSharedFollowersBatchPaginateRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetSharedFollowersBatchPaginateRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetSharedFollowersBatchPaginateRow
				if err := rows.Scan(
					&i.User.ID,
					&i.User.Deleted,
					&i.User.Version,
					&i.User.LastUpdated,
					&i.User.CreatedAt,
					&i.User.Username,
					&i.User.UsernameIdempotent,
					&i.User.Wallets,
					&i.User.Bio,
					&i.User.Traits,
					&i.User.Universal,
					&i.User.NotificationSettings,
					&i.User.EmailUnsubscriptions,
					&i.User.FeaturedGallery,
					&i.User.PrimaryWalletID,
					&i.User.UserExperiences,
					&i.User.ProfileImageID,
					&i.User.Persona,
					&i.FollowedOn,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetSharedFollowersBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByIdBatch = `-- name: GetTokenByIdBatch :batchone
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash
from tokens t
join token_definitions td on t.token_definition_id = td.id
where t.id = $1 and t.displayable and t.deleted = false and td.deleted = false
`

type GetTokenByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokenByIdBatchRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
}

func (q *Queries) GetTokenByIdBatch(ctx context.Context, id []persist.DBID) *GetTokenByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByIdBatchBatchResults{br, len(id), false}
}

func (b *GetTokenByIdBatchBatchResults) QueryRow(f func(int, GetTokenByIdBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i GetTokenByIdBatchRow
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.Token.ID,
			&i.Token.Deleted,
			&i.Token.Version,
			&i.Token.CreatedAt,
			&i.Token.LastUpdated,
			&i.Token.CollectorsNote,
			&i.Token.Quantity,
			&i.Token.BlockNumber,
			&i.Token.OwnerUserID,
			&i.Token.OwnedByWallets,
			&i.Token.ContractID,
			&i.Token.IsUserMarkedSpam,
			&i.Token.LastSynced,
			&i.Token.IsCreatorToken,
			&i.Token.TokenDefinitionID,
			&i.Token.IsHolderToken,
			&i.Token.Displayable,
			&i.TokenDefinition.ID,
			&i.TokenDefinition.CreatedAt,
			&i.TokenDefinition.LastUpdated,
			&i.TokenDefinition.Deleted,
			&i.TokenDefinition.Name,
			&i.TokenDefinition.Description,
			&i.TokenDefinition.TokenType,
			&i.TokenDefinition.TokenID,
			&i.TokenDefinition.ExternalUrl,
			&i.TokenDefinition.Chain,
			&i.TokenDefinition.Metadata,
			&i.TokenDefinition.FallbackMedia,
			&i.TokenDefinition.ContractAddress,
			&i.TokenDefinition.ContractID,
			&i.TokenDefinition.TokenMediaID,
			&i.TokenDefinition.IsFxhash,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByIdIgnoreDisplayableBatch = `-- name: GetTokenByIdIgnoreDisplayableBatch :batchone
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash
from tokens t
join token_definitions td on t.token_definition_id = td.id
where t.id = $1 and t.deleted = false and td.deleted = false
`

type GetTokenByIdIgnoreDisplayableBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokenByIdIgnoreDisplayableBatchRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
}

func (q *Queries) GetTokenByIdIgnoreDisplayableBatch(ctx context.Context, id []persist.DBID) *GetTokenByIdIgnoreDisplayableBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenByIdIgnoreDisplayableBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByIdIgnoreDisplayableBatchBatchResults{br, len(id), false}
}

func (b *GetTokenByIdIgnoreDisplayableBatchBatchResults) QueryRow(f func(int, GetTokenByIdIgnoreDisplayableBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i GetTokenByIdIgnoreDisplayableBatchRow
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.Token.ID,
			&i.Token.Deleted,
			&i.Token.Version,
			&i.Token.CreatedAt,
			&i.Token.LastUpdated,
			&i.Token.CollectorsNote,
			&i.Token.Quantity,
			&i.Token.BlockNumber,
			&i.Token.OwnerUserID,
			&i.Token.OwnedByWallets,
			&i.Token.ContractID,
			&i.Token.IsUserMarkedSpam,
			&i.Token.LastSynced,
			&i.Token.IsCreatorToken,
			&i.Token.TokenDefinitionID,
			&i.Token.IsHolderToken,
			&i.Token.Displayable,
			&i.TokenDefinition.ID,
			&i.TokenDefinition.CreatedAt,
			&i.TokenDefinition.LastUpdated,
			&i.TokenDefinition.Deleted,
			&i.TokenDefinition.Name,
			&i.TokenDefinition.Description,
			&i.TokenDefinition.TokenType,
			&i.TokenDefinition.TokenID,
			&i.TokenDefinition.ExternalUrl,
			&i.TokenDefinition.Chain,
			&i.TokenDefinition.Metadata,
			&i.TokenDefinition.FallbackMedia,
			&i.TokenDefinition.ContractAddress,
			&i.TokenDefinition.ContractID,
			&i.TokenDefinition.TokenMediaID,
			&i.TokenDefinition.IsFxhash,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByIdIgnoreDisplayableBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByUserTokenIdentifiersBatch = `-- name: GetTokenByUserTokenIdentifiersBatch :batchone
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain
from tokens t, token_definitions td, contracts c
where t.token_definition_id = td.id
    and td.contract_id = c.id
    and t.owner_user_id = $1
    and td.token_id = $2
    and td.chain = $3
    and td.contract_address = $4
    and t.displayable
    and not t.deleted
    and not td.deleted
    and not c.deleted
`

type GetTokenByUserTokenIdentifiersBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokenByUserTokenIdentifiersBatchParams struct {
	OwnerID         persist.DBID       `db:"owner_id" json:"owner_id"`
	TokenID         persist.HexTokenID `db:"token_id" json:"token_id"`
	Chain           persist.Chain      `db:"chain" json:"chain"`
	ContractAddress persist.Address    `db:"contract_address" json:"contract_address"`
}

type GetTokenByUserTokenIdentifiersBatchRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
	Contract        Contract        `db:"contract" json:"contract"`
}

// Fetch the definition and contract to cache since downstream queries will likely use them
func (q *Queries) GetTokenByUserTokenIdentifiersBatch(ctx context.Context, arg []GetTokenByUserTokenIdentifiersBatchParams) *GetTokenByUserTokenIdentifiersBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerID,
			a.TokenID,
			a.Chain,
			a.ContractAddress,
		}
		batch.Queue(getTokenByUserTokenIdentifiersBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByUserTokenIdentifiersBatchBatchResults{br, len(arg), false}
}

func (b *GetTokenByUserTokenIdentifiersBatchBatchResults) QueryRow(f func(int, GetTokenByUserTokenIdentifiersBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i GetTokenByUserTokenIdentifiersBatchRow
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.Token.ID,
			&i.Token.Deleted,
			&i.Token.Version,
			&i.Token.CreatedAt,
			&i.Token.LastUpdated,
			&i.Token.CollectorsNote,
			&i.Token.Quantity,
			&i.Token.BlockNumber,
			&i.Token.OwnerUserID,
			&i.Token.OwnedByWallets,
			&i.Token.ContractID,
			&i.Token.IsUserMarkedSpam,
			&i.Token.LastSynced,
			&i.Token.IsCreatorToken,
			&i.Token.TokenDefinitionID,
			&i.Token.IsHolderToken,
			&i.Token.Displayable,
			&i.TokenDefinition.ID,
			&i.TokenDefinition.CreatedAt,
			&i.TokenDefinition.LastUpdated,
			&i.TokenDefinition.Deleted,
			&i.TokenDefinition.Name,
			&i.TokenDefinition.Description,
			&i.TokenDefinition.TokenType,
			&i.TokenDefinition.TokenID,
			&i.TokenDefinition.ExternalUrl,
			&i.TokenDefinition.Chain,
			&i.TokenDefinition.Metadata,
			&i.TokenDefinition.FallbackMedia,
			&i.TokenDefinition.ContractAddress,
			&i.TokenDefinition.ContractID,
			&i.TokenDefinition.TokenMediaID,
			&i.TokenDefinition.IsFxhash,
			&i.Contract.ID,
			&i.Contract.Deleted,
			&i.Contract.Version,
			&i.Contract.CreatedAt,
			&i.Contract.LastUpdated,
			&i.Contract.Name,
			&i.Contract.Symbol,
			&i.Contract.Address,
			&i.Contract.CreatorAddress,
			&i.Contract.Chain,
			&i.Contract.ProfileBannerUrl,
			&i.Contract.ProfileImageUrl,
			&i.Contract.BadgeUrl,
			&i.Contract.Description,
			&i.Contract.OwnerAddress,
			&i.Contract.IsProviderMarkedSpam,
			&i.Contract.ParentID,
			&i.Contract.OverrideCreatorUserID,
			&i.Contract.L1Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByUserTokenIdentifiersBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByUserTokenIdentifiersIgnoreDisplayableBatch = `-- name: GetTokenByUserTokenIdentifiersIgnoreDisplayableBatch :batchone
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain, tm.id, tm.created_at, tm.last_updated, tm.version, tm.active, tm.media, tm.processing_job_id, tm.deleted
from tokens t, token_definitions td, contracts c, token_medias tm
where t.token_definition_id = td.id
    and td.contract_id = c.id
    and t.owner_user_id = $1
    and td.token_id = $2
    and td.chain = $3
    and td.contract_address = $4
    and td.token_media_id = tm.id
    and not t.deleted
    and not td.deleted
    and not c.deleted
    and not tm.deleted
`

type GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchParams struct {
	OwnerID         persist.DBID       `db:"owner_id" json:"owner_id"`
	TokenID         persist.HexTokenID `db:"token_id" json:"token_id"`
	Chain           persist.Chain      `db:"chain" json:"chain"`
	ContractAddress persist.Address    `db:"contract_address" json:"contract_address"`
}

type GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
	Contract        Contract        `db:"contract" json:"contract"`
	TokenMedia      TokenMedia      `db:"tokenmedia" json:"tokenmedia"`
}

func (q *Queries) GetTokenByUserTokenIdentifiersIgnoreDisplayableBatch(ctx context.Context, arg []GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchParams) *GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerID,
			a.TokenID,
			a.Chain,
			a.ContractAddress,
		}
		batch.Queue(getTokenByUserTokenIdentifiersIgnoreDisplayableBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchBatchResults{br, len(arg), false}
}

func (b *GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchBatchResults) QueryRow(f func(int, GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchRow
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.Token.ID,
			&i.Token.Deleted,
			&i.Token.Version,
			&i.Token.CreatedAt,
			&i.Token.LastUpdated,
			&i.Token.CollectorsNote,
			&i.Token.Quantity,
			&i.Token.BlockNumber,
			&i.Token.OwnerUserID,
			&i.Token.OwnedByWallets,
			&i.Token.ContractID,
			&i.Token.IsUserMarkedSpam,
			&i.Token.LastSynced,
			&i.Token.IsCreatorToken,
			&i.Token.TokenDefinitionID,
			&i.Token.IsHolderToken,
			&i.Token.Displayable,
			&i.TokenDefinition.ID,
			&i.TokenDefinition.CreatedAt,
			&i.TokenDefinition.LastUpdated,
			&i.TokenDefinition.Deleted,
			&i.TokenDefinition.Name,
			&i.TokenDefinition.Description,
			&i.TokenDefinition.TokenType,
			&i.TokenDefinition.TokenID,
			&i.TokenDefinition.ExternalUrl,
			&i.TokenDefinition.Chain,
			&i.TokenDefinition.Metadata,
			&i.TokenDefinition.FallbackMedia,
			&i.TokenDefinition.ContractAddress,
			&i.TokenDefinition.ContractID,
			&i.TokenDefinition.TokenMediaID,
			&i.TokenDefinition.IsFxhash,
			&i.Contract.ID,
			&i.Contract.Deleted,
			&i.Contract.Version,
			&i.Contract.CreatedAt,
			&i.Contract.LastUpdated,
			&i.Contract.Name,
			&i.Contract.Symbol,
			&i.Contract.Address,
			&i.Contract.CreatorAddress,
			&i.Contract.Chain,
			&i.Contract.ProfileBannerUrl,
			&i.Contract.ProfileImageUrl,
			&i.Contract.BadgeUrl,
			&i.Contract.Description,
			&i.Contract.OwnerAddress,
			&i.Contract.IsProviderMarkedSpam,
			&i.Contract.ParentID,
			&i.Contract.OverrideCreatorUserID,
			&i.Contract.L1Chain,
			&i.TokenMedia.ID,
			&i.TokenMedia.CreatedAt,
			&i.TokenMedia.LastUpdated,
			&i.TokenMedia.Version,
			&i.TokenMedia.Active,
			&i.TokenMedia.Media,
			&i.TokenMedia.ProcessingJobID,
			&i.TokenMedia.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByUserTokenIdentifiersIgnoreDisplayableBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenDefinitionByIdBatch = `-- name: GetTokenDefinitionByIdBatch :batchone
select id, created_at, last_updated, deleted, name, description, token_type, token_id, external_url, chain, metadata, fallback_media, contract_address, contract_id, token_media_id, is_fxhash from token_definitions where id = $1 and not deleted
`

type GetTokenDefinitionByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenDefinitionByIdBatch(ctx context.Context, id []persist.DBID) *GetTokenDefinitionByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenDefinitionByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenDefinitionByIdBatchBatchResults{br, len(id), false}
}

func (b *GetTokenDefinitionByIdBatchBatchResults) QueryRow(f func(int, TokenDefinition, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenDefinition
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Name,
			&i.Description,
			&i.TokenType,
			&i.TokenID,
			&i.ExternalUrl,
			&i.Chain,
			&i.Metadata,
			&i.FallbackMedia,
			&i.ContractAddress,
			&i.ContractID,
			&i.TokenMediaID,
			&i.IsFxhash,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenDefinitionByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenDefinitionByTokenDbidBatch = `-- name: GetTokenDefinitionByTokenDbidBatch :batchone
select token_definitions.id, token_definitions.created_at, token_definitions.last_updated, token_definitions.deleted, token_definitions.name, token_definitions.description, token_definitions.token_type, token_definitions.token_id, token_definitions.external_url, token_definitions.chain, token_definitions.metadata, token_definitions.fallback_media, token_definitions.contract_address, token_definitions.contract_id, token_definitions.token_media_id, token_definitions.is_fxhash
from token_definitions, tokens
where token_definitions.id = tokens.token_definition_id
    and tokens.id = $1
    and not tokens.deleted
    and not token_definitions.deleted
`

type GetTokenDefinitionByTokenDbidBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenDefinitionByTokenDbidBatch(ctx context.Context, id []persist.DBID) *GetTokenDefinitionByTokenDbidBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenDefinitionByTokenDbidBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenDefinitionByTokenDbidBatchBatchResults{br, len(id), false}
}

func (b *GetTokenDefinitionByTokenDbidBatchBatchResults) QueryRow(f func(int, TokenDefinition, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenDefinition
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Name,
			&i.Description,
			&i.TokenType,
			&i.TokenID,
			&i.ExternalUrl,
			&i.Chain,
			&i.Metadata,
			&i.FallbackMedia,
			&i.ContractAddress,
			&i.ContractID,
			&i.TokenMediaID,
			&i.IsFxhash,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenDefinitionByTokenDbidBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByCollectionIdBatch = `-- name: GetTokensByCollectionIdBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable from collections c,
    unnest(c.nfts) with ordinality as u(nft_id, nft_ord)
    join tokens t on t.id = u.nft_id
    where c.id = $1
      and c.owner_user_id = t.owner_user_id
      and t.displayable
      and c.deleted = false
      and t.deleted = false
    order by u.nft_ord
    limit $2
`

type GetTokensByCollectionIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByCollectionIdBatchParams struct {
	CollectionID persist.DBID  `db:"collection_id" json:"collection_id"`
	Limit        sql.NullInt32 `db:"limit" json:"limit"`
}

func (q *Queries) GetTokensByCollectionIdBatch(ctx context.Context, arg []GetTokensByCollectionIdBatchParams) *GetTokensByCollectionIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CollectionID,
			a.Limit,
		}
		batch.Queue(getTokensByCollectionIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByCollectionIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByCollectionIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.CollectorsNote,
					&i.Quantity,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.LastSynced,
					&i.IsCreatorToken,
					&i.TokenDefinitionID,
					&i.IsHolderToken,
					&i.Displayable,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByCollectionIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByUserIdBatch = `-- name: GetTokensByUserIdBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain
from tokens t
join token_definitions td on t.token_definition_id = td.id
join contracts c on c.id = td.contract_id
where t.owner_user_id = $1
    and t.deleted = false
    and t.displayable
    and (($2::bool and t.is_holder_token) or ($3::bool and t.is_creator_token))
    and td.deleted = false
    and c.deleted = false
order by t.created_at desc, td.name desc, t.id desc
`

type GetTokensByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByUserIdBatchParams struct {
	OwnerUserID    persist.DBID `db:"owner_user_id" json:"owner_user_id"`
	IncludeHolder  bool         `db:"include_holder" json:"include_holder"`
	IncludeCreator bool         `db:"include_creator" json:"include_creator"`
}

type GetTokensByUserIdBatchRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
	Contract        Contract        `db:"contract" json:"contract"`
}

func (q *Queries) GetTokensByUserIdBatch(ctx context.Context, arg []GetTokensByUserIdBatchParams) *GetTokensByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerUserID,
			a.IncludeHolder,
			a.IncludeCreator,
		}
		batch.Queue(getTokensByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByUserIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByUserIdBatchBatchResults) Query(f func(int, []GetTokensByUserIdBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetTokensByUserIdBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetTokensByUserIdBatchRow
				if err := rows.Scan(
					&i.Token.ID,
					&i.Token.Deleted,
					&i.Token.Version,
					&i.Token.CreatedAt,
					&i.Token.LastUpdated,
					&i.Token.CollectorsNote,
					&i.Token.Quantity,
					&i.Token.BlockNumber,
					&i.Token.OwnerUserID,
					&i.Token.OwnedByWallets,
					&i.Token.ContractID,
					&i.Token.IsUserMarkedSpam,
					&i.Token.LastSynced,
					&i.Token.IsCreatorToken,
					&i.Token.TokenDefinitionID,
					&i.Token.IsHolderToken,
					&i.Token.Displayable,
					&i.TokenDefinition.ID,
					&i.TokenDefinition.CreatedAt,
					&i.TokenDefinition.LastUpdated,
					&i.TokenDefinition.Deleted,
					&i.TokenDefinition.Name,
					&i.TokenDefinition.Description,
					&i.TokenDefinition.TokenType,
					&i.TokenDefinition.TokenID,
					&i.TokenDefinition.ExternalUrl,
					&i.TokenDefinition.Chain,
					&i.TokenDefinition.Metadata,
					&i.TokenDefinition.FallbackMedia,
					&i.TokenDefinition.ContractAddress,
					&i.TokenDefinition.ContractID,
					&i.TokenDefinition.TokenMediaID,
					&i.TokenDefinition.IsFxhash,
					&i.Contract.ID,
					&i.Contract.Deleted,
					&i.Contract.Version,
					&i.Contract.CreatedAt,
					&i.Contract.LastUpdated,
					&i.Contract.Name,
					&i.Contract.Symbol,
					&i.Contract.Address,
					&i.Contract.CreatorAddress,
					&i.Contract.Chain,
					&i.Contract.ProfileBannerUrl,
					&i.Contract.ProfileImageUrl,
					&i.Contract.BadgeUrl,
					&i.Contract.Description,
					&i.Contract.OwnerAddress,
					&i.Contract.IsProviderMarkedSpam,
					&i.Contract.ParentID,
					&i.Contract.OverrideCreatorUserID,
					&i.Contract.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByWalletIdsBatch = `-- name: GetTokensByWalletIdsBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.deleted, td.version, td.created_at, td.last_updated, td.collectors_note, td.quantity, td.block_number, td.owner_user_id, td.owned_by_wallets, td.contract_id, td.is_user_marked_spam, td.last_synced, td.is_creator_token, td.token_definition_id, td.is_holder_token, td.displayable
from tokens t
join tokens td on t.token_definition_id = td.id
where t.owned_by_wallets && $1 and t.displayable and t.deleted = false and td.deleted = false
order by t.created_at desc, td.name desc, t.id desc
`

type GetTokensByWalletIdsBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByWalletIdsBatchRow struct {
	Token   Token `db:"token" json:"token"`
	Token_2 Token `db:"token_2" json:"token_2"`
}

func (q *Queries) GetTokensByWalletIdsBatch(ctx context.Context, ownedByWallets []persist.DBIDList) *GetTokensByWalletIdsBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range ownedByWallets {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokensByWalletIdsBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByWalletIdsBatchBatchResults{br, len(ownedByWallets), false}
}

func (b *GetTokensByWalletIdsBatchBatchResults) Query(f func(int, []GetTokensByWalletIdsBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetTokensByWalletIdsBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetTokensByWalletIdsBatchRow
				if err := rows.Scan(
					&i.Token.ID,
					&i.Token.Deleted,
					&i.Token.Version,
					&i.Token.CreatedAt,
					&i.Token.LastUpdated,
					&i.Token.CollectorsNote,
					&i.Token.Quantity,
					&i.Token.BlockNumber,
					&i.Token.OwnerUserID,
					&i.Token.OwnedByWallets,
					&i.Token.ContractID,
					&i.Token.IsUserMarkedSpam,
					&i.Token.LastSynced,
					&i.Token.IsCreatorToken,
					&i.Token.TokenDefinitionID,
					&i.Token.IsHolderToken,
					&i.Token.Displayable,
					&i.Token_2.ID,
					&i.Token_2.Deleted,
					&i.Token_2.Version,
					&i.Token_2.CreatedAt,
					&i.Token_2.LastUpdated,
					&i.Token_2.CollectorsNote,
					&i.Token_2.Quantity,
					&i.Token_2.BlockNumber,
					&i.Token_2.OwnerUserID,
					&i.Token_2.OwnedByWallets,
					&i.Token_2.ContractID,
					&i.Token_2.IsUserMarkedSpam,
					&i.Token_2.LastSynced,
					&i.Token_2.IsCreatorToken,
					&i.Token_2.TokenDefinitionID,
					&i.Token_2.IsHolderToken,
					&i.Token_2.Displayable,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByWalletIdsBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByAddressAndL1Batch = `-- name: GetUserByAddressAndL1Batch :batchone
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id, users.persona
from users, wallets
where wallets.address = $1
	and wallets.l1_chain = $2
	and array[wallets.id] <@ users.wallets
	and wallets.deleted = false
	and users.deleted = false
`

type GetUserByAddressAndL1BatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUserByAddressAndL1BatchParams struct {
	Address persist.Address `db:"address" json:"address"`
	L1Chain persist.L1Chain `db:"l1_chain" json:"l1_chain"`
}

func (q *Queries) GetUserByAddressAndL1Batch(ctx context.Context, arg []GetUserByAddressAndL1BatchParams) *GetUserByAddressAndL1BatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.L1Chain,
		}
		batch.Queue(getUserByAddressAndL1Batch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByAddressAndL1BatchBatchResults{br, len(arg), false}
}

func (b *GetUserByAddressAndL1BatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
			&i.Persona,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByAddressAndL1BatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByIdBatch = `-- name: GetUserByIdBatch :batchone
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id, persona FROM users WHERE id = $1 AND deleted = false
`

type GetUserByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUserByIdBatch(ctx context.Context, id []persist.DBID) *GetUserByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUserByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByIdBatchBatchResults{br, len(id), false}
}

func (b *GetUserByIdBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
			&i.Persona,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByUsernameBatch = `-- name: GetUserByUsernameBatch :batchone
select id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id, persona from users where username_idempotent = lower($1) and deleted = false and universal = false
`

type GetUserByUsernameBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUserByUsernameBatch(ctx context.Context, lower []string) *GetUserByUsernameBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range lower {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUserByUsernameBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByUsernameBatchBatchResults{br, len(lower), false}
}

func (b *GetUserByUsernameBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
			&i.Persona,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByUsernameBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserNotificationsBatch = `-- name: GetUserNotificationsBatch :batchmany
SELECT id, deleted, owner_id, version, last_updated, created_at, action, data, event_ids, feed_event_id, comment_id, gallery_id, seen, amount, post_id, token_id, mention_id, community_id, pinned FROM notifications WHERE owner_id = $1 AND deleted = false
    AND (last_updated, id) < ($2, $3)
    AND (last_updated, id) > ($4, $5)
    ORDER BY pinned DESC,
        CASE WHEN $6::bool THEN (last_updated, id) END ASC,
        CASE WHEN NOT $6::bool THEN (last_updated, id) END DESC
    LIMIT $7
`

type GetUserNotificationsBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUserNotificationsBatchParams struct {
	OwnerID       persist.DBID `db:"owner_id" json:"owner_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) GetUserNotificationsBatch(ctx context.Context, arg []GetUserNotificationsBatchParams) *GetUserNotificationsBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getUserNotificationsBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserNotificationsBatchBatchResults{br, len(arg), false}
}

func (b *GetUserNotificationsBatchBatchResults) Query(f func(int, []Notification, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Notification
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Notification
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerID,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Action,
					&i.Data,
					&i.EventIds,
					&i.FeedEventID,
					&i.CommentID,
					&i.GalleryID,
					&i.Seen,
					&i.Amount,
					&i.PostID,
					&i.TokenID,
					&i.MentionID,
					&i.CommunityID,
					&i.Pinned,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUserNotificationsBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUsersByPositionPaginateBatch = `-- name: GetUsersByPositionPaginateBatch :batchmany
select u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id, u.persona
from users u
join unnest($1::varchar[]) with ordinality t(id, pos) using(id)
where not u.deleted and not u.universal and t.pos > $2::int and t.pos < $3::int
order by t.pos asc
`

type GetUsersByPositionPaginateBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUsersByPositionPaginateBatchParams struct {
	UserIds      []string `db:"user_ids" json:"user_ids"`
	CurAfterPos  int32    `db:"cur_after_pos" json:"cur_after_pos"`
	CurBeforePos int32    `db:"cur_before_pos" json:"cur_before_pos"`
}

func (q *Queries) GetUsersByPositionPaginateBatch(ctx context.Context, arg []GetUsersByPositionPaginateBatchParams) *GetUsersByPositionPaginateBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserIds,
			a.CurAfterPos,
			a.CurBeforePos,
		}
		batch.Queue(getUsersByPositionPaginateBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUsersByPositionPaginateBatchBatchResults{br, len(arg), false}
}

func (b *GetUsersByPositionPaginateBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUsersByPositionPaginateBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUsersByPositionPersonalizedBatch = `-- name: GetUsersByPositionPersonalizedBatch :batchmany
select u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id, u.persona
from users u
join unnest($1::varchar[]) with ordinality t(id, pos) using(id)
left join follows on follows.follower = $2 and follows.followee = u.id
where not u.deleted and not u.universal and follows.id is null
order by t.pos
limit 100
`

type GetUsersByPositionPersonalizedBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUsersByPositionPersonalizedBatchParams struct {
	UserIds  []string     `db:"user_ids" json:"user_ids"`
	ViewerID persist.DBID `db:"viewer_id" json:"viewer_id"`
}

func (q *Queries) GetUsersByPositionPersonalizedBatch(ctx context.Context, arg []GetUsersByPositionPersonalizedBatchParams) *GetUsersByPositionPersonalizedBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserIds,
			a.ViewerID,
		}
		batch.Queue(getUsersByPositionPersonalizedBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUsersByPositionPersonalizedBatchBatchResults{br, len(arg), false}
}

func (b *GetUsersByPositionPersonalizedBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUsersByPositionPersonalizedBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUsersWithTraitBatch = `-- name: GetUsersWithTraitBatch :batchmany
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id, persona FROM users WHERE (traits->$1::string) IS NOT NULL AND deleted = false
`

type GetUsersWithTraitBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUsersWithTraitBatch(ctx context.Context, dollar_1 []string) *GetUsersWithTraitBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range dollar_1 {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUsersWithTraitBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUsersWithTraitBatchBatchResults{br, len(dollar_1), false}
}

func (b *GetUsersWithTraitBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUsersWithTraitBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getVisibleCollectionsByIDsPaginateBatch = `-- name: GetVisibleCollectionsByIDsPaginateBatch :batchmany
select collections.id, collections.deleted, collections.owner_user_id, collections.nfts, collections.version, collections.last_updated, collections.created_at, collections.hidden, collections.collectors_note, collections.name, collections.layout, collections.token_settings, collections.gallery_id
from collections, unnest($1::varchar[]) with ordinality as t(id, pos)
where collections.id = t.id and not deleted and not hidden and t.pos > $2::int and t.pos < $3::int
order by t.pos asc
`

type GetVisibleCollectionsByIDsPaginateBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetVisibleCollectionsByIDsPaginateBatchParams struct {
	CollectionIds []string `db:"collection_ids" json:"collection_ids"`
	CurAfterPos   int32    `db:"cur_after_pos" json:"cur_after_pos"`
	CurBeforePos  int32    `db:"cur_before_pos" json:"cur_before_pos"`
}

func (q *Queries) GetVisibleCollectionsByIDsPaginateBatch(ctx context.Context, arg []GetVisibleCollectionsByIDsPaginateBatchParams) *GetVisibleCollectionsByIDsPaginateBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CollectionIds,
			a.CurAfterPos,
			a.CurBeforePos,
		}
		batch.Queue(getVisibleCollectionsByIDsPaginateBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetVisibleCollectionsByIDsPaginateBatchBatchResults{br, len(arg), false}
}

func (b *GetVisibleCollectionsByIDsPaginateBatchBatchResults) Query(f func(int, []Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Collection
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Collection
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerUserID,
					&i.Nfts,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Hidden,
					&i.CollectorsNote,
					&i.Name,
					&i.Layout,
					&i.TokenSettings,
					&i.GalleryID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetVisibleCollectionsByIDsPaginateBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletByIDBatch = `-- name: GetWalletByIDBatch :batchone
SELECT id, created_at, last_updated, deleted, version, address, wallet_type, chain, l1_chain FROM wallets WHERE id = $1 AND deleted = false
`

type GetWalletByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetWalletByIDBatch(ctx context.Context, id []persist.DBID) *GetWalletByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getWalletByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletByIDBatchBatchResults{br, len(id), false}
}

func (b *GetWalletByIDBatchBatchResults) QueryRow(f func(int, Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Wallet
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Version,
			&i.Address,
			&i.WalletType,
			&i.Chain,
			&i.L1Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetWalletByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletsByUserIDBatch = `-- name: GetWalletsByUserIDBatch :batchmany
SELECT w.id, w.created_at, w.last_updated, w.deleted, w.version, w.address, w.wallet_type, w.chain, w.l1_chain FROM users u, unnest(u.wallets) WITH ORDINALITY AS a(wallet_id, wallet_ord)INNER JOIN wallets w on w.id = a.wallet_id WHERE u.id = $1 AND u.deleted = false AND w.deleted = false ORDER BY a.wallet_ord
`

type GetWalletsByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetWalletsByUserIDBatch(ctx context.Context, id []persist.DBID) *GetWalletsByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getWalletsByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletsByUserIDBatchBatchResults{br, len(id), false}
}

func (b *GetWalletsByUserIDBatchBatchResults) Query(f func(int, []Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Wallet
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Wallet
				if err := rows.Scan(
					&i.ID,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.Version,
					&i.Address,
					&i.WalletType,
					&i.Chain,
					&i.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetWalletsByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByCommentIDBatch = `-- name: PaginateAdmiresByCommentIDBatch :batchmany
select id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id from admires where comment_id = $1 and deleted = false
    and (created_at, id) < ($2, $3) and (created_at, id) > ($4, $5)
    order by case when $6::bool then (created_at, id) end asc,
             case when not $6::bool then (created_at, id) end desc
    limit $7
`

type PaginateAdmiresByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByCommentIDBatchParams struct {
	CommentID     persist.DBID `db:"comment_id" json:"comment_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateAdmiresByCommentIDBatch(ctx context.Context, arg []PaginateAdmiresByCommentIDBatchParams) *PaginateAdmiresByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommentID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByCommentIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByCommentIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
					&i.CommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByFeedEventIDBatch = `-- name: PaginateAdmiresByFeedEventIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE feed_event_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3) AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateAdmiresByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByFeedEventIDBatchParams struct {
	FeedEventID   persist.DBID `db:"feed_event_id" json:"feed_event_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateAdmiresByFeedEventIDBatch(ctx context.Context, arg []PaginateAdmiresByFeedEventIDBatchParams) *PaginateAdmiresByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.FeedEventID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByFeedEventIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
					&i.CommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByPostIDBatch = `-- name: PaginateAdmiresByPostIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE post_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3) AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateAdmiresByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByPostIDBatchParams struct {
	PostID        persist.DBID `db:"post_id" json:"post_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateAdmiresByPostIDBatch(ctx context.Context, arg []PaginateAdmiresByPostIDBatchParams) *PaginateAdmiresByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByPostIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
					&i.CommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByTokenIDBatch = `-- name: PaginateAdmiresByTokenIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id, comment_id FROM admires WHERE token_id = $1 AND (not $2::bool or actor_id = $3) AND deleted = false
    AND (created_at, id) < ($4, $5) AND (created_at, id) > ($6, $7)
    ORDER BY CASE WHEN $8::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $8::bool THEN (created_at, id) END DESC
    LIMIT $9
`

type PaginateAdmiresByTokenIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByTokenIDBatchParams struct {
	TokenID       persist.DBID `db:"token_id" json:"token_id"`
	OnlyForActor  bool         `db:"only_for_actor" json:"only_for_actor"`
	ActorID       persist.DBID `db:"actor_id" json:"actor_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateAdmiresByTokenIDBatch(ctx context.Context, arg []PaginateAdmiresByTokenIDBatchParams) *PaginateAdmiresByTokenIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.TokenID,
			a.OnlyForActor,
			a.ActorID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByTokenIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByTokenIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByTokenIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
					&i.CommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByTokenIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateCommentsByFeedEventIDBatch = `-- name: PaginateCommentsByFeedEventIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed, top_level_comment_id FROM comments WHERE feed_event_id = $1 AND reply_to is null AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateCommentsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateCommentsByFeedEventIDBatchParams struct {
	FeedEventID   persist.DBID `db:"feed_event_id" json:"feed_event_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateCommentsByFeedEventIDBatch(ctx context.Context, arg []PaginateCommentsByFeedEventIDBatchParams) *PaginateCommentsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.FeedEventID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateCommentsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateCommentsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateCommentsByFeedEventIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.Removed,
					&i.TopLevelCommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateCommentsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateCommentsByPostIDBatch = `-- name: PaginateCommentsByPostIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed, top_level_comment_id FROM comments WHERE post_id = $1 AND reply_to is null AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateCommentsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateCommentsByPostIDBatchParams struct {
	PostID        persist.DBID `db:"post_id" json:"post_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateCommentsByPostIDBatch(ctx context.Context, arg []PaginateCommentsByPostIDBatchParams) *PaginateCommentsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateCommentsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateCommentsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateCommentsByPostIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.Removed,
					&i.TopLevelCommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateCommentsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateHoldersByCommunityID = `-- name: PaginateHoldersByCommunityID :batchmany
with community_data as (
    select community_type, contract_id
    from communities
    where communities.id = $7 and not deleted
),

community_tokens as (
    select tokens.id, tokens.deleted, tokens.version, tokens.created_at, tokens.last_updated, tokens.collectors_note, tokens.quantity, tokens.block_number, tokens.owner_user_id, tokens.owned_by_wallets, tokens.contract_id, tokens.is_user_marked_spam, tokens.last_synced, tokens.is_creator_token, tokens.token_definition_id, tokens.is_holder_token, tokens.displayable
    from community_data, tokens
    where community_data.community_type = 0
        and tokens.contract_id = community_data.contract_id
        and not tokens.deleted

    union all

    select tokens.id, tokens.deleted, tokens.version, tokens.created_at, tokens.last_updated, tokens.collectors_note, tokens.quantity, tokens.block_number, tokens.owner_user_id, tokens.owned_by_wallets, tokens.contract_id, tokens.is_user_marked_spam, tokens.last_synced, tokens.is_creator_token, tokens.token_definition_id, tokens.is_holder_token, tokens.displayable
    from community_data, tokens
        join token_community_memberships on tokens.token_definition_id = token_community_memberships.token_definition_id
            and token_community_memberships.community_id = $7
            and not token_community_memberships.deleted
    where community_data.community_type != 0
        and not tokens.deleted
)

select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id, users.persona from (
    select distinct on (u.id) u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id, u.persona from users u, community_tokens t
        where t.owner_user_id = u.id
        and t.displayable
        and u.universal = false
        and t.deleted = false and u.deleted = false
    ) as users
    where (users.created_at,users.id) < ($1::timestamptz, $2)
    and (users.created_at,users.id) > ($3::timestamptz, $4)
    order by case when $5::bool then (users.created_at,users.id) end asc,
         case when not $5::bool then (users.created_at,users.id) end desc limit $6
`

type PaginateHoldersByCommunityIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateHoldersByCommunityIDParams struct {
	CurBeforeTime time.Time     `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID  `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time     `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID  `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool          `db:"paging_forward" json:"paging_forward"`
	Limit         sql.NullInt32 `db:"limit" json:"limit"`
	CommunityID   persist.DBID  `db:"community_id" json:"community_id"`
}

// Note: sqlc has trouble recognizing that the output of the "select distinct" subquery below will
//
//	return complete rows from the users table. As a workaround, aliasing the subquery to
//	"users" seems to fix the issue (along with aliasing the users table inside the subquery
//	to "u" to avoid confusion -- otherwise, sqlc creates a custom row type that includes
//	all users.* fields twice).
func (q *Queries) PaginateHoldersByCommunityID(ctx context.Context, arg []PaginateHoldersByCommunityIDParams) *PaginateHoldersByCommunityIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
			a.CommunityID,
		}
		batch.Queue(paginateHoldersByCommunityID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateHoldersByCommunityIDBatchResults{br, len(arg), false}
}

func (b *PaginateHoldersByCommunityIDBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.Persona,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateHoldersByCommunityIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateInteractionsByFeedEventIDBatch = `-- name: PaginateInteractionsByFeedEventIDBatch :batchmany
SELECT interactions.created_At, interactions.id, interactions.tag FROM (
    SELECT t.created_at, t.id, $1::int as tag FROM admires t WHERE $1 != 0 AND t.feed_event_id = $2 AND t.deleted = false
        AND ($1, t.created_at, t.id) < ($3::int, $4, $5) AND ($1, t.created_at, t.id) > ($6::int, $7, $8)
                                                                    UNION
    SELECT t.created_at, t.id, $9::int as tag FROM comments t WHERE $9 != 0 AND t.feed_event_id = $2 AND t.reply_to is null AND t.deleted = false
        AND ($9, t.created_at, t.id) < ($3::int, $4, $5) AND ($9, t.created_at, t.id) > ($6::int, $7, $8)
) as interactions

ORDER BY CASE WHEN $10::bool THEN (tag, created_at, id) END ASC,
         CASE WHEN NOT $10::bool THEN (tag, created_at, id) END DESC
LIMIT $11
`

type PaginateInteractionsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateInteractionsByFeedEventIDBatchParams struct {
	AdmireTag     int32        `db:"admire_tag" json:"admire_tag"`
	FeedEventID   persist.DBID `db:"feed_event_id" json:"feed_event_id"`
	CurBeforeTag  int32        `db:"cur_before_tag" json:"cur_before_tag"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTag   int32        `db:"cur_after_tag" json:"cur_after_tag"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	CommentTag    int32        `db:"comment_tag" json:"comment_tag"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

type PaginateInteractionsByFeedEventIDBatchRow struct {
	CreatedAt time.Time    `db:"created_at" json:"created_at"`
	ID        persist.DBID `db:"id" json:"id"`
	Tag       int32        `db:"tag" json:"tag"`
}

func (q *Queries) PaginateInteractionsByFeedEventIDBatch(ctx context.Context, arg []PaginateInteractionsByFeedEventIDBatchParams) *PaginateInteractionsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.FeedEventID,
			a.CurBeforeTag,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTag,
			a.CurAfterTime,
			a.CurAfterID,
			a.CommentTag,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateInteractionsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateInteractionsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateInteractionsByFeedEventIDBatchBatchResults) Query(f func(int, []PaginateInteractionsByFeedEventIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateInteractionsByFeedEventIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateInteractionsByFeedEventIDBatchRow
				if err := rows.Scan(&i.CreatedAt, &i.ID, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateInteractionsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateInteractionsByPostIDBatch = `-- name: PaginateInteractionsByPostIDBatch :batchmany
SELECT interactions.created_At, interactions.id, interactions.tag FROM (
    SELECT t.created_at, t.id, $1::int as tag FROM admires t WHERE $1 != 0 AND t.post_id = $2 AND t.deleted = false
        AND ($1, t.created_at, t.id) < ($3::int, $4, $5) AND ($1, t.created_at, t.id) > ($6::int, $7, $8)
                                                                    UNION
    SELECT t.created_at, t.id, $9::int as tag FROM comments t WHERE $9 != 0 AND t.post_id = $2 AND t.reply_to is null AND t.deleted = false
        AND ($9, t.created_at, t.id) < ($3::int, $4, $5) AND ($9, t.created_at, t.id) > ($6::int, $7, $8)
) as interactions

ORDER BY CASE WHEN $10::bool THEN (tag, created_at, id) END ASC,
         CASE WHEN NOT $10::bool THEN (tag, created_at, id) END DESC
LIMIT $11
`

type PaginateInteractionsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateInteractionsByPostIDBatchParams struct {
	AdmireTag     int32        `db:"admire_tag" json:"admire_tag"`
	PostID        persist.DBID `db:"post_id" json:"post_id"`
	CurBeforeTag  int32        `db:"cur_before_tag" json:"cur_before_tag"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTag   int32        `db:"cur_after_tag" json:"cur_after_tag"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	CommentTag    int32        `db:"comment_tag" json:"comment_tag"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

type PaginateInteractionsByPostIDBatchRow struct {
	CreatedAt time.Time    `db:"created_at" json:"created_at"`
	ID        persist.DBID `db:"id" json:"id"`
	Tag       int32        `db:"tag" json:"tag"`
}

func (q *Queries) PaginateInteractionsByPostIDBatch(ctx context.Context, arg []PaginateInteractionsByPostIDBatchParams) *PaginateInteractionsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.PostID,
			a.CurBeforeTag,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTag,
			a.CurAfterTime,
			a.CurAfterID,
			a.CommentTag,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateInteractionsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateInteractionsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateInteractionsByPostIDBatchBatchResults) Query(f func(int, []PaginateInteractionsByPostIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateInteractionsByPostIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateInteractionsByPostIDBatchRow
				if err := rows.Scan(&i.CreatedAt, &i.ID, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateInteractionsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginatePostsByCommunityID = `-- name: PaginatePostsByCommunityID :batchmany
with community_data as (
    select community_type, contract_id
    from communities
    where communities.id = $1 and not deleted
)

(
select posts.id, posts.version, posts.token_ids, posts.contract_ids, posts.actor_id, posts.caption, posts.created_at, posts.last_updated, posts.deleted, posts.is_first_post, posts.user_mint_url
    from community_data, posts
    where community_data.community_type = 0
        and community_data.contract_id = any(posts.contract_ids)
        and posts.deleted = false
        and (posts.created_at, posts.id) < ($2, $3)
        and (posts.created_at, posts.id) > ($4, $5)
    order by
        case when $6::bool then (posts.created_at, posts.id) end asc,
        case when not $6::bool then (posts.created_at, posts.id) end desc
    limit $7
)

union all

(
select posts.id, posts.version, posts.token_ids, posts.contract_ids, posts.actor_id, posts.caption, posts.created_at, posts.last_updated, posts.deleted, posts.is_first_post, posts.user_mint_url
    from community_data, posts
        join tokens on tokens.id = any(posts.token_ids) and not tokens.deleted
        join token_community_memberships on tokens.token_definition_id = token_community_memberships.token_definition_id
            and token_community_memberships.community_id = $1
            and not token_community_memberships.deleted
    where community_data.community_type = 1
      and posts.deleted = false
      and (posts.created_at, posts.id) < ($2, $3)
      and (posts.created_at, posts.id) > ($4, $5)
    order by
        case when $6::bool then (posts.created_at, posts.id) end asc,
        case when not $6::bool then (posts.created_at, posts.id) end desc
    limit $7
)
`

type PaginatePostsByCommunityIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginatePostsByCommunityIDParams struct {
	CommunityID   persist.DBID `db:"community_id" json:"community_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginatePostsByCommunityID(ctx context.Context, arg []PaginatePostsByCommunityIDParams) *PaginatePostsByCommunityIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommunityID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginatePostsByCommunityID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginatePostsByCommunityIDBatchResults{br, len(arg), false}
}

func (b *PaginatePostsByCommunityIDBatchResults) Query(f func(int, []Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Post
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Post
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.TokenIds,
					&i.ContractIds,
					&i.ActorID,
					&i.Caption,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.IsFirstPost,
					&i.UserMintUrl,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginatePostsByCommunityIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginatePostsByContractID = `-- name: PaginatePostsByContractID :batchmany
SELECT posts.id, posts.version, posts.token_ids, posts.contract_ids, posts.actor_id, posts.caption, posts.created_at, posts.last_updated, posts.deleted, posts.is_first_post, posts.user_mint_url
FROM posts
WHERE $1 = ANY(posts.contract_ids)
AND posts.deleted = false
AND (posts.created_at, posts.id) < ($2, $3)
AND (posts.created_at, posts.id) > ($4, $5)
ORDER BY
    CASE WHEN $6::bool THEN (posts.created_at, posts.id) END ASC,
    CASE WHEN NOT $6::bool THEN (posts.created_at, posts.id) END DESC
LIMIT $7
`

type PaginatePostsByContractIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginatePostsByContractIDParams struct {
	ContractID    persist.DBID `db:"contract_id" json:"contract_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginatePostsByContractID(ctx context.Context, arg []PaginatePostsByContractIDParams) *PaginatePostsByContractIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ContractID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginatePostsByContractID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginatePostsByContractIDBatchResults{br, len(arg), false}
}

func (b *PaginatePostsByContractIDBatchResults) Query(f func(int, []Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Post
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Post
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.TokenIds,
					&i.ContractIds,
					&i.ActorID,
					&i.Caption,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.IsFirstPost,
					&i.UserMintUrl,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginatePostsByContractIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateRepliesByCommentIDBatch = `-- name: PaginateRepliesByCommentIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed, top_level_comment_id FROM comments c 
WHERE 
    CASE 
        WHEN (SELECT reply_to FROM comments cc WHERE cc.id = $1) IS NULL 
        THEN c.top_level_comment_id = $1 
        ELSE c.reply_to = $1 
    END
    AND c.deleted = false
    AND (c.created_at, c.id) < ($2, $3)
    AND (c.created_at, c.id) > ($4, $5)
ORDER BY 
    CASE 
        WHEN $6::bool THEN (c.created_at, c.id) 
    END ASC,
    CASE 
        WHEN NOT $6::bool THEN (c.created_at, c.id) 
    END DESC
LIMIT $7
`

type PaginateRepliesByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateRepliesByCommentIDBatchParams struct {
	CommentID     persist.DBID `db:"comment_id" json:"comment_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

func (q *Queries) PaginateRepliesByCommentIDBatch(ctx context.Context, arg []PaginateRepliesByCommentIDBatchParams) *PaginateRepliesByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommentID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateRepliesByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateRepliesByCommentIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateRepliesByCommentIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.Removed,
					&i.TopLevelCommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateRepliesByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateTokensAdmiredByUserIDBatch = `-- name: PaginateTokensAdmiredByUserIDBatch :batchmany
select tokens.id, tokens.deleted, tokens.version, tokens.created_at, tokens.last_updated, tokens.collectors_note, tokens.quantity, tokens.block_number, tokens.owner_user_id, tokens.owned_by_wallets, tokens.contract_id, tokens.is_user_marked_spam, tokens.last_synced, tokens.is_creator_token, tokens.token_definition_id, tokens.is_holder_token, tokens.displayable, admires.id, admires.version, admires.feed_event_id, admires.actor_id, admires.deleted, admires.created_at, admires.last_updated, admires.post_id, admires.token_id, admires.comment_id
from admires
join tokens on admires.token_id = tokens.id
where actor_id = $1 and not admires.deleted and not tokens.deleted
and (admires.created_at, admires.id) > ($2, $3)
and (admires.created_at, admires.id) < ($4, $5)
order by case when $6::bool then (admires.created_at, admires.id) end desc,
    case when not $6::bool then (admires.created_at, admires.id) end asc
limit $7
`

type PaginateTokensAdmiredByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateTokensAdmiredByUserIDBatchParams struct {
	UserID        persist.DBID `db:"user_id" json:"user_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

type PaginateTokensAdmiredByUserIDBatchRow struct {
	Token  Token  `db:"token" json:"token"`
	Admire Admire `db:"admire" json:"admire"`
}

func (q *Queries) PaginateTokensAdmiredByUserIDBatch(ctx context.Context, arg []PaginateTokensAdmiredByUserIDBatchParams) *PaginateTokensAdmiredByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateTokensAdmiredByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateTokensAdmiredByUserIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateTokensAdmiredByUserIDBatchBatchResults) Query(f func(int, []PaginateTokensAdmiredByUserIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateTokensAdmiredByUserIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateTokensAdmiredByUserIDBatchRow
				if err := rows.Scan(
					&i.Token.ID,
					&i.Token.Deleted,
					&i.Token.Version,
					&i.Token.CreatedAt,
					&i.Token.LastUpdated,
					&i.Token.CollectorsNote,
					&i.Token.Quantity,
					&i.Token.BlockNumber,
					&i.Token.OwnerUserID,
					&i.Token.OwnedByWallets,
					&i.Token.ContractID,
					&i.Token.IsUserMarkedSpam,
					&i.Token.LastSynced,
					&i.Token.IsCreatorToken,
					&i.Token.TokenDefinitionID,
					&i.Token.IsHolderToken,
					&i.Token.Displayable,
					&i.Admire.ID,
					&i.Admire.Version,
					&i.Admire.FeedEventID,
					&i.Admire.ActorID,
					&i.Admire.Deleted,
					&i.Admire.CreatedAt,
					&i.Admire.LastUpdated,
					&i.Admire.PostID,
					&i.Admire.TokenID,
					&i.Admire.CommentID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateTokensAdmiredByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateTokensByCommunityID = `-- name: PaginateTokensByCommunityID :batchmany
with community_data as (
    select id as community_id, community_type, contract_id
    from communities
    where communities.id = $1 and not deleted
    limit 1
)

(select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain from community_data cd
    join tokens t on t.contract_id = cd.contract_id
    join token_definitions td on t.token_definition_id = td.id
    join users u on u.id = t.owner_user_id
    join contracts c on t.contract_id = c.id
where cd.community_type = 0
    and t.displayable
    and t.deleted = false
    and c.deleted = false
    and td.deleted = false
    and u.deleted = false
    and u.universal = false
    and (t.created_at,t.id) < ($2::timestamptz, $3)
    and (t.created_at,t.id) > ($4::timestamptz, $5)
order by case when $6::bool then (t.created_at,t.id) end asc,
         case when not $6::bool then (t.created_at,t.id) end desc
limit $7)

union all

(select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.collectors_note, t.quantity, t.block_number, t.owner_user_id, t.owned_by_wallets, t.contract_id, t.is_user_marked_spam, t.last_synced, t.is_creator_token, t.token_definition_id, t.is_holder_token, t.displayable, td.id, td.created_at, td.last_updated, td.deleted, td.name, td.description, td.token_type, td.token_id, td.external_url, td.chain, td.metadata, td.fallback_media, td.contract_address, td.contract_id, td.token_media_id, td.is_fxhash, c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id, c.l1_chain from community_data cd, tokens t
    join token_community_memberships tcm on t.token_definition_id = tcm.token_definition_id
    join token_definitions td on td.id = t.token_definition_id
    join users u on u.id = t.owner_user_id
    join contracts c on t.contract_id = c.id
where cd.community_type != 0
    and tcm.community_id = cd.community_id
    and t.displayable
    and tcm.deleted = false
    and t.deleted = false
    and c.deleted = false
    and td.deleted = false
    and u.deleted = false
    and u.universal = false
    and (t.created_at,t.id) < ($2::timestamptz, $3)
    and (t.created_at,t.id) > ($4::timestamptz, $5)
order by case when $6::bool then (t.created_at,t.id) end asc,
         case when not $6::bool then (t.created_at,t.id) end desc
limit $7)
`

type PaginateTokensByCommunityIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateTokensByCommunityIDParams struct {
	CommunityID   persist.DBID `db:"community_id" json:"community_id"`
	CurBeforeTime time.Time    `db:"cur_before_time" json:"cur_before_time"`
	CurBeforeID   persist.DBID `db:"cur_before_id" json:"cur_before_id"`
	CurAfterTime  time.Time    `db:"cur_after_time" json:"cur_after_time"`
	CurAfterID    persist.DBID `db:"cur_after_id" json:"cur_after_id"`
	PagingForward bool         `db:"paging_forward" json:"paging_forward"`
	Limit         int32        `db:"limit" json:"limit"`
}

type PaginateTokensByCommunityIDRow struct {
	Token           Token           `db:"token" json:"token"`
	TokenDefinition TokenDefinition `db:"tokendefinition" json:"tokendefinition"`
	Contract        Contract        `db:"contract" json:"contract"`
}

// At present, a community is either entirely token-based or contract-based, so only
// one of these two union clauses will return any tokens (which means it's okay for each
// clause to have its own ordering). This query was originally written with a union
// of results from contract_memberships and token_memberships and a single outer
// select + join on the results of that union, but that prevented the query planner from
// using indexes correctly (since the referenced tables might be indexed, but the union
// of results is not). The current method is verbose and brittle, but it's fast!
func (q *Queries) PaginateTokensByCommunityID(ctx context.Context, arg []PaginateTokensByCommunityIDParams) *PaginateTokensByCommunityIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommunityID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateTokensByCommunityID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateTokensByCommunityIDBatchResults{br, len(arg), false}
}

func (b *PaginateTokensByCommunityIDBatchResults) Query(f func(int, []PaginateTokensByCommunityIDRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateTokensByCommunityIDRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateTokensByCommunityIDRow
				if err := rows.Scan(
					&i.Token.ID,
					&i.Token.Deleted,
					&i.Token.Version,
					&i.Token.CreatedAt,
					&i.Token.LastUpdated,
					&i.Token.CollectorsNote,
					&i.Token.Quantity,
					&i.Token.BlockNumber,
					&i.Token.OwnerUserID,
					&i.Token.OwnedByWallets,
					&i.Token.ContractID,
					&i.Token.IsUserMarkedSpam,
					&i.Token.LastSynced,
					&i.Token.IsCreatorToken,
					&i.Token.TokenDefinitionID,
					&i.Token.IsHolderToken,
					&i.Token.Displayable,
					&i.TokenDefinition.ID,
					&i.TokenDefinition.CreatedAt,
					&i.TokenDefinition.LastUpdated,
					&i.TokenDefinition.Deleted,
					&i.TokenDefinition.Name,
					&i.TokenDefinition.Description,
					&i.TokenDefinition.TokenType,
					&i.TokenDefinition.TokenID,
					&i.TokenDefinition.ExternalUrl,
					&i.TokenDefinition.Chain,
					&i.TokenDefinition.Metadata,
					&i.TokenDefinition.FallbackMedia,
					&i.TokenDefinition.ContractAddress,
					&i.TokenDefinition.ContractID,
					&i.TokenDefinition.TokenMediaID,
					&i.TokenDefinition.IsFxhash,
					&i.Contract.ID,
					&i.Contract.Deleted,
					&i.Contract.Version,
					&i.Contract.CreatedAt,
					&i.Contract.LastUpdated,
					&i.Contract.Name,
					&i.Contract.Symbol,
					&i.Contract.Address,
					&i.Contract.CreatorAddress,
					&i.Contract.Chain,
					&i.Contract.ProfileBannerUrl,
					&i.Contract.ProfileImageUrl,
					&i.Contract.BadgeUrl,
					&i.Contract.Description,
					&i.Contract.OwnerAddress,
					&i.Contract.IsProviderMarkedSpam,
					&i.Contract.ParentID,
					&i.Contract.OverrideCreatorUserID,
					&i.Contract.L1Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateTokensByCommunityIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
