// Code generated by sqlc. DO NOT EDIT.
// versions:
//   sqlc v1.18.0
// source: batch.go

package coredb

import (
	"context"
	"database/sql"
	"errors"
	"time"

	"github.com/jackc/pgtype"
	"github.com/jackc/pgx/v4"
	"github.com/mikeydub/go-gallery/service/persist"
)

var (
	ErrBatchAlreadyClosed = errors.New("batch already closed")
)

const countAdmiresByFeedEventIDBatch = `-- name: CountAdmiresByFeedEventIDBatch :batchone
SELECT count(*) FROM admires WHERE feed_event_id = $1 AND deleted = false
`

type CountAdmiresByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByFeedEventIDBatch(ctx context.Context, feedEventID []persist.DBID) *CountAdmiresByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range feedEventID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByFeedEventIDBatchBatchResults{br, len(feedEventID), false}
}

func (b *CountAdmiresByFeedEventIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countAdmiresByPostIDBatch = `-- name: CountAdmiresByPostIDBatch :batchone
SELECT count(*) FROM admires WHERE post_id = $1 AND deleted = false
`

type CountAdmiresByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByPostIDBatch(ctx context.Context, postID []persist.DBID) *CountAdmiresByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByPostIDBatchBatchResults{br, len(postID), false}
}

func (b *CountAdmiresByPostIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countAdmiresByTokenIDBatch = `-- name: CountAdmiresByTokenIDBatch :batchone
SELECT count(*) FROM admires WHERE token_id = $1 AND deleted = false
`

type CountAdmiresByTokenIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountAdmiresByTokenIDBatch(ctx context.Context, tokenID []persist.DBID) *CountAdmiresByTokenIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range tokenID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countAdmiresByTokenIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountAdmiresByTokenIDBatchBatchResults{br, len(tokenID), false}
}

func (b *CountAdmiresByTokenIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountAdmiresByTokenIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countCommentsByFeedEventIDBatch = `-- name: CountCommentsByFeedEventIDBatch :batchone
SELECT count(*) FROM comments WHERE feed_event_id = $1 AND reply_to is null AND deleted = false
`

type CountCommentsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountCommentsByFeedEventIDBatch(ctx context.Context, feedEventID []persist.DBID) *CountCommentsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range feedEventID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countCommentsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountCommentsByFeedEventIDBatchBatchResults{br, len(feedEventID), false}
}

func (b *CountCommentsByFeedEventIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountCommentsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countCommentsByPostIDBatch = `-- name: CountCommentsByPostIDBatch :batchone
SELECT count(*) FROM comments WHERE post_id = $1 AND reply_to is null AND deleted = false
`

type CountCommentsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountCommentsByPostIDBatch(ctx context.Context, postID []persist.DBID) *CountCommentsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countCommentsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountCommentsByPostIDBatchBatchResults{br, len(postID), false}
}

func (b *CountCommentsByPostIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountCommentsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countInteractionsByFeedEventIDBatch = `-- name: CountInteractionsByFeedEventIDBatch :batchmany
SELECT count(*), $1::int as tag FROM admires t WHERE $1 != 0 AND t.feed_event_id = $2 AND t.deleted = false
                                                        UNION
SELECT count(*), $3::int as tag FROM comments t WHERE $3 != 0 AND t.feed_event_id = $2 AND t.reply_to is null AND t.deleted = false
`

type CountInteractionsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CountInteractionsByFeedEventIDBatchParams struct {
	AdmireTag   int32        `json:"admire_tag"`
	FeedEventID persist.DBID `json:"feed_event_id"`
	CommentTag  int32        `json:"comment_tag"`
}

type CountInteractionsByFeedEventIDBatchRow struct {
	Count int64 `json:"count"`
	Tag   int32 `json:"tag"`
}

func (q *Queries) CountInteractionsByFeedEventIDBatch(ctx context.Context, arg []CountInteractionsByFeedEventIDBatchParams) *CountInteractionsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.FeedEventID,
			a.CommentTag,
		}
		batch.Queue(countInteractionsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountInteractionsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *CountInteractionsByFeedEventIDBatchBatchResults) Query(f func(int, []CountInteractionsByFeedEventIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []CountInteractionsByFeedEventIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i CountInteractionsByFeedEventIDBatchRow
				if err := rows.Scan(&i.Count, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *CountInteractionsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countInteractionsByPostIDBatch = `-- name: CountInteractionsByPostIDBatch :batchmany
SELECT count(*), $1::int as tag FROM admires t WHERE $1 != 0 AND t.post_id = $2 AND t.deleted = false
                                                        UNION
SELECT count(*), $3::int as tag FROM comments t WHERE $3 != 0 AND t.post_id = $2 AND t.reply_to is null AND t.deleted = false
`

type CountInteractionsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type CountInteractionsByPostIDBatchParams struct {
	AdmireTag  int32        `json:"admire_tag"`
	PostID     persist.DBID `json:"post_id"`
	CommentTag int32        `json:"comment_tag"`
}

type CountInteractionsByPostIDBatchRow struct {
	Count int64 `json:"count"`
	Tag   int32 `json:"tag"`
}

func (q *Queries) CountInteractionsByPostIDBatch(ctx context.Context, arg []CountInteractionsByPostIDBatchParams) *CountInteractionsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.PostID,
			a.CommentTag,
		}
		batch.Queue(countInteractionsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountInteractionsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *CountInteractionsByPostIDBatchBatchResults) Query(f func(int, []CountInteractionsByPostIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []CountInteractionsByPostIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i CountInteractionsByPostIDBatchRow
				if err := rows.Scan(&i.Count, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *CountInteractionsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const countRepliesByCommentIDBatch = `-- name: CountRepliesByCommentIDBatch :batchone
SELECT count(*) FROM comments WHERE reply_to = $1 AND deleted = false
`

type CountRepliesByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) CountRepliesByCommentIDBatch(ctx context.Context, commentID []persist.DBID) *CountRepliesByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range commentID {
		vals := []interface{}{
			a,
		}
		batch.Queue(countRepliesByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &CountRepliesByCommentIDBatchBatchResults{br, len(commentID), false}
}

func (b *CountRepliesByCommentIDBatchBatchResults) QueryRow(f func(int, int64, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var count int64
		if b.closed {
			if f != nil {
				f(t, count, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(&count)
		if f != nil {
			f(t, count, err)
		}
	}
}

func (b *CountRepliesByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndFeedEventID = `-- name: GetAdmireByActorIDAndFeedEventID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE actor_id = $1 AND feed_event_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndFeedEventIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndFeedEventIDParams struct {
	ActorID     persist.DBID `json:"actor_id"`
	FeedEventID persist.DBID `json:"feed_event_id"`
}

func (q *Queries) GetAdmireByActorIDAndFeedEventID(ctx context.Context, arg []GetAdmireByActorIDAndFeedEventIDParams) *GetAdmireByActorIDAndFeedEventIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.FeedEventID,
		}
		batch.Queue(getAdmireByActorIDAndFeedEventID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndFeedEventIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndFeedEventIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndFeedEventIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndPostID = `-- name: GetAdmireByActorIDAndPostID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE actor_id = $1 AND post_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndPostIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndPostIDParams struct {
	ActorID persist.DBID `json:"actor_id"`
	PostID  persist.DBID `json:"post_id"`
}

func (q *Queries) GetAdmireByActorIDAndPostID(ctx context.Context, arg []GetAdmireByActorIDAndPostIDParams) *GetAdmireByActorIDAndPostIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.PostID,
		}
		batch.Queue(getAdmireByActorIDAndPostID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndPostIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndPostIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndPostIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByActorIDAndTokenID = `-- name: GetAdmireByActorIDAndTokenID :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE actor_id = $1 AND token_id = $2 AND deleted = false
`

type GetAdmireByActorIDAndTokenIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetAdmireByActorIDAndTokenIDParams struct {
	ActorID persist.DBID `json:"actor_id"`
	TokenID persist.DBID `json:"token_id"`
}

func (q *Queries) GetAdmireByActorIDAndTokenID(ctx context.Context, arg []GetAdmireByActorIDAndTokenIDParams) *GetAdmireByActorIDAndTokenIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ActorID,
			a.TokenID,
		}
		batch.Queue(getAdmireByActorIDAndTokenID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByActorIDAndTokenIDBatchResults{br, len(arg), false}
}

func (b *GetAdmireByActorIDAndTokenIDBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByActorIDAndTokenIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmireByAdmireIDBatch = `-- name: GetAdmireByAdmireIDBatch :batchone
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE id = $1 AND deleted = false
`

type GetAdmireByAdmireIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetAdmireByAdmireIDBatch(ctx context.Context, id []persist.DBID) *GetAdmireByAdmireIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getAdmireByAdmireIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmireByAdmireIDBatchBatchResults{br, len(id), false}
}

func (b *GetAdmireByAdmireIDBatchBatchResults) QueryRow(f func(int, Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Admire
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.TokenID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetAdmireByAdmireIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getAdmiresByActorIDBatch = `-- name: GetAdmiresByActorIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE actor_id = $1 AND deleted = false ORDER BY created_at DESC
`

type GetAdmiresByActorIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetAdmiresByActorIDBatch(ctx context.Context, actorID []persist.DBID) *GetAdmiresByActorIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range actorID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getAdmiresByActorIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetAdmiresByActorIDBatchBatchResults{br, len(actorID), false}
}

func (b *GetAdmiresByActorIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetAdmiresByActorIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getChildContractsByParentIDBatchPaginate = `-- name: GetChildContractsByParentIDBatchPaginate :batchmany
select c.id, c.deleted, c.version, c.created_at, c.last_updated, c.name, c.symbol, c.address, c.creator_address, c.chain, c.profile_banner_url, c.profile_image_url, c.badge_url, c.description, c.owner_address, c.is_provider_marked_spam, c.parent_id, c.override_creator_user_id
from contracts c
where c.parent_id = $1
  and c.deleted = false
  and (c.created_at, c.id) < ($2, $3)
  and (c.created_at, c.id) > ( $4, $5)
order by case when $6::bool then (c.created_at, c.id) end asc,
        case when not $6::bool then (c.created_at, c.id) end desc
limit $7
`

type GetChildContractsByParentIDBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetChildContractsByParentIDBatchPaginateParams struct {
	ParentID      persist.DBID `json:"parent_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) GetChildContractsByParentIDBatchPaginate(ctx context.Context, arg []GetChildContractsByParentIDBatchPaginateParams) *GetChildContractsByParentIDBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ParentID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getChildContractsByParentIDBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetChildContractsByParentIDBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetChildContractsByParentIDBatchPaginateBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetChildContractsByParentIDBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCollectionByIdBatch = `-- name: GetCollectionByIdBatch :batchone
SELECT id, deleted, owner_user_id, nfts, version, last_updated, created_at, hidden, collectors_note, name, layout, token_settings, gallery_id FROM collections WHERE id = $1 AND deleted = false
`

type GetCollectionByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCollectionByIdBatch(ctx context.Context, id []persist.DBID) *GetCollectionByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCollectionByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCollectionByIdBatchBatchResults{br, len(id), false}
}

func (b *GetCollectionByIdBatchBatchResults) QueryRow(f func(int, Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Collection
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.OwnerUserID,
			&i.Nfts,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Hidden,
			&i.CollectorsNote,
			&i.Name,
			&i.Layout,
			&i.TokenSettings,
			&i.GalleryID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCollectionByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCollectionsByGalleryIdBatch = `-- name: GetCollectionsByGalleryIdBatch :batchmany
SELECT c.id, c.deleted, c.owner_user_id, c.nfts, c.version, c.last_updated, c.created_at, c.hidden, c.collectors_note, c.name, c.layout, c.token_settings, c.gallery_id FROM galleries g, unnest(g.collections)
    WITH ORDINALITY AS x(coll_id, coll_ord)
    INNER JOIN collections c ON c.id = x.coll_id
    WHERE g.id = $1 AND g.deleted = false AND c.deleted = false ORDER BY x.coll_ord
`

type GetCollectionsByGalleryIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCollectionsByGalleryIdBatch(ctx context.Context, id []persist.DBID) *GetCollectionsByGalleryIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCollectionsByGalleryIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCollectionsByGalleryIdBatchBatchResults{br, len(id), false}
}

func (b *GetCollectionsByGalleryIdBatchBatchResults) Query(f func(int, []Collection, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Collection
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Collection
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerUserID,
					&i.Nfts,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Hidden,
					&i.CollectorsNote,
					&i.Name,
					&i.Layout,
					&i.TokenSettings,
					&i.GalleryID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCollectionsByGalleryIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCommentByCommentIDBatch = `-- name: GetCommentByCommentIDBatch :batchone
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed FROM comments WHERE id = $1 and deleted = false
`

type GetCommentByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetCommentByCommentIDBatch(ctx context.Context, id []persist.DBID) *GetCommentByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getCommentByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCommentByCommentIDBatchBatchResults{br, len(id), false}
}

func (b *GetCommentByCommentIDBatchBatchResults) QueryRow(f func(int, Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Comment
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.FeedEventID,
			&i.ActorID,
			&i.ReplyTo,
			&i.Comment,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.PostID,
			&i.Removed,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetCommentByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getContractByChainAddressBatch = `-- name: GetContractByChainAddressBatch :batchone
select id, deleted, version, created_at, last_updated, name, symbol, address, creator_address, chain, profile_banner_url, profile_image_url, badge_url, description, owner_address, is_provider_marked_spam, parent_id, override_creator_user_id FROM contracts WHERE address = $1 AND chain = $2 AND deleted = false
`

type GetContractByChainAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetContractByChainAddressBatchParams struct {
	Address persist.Address `json:"address"`
	Chain   persist.Chain   `json:"chain"`
}

func (q *Queries) GetContractByChainAddressBatch(ctx context.Context, arg []GetContractByChainAddressBatchParams) *GetContractByChainAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getContractByChainAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetContractByChainAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetContractByChainAddressBatchBatchResults) QueryRow(f func(int, Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Contract
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Name,
			&i.Symbol,
			&i.Address,
			&i.CreatorAddress,
			&i.Chain,
			&i.ProfileBannerUrl,
			&i.ProfileImageUrl,
			&i.BadgeUrl,
			&i.Description,
			&i.OwnerAddress,
			&i.IsProviderMarkedSpam,
			&i.ParentID,
			&i.OverrideCreatorUserID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetContractByChainAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getContractsDisplayedByUserIDBatch = `-- name: GetContractsDisplayedByUserIDBatch :batchmany
with last_refreshed as (
  select last_updated from owned_contracts limit 1
),
displayed as (
  select contract_id
  from owned_contracts
  where owned_contracts.user_id = $1 and displayed = true
  union
  select contracts.id
  from last_refreshed, galleries, contracts, tokens
  join collections on tokens.id = any(collections.nfts) and collections.deleted = false
  where tokens.owner_user_id = $1
    and tokens.contract = contracts.id
    and collections.owner_user_id = tokens.owner_user_id
    and galleries.owner_user_id = tokens.owner_user_id
    and tokens.displayable
    and tokens.deleted = false
    and galleries.deleted = false
    and contracts.deleted = false
    and galleries.last_updated > last_refreshed.last_updated
    and collections.last_updated > last_refreshed.last_updated
)
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id from contracts, displayed
where contracts.id = displayed.contract_id and contracts.deleted = false
`

type GetContractsDisplayedByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetContractsDisplayedByUserIDBatch(ctx context.Context, userID []persist.DBID) *GetContractsDisplayedByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range userID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getContractsDisplayedByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetContractsDisplayedByUserIDBatchBatchResults{br, len(userID), false}
}

func (b *GetContractsDisplayedByUserIDBatchBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetContractsDisplayedByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getCreatedContractsBatchPaginate = `-- name: GetCreatedContractsBatchPaginate :batchmany
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id
from contracts
    join contract_creators on contracts.id = contract_creators.contract_id and contract_creators.creator_user_id = $1
where ($2::bool or contracts.chain = any(string_to_array($3, ',')::int[]))
  and (contracts.created_at, contracts.id) < ($4, $5)
  and (contracts.created_at, contracts.id) > ( $6, $7)
order by case when $8::bool then (contracts.created_at, contracts.id) end asc,
        case when not $8::bool then (contracts.created_at, contracts.id) end desc
limit $9
`

type GetCreatedContractsBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetCreatedContractsBatchPaginateParams struct {
	UserID           persist.DBID `json:"user_id"`
	IncludeAllChains bool         `json:"include_all_chains"`
	Chains           string       `json:"chains"`
	CurBeforeTime    time.Time    `json:"cur_before_time"`
	CurBeforeID      persist.DBID `json:"cur_before_id"`
	CurAfterTime     time.Time    `json:"cur_after_time"`
	CurAfterID       persist.DBID `json:"cur_after_id"`
	PagingForward    bool         `json:"paging_forward"`
	Limit            int32        `json:"limit"`
}

func (q *Queries) GetCreatedContractsBatchPaginate(ctx context.Context, arg []GetCreatedContractsBatchPaginateParams) *GetCreatedContractsBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserID,
			a.IncludeAllChains,
			a.Chains,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getCreatedContractsBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetCreatedContractsBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetCreatedContractsBatchPaginateBatchResults) Query(f func(int, []Contract, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Contract
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Contract
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetCreatedContractsBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getEventByIdBatch = `-- name: GetEventByIdBatch :batchone
SELECT id, version, owner_id, action, data, event_time, event_ids, deleted, last_updated, created_at, caption, group_id FROM feed_events WHERE id = $1 AND deleted = false
`

type GetEventByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetEventByIdBatch(ctx context.Context, id []persist.DBID) *GetEventByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getEventByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetEventByIdBatchBatchResults{br, len(id), false}
}

func (b *GetEventByIdBatchBatchResults) QueryRow(f func(int, FeedEvent, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i FeedEvent
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.OwnerID,
			&i.Action,
			&i.Data,
			&i.EventTime,
			&i.EventIds,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Caption,
			&i.GroupID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetEventByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFollowersByUserIdBatch = `-- name: GetFollowersByUserIdBatch :batchmany
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id FROM follows f
    INNER JOIN users u ON f.follower = u.id
    WHERE f.followee = $1 AND f.deleted = false
    ORDER BY f.last_updated DESC
`

type GetFollowersByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetFollowersByUserIdBatch(ctx context.Context, followee []persist.DBID) *GetFollowersByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range followee {
		vals := []interface{}{
			a,
		}
		batch.Queue(getFollowersByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFollowersByUserIdBatchBatchResults{br, len(followee), false}
}

func (b *GetFollowersByUserIdBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFollowersByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getFollowingByUserIdBatch = `-- name: GetFollowingByUserIdBatch :batchmany
SELECT u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id FROM follows f
    INNER JOIN users u ON f.followee = u.id
    WHERE f.follower = $1 AND f.deleted = false
    ORDER BY f.last_updated DESC
`

type GetFollowingByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetFollowingByUserIdBatch(ctx context.Context, follower []persist.DBID) *GetFollowingByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range follower {
		vals := []interface{}{
			a,
		}
		batch.Queue(getFollowingByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetFollowingByUserIdBatchBatchResults{br, len(follower), false}
}

func (b *GetFollowingByUserIdBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetFollowingByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleriesByUserIdBatch = `-- name: GetGalleriesByUserIdBatch :batchmany
SELECT id, deleted, last_updated, created_at, version, owner_user_id, collections, name, description, hidden, position FROM galleries WHERE owner_user_id = $1 AND deleted = false order by position
`

type GetGalleriesByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleriesByUserIdBatch(ctx context.Context, ownerUserID []persist.DBID) *GetGalleriesByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range ownerUserID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleriesByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleriesByUserIdBatchBatchResults{br, len(ownerUserID), false}
}

func (b *GetGalleriesByUserIdBatchBatchResults) Query(f func(int, []Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Gallery
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Gallery
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Version,
					&i.OwnerUserID,
					&i.Collections,
					&i.Name,
					&i.Description,
					&i.Hidden,
					&i.Position,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetGalleriesByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryByCollectionIdBatch = `-- name: GetGalleryByCollectionIdBatch :batchone
SELECT g.id, g.deleted, g.last_updated, g.created_at, g.version, g.owner_user_id, g.collections, g.name, g.description, g.hidden, g.position FROM galleries g, collections c WHERE c.id = $1 AND c.deleted = false AND $1 = ANY(g.collections) AND g.deleted = false
`

type GetGalleryByCollectionIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryByCollectionIdBatch(ctx context.Context, id []persist.DBID) *GetGalleryByCollectionIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryByCollectionIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryByCollectionIdBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryByCollectionIdBatchBatchResults) QueryRow(f func(int, Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Gallery
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Version,
			&i.OwnerUserID,
			&i.Collections,
			&i.Name,
			&i.Description,
			&i.Hidden,
			&i.Position,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetGalleryByCollectionIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryByIdBatch = `-- name: GetGalleryByIdBatch :batchone
SELECT id, deleted, last_updated, created_at, version, owner_user_id, collections, name, description, hidden, position FROM galleries WHERE id = $1 AND deleted = false
`

type GetGalleryByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryByIdBatch(ctx context.Context, id []persist.DBID) *GetGalleryByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryByIdBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryByIdBatchBatchResults) QueryRow(f func(int, Gallery, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Gallery
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Version,
			&i.OwnerUserID,
			&i.Collections,
			&i.Name,
			&i.Description,
			&i.Hidden,
			&i.Position,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetGalleryByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getGalleryTokenMediasByGalleryIDBatch = `-- name: GetGalleryTokenMediasByGalleryIDBatch :batchmany
select tm.id, tm.created_at, tm.last_updated, tm.version, tm.contract_id__deprecated, tm.token_id__deprecated, tm.chain__deprecated, tm.active, tm.metadata__deprecated, tm.media, tm.name__deprecated, tm.description__deprecated, tm.processing_job_id, tm.deleted
	from galleries g, collections c, tokens t, token_medias tm
	where
		g.id = $1
		and c.id = any(g.collections[:8])
		and t.id = any(c.nfts[:8])
		and t.token_media_id = tm.id
	    and t.owner_user_id = g.owner_user_id
	    and t.displayable
		and not g.deleted
		and not c.deleted
		and not t.deleted
		and not tm.deleted
		and tm.active
		and (length(tm.media ->> 'thumbnail_url'::varchar) > 0 or length(tm.media ->> 'media_url'::varchar) > 0)
	order by array_position(g.collections, c.id) , array_position(c.nfts, t.id)
	limit 4
`

type GetGalleryTokenMediasByGalleryIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetGalleryTokenMediasByGalleryIDBatch(ctx context.Context, id []persist.DBID) *GetGalleryTokenMediasByGalleryIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getGalleryTokenMediasByGalleryIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetGalleryTokenMediasByGalleryIDBatchBatchResults{br, len(id), false}
}

func (b *GetGalleryTokenMediasByGalleryIDBatchBatchResults) Query(f func(int, []TokenMedia, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []TokenMedia
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i TokenMedia
				if err := rows.Scan(
					&i.ID,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Version,
					&i.ContractIDDeprecated,
					&i.TokenIDDeprecated,
					&i.ChainDeprecated,
					&i.Active,
					&i.MetadataDeprecated,
					&i.Media,
					&i.NameDeprecated,
					&i.DescriptionDeprecated,
					&i.ProcessingJobID,
					&i.Deleted,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetGalleryTokenMediasByGalleryIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMediaByTokenDefinitionIDIgnoringStatusBatch = `-- name: GetMediaByTokenDefinitionIDIgnoringStatusBatch :batchone
select m.id, m.created_at, m.last_updated, m.version, m.contract_id__deprecated, m.token_id__deprecated, m.chain__deprecated, m.active, m.metadata__deprecated, m.media, m.name__deprecated, m.description__deprecated, m.processing_job_id, m.deleted
from token_medias m
where m.id = (select token_media_id from token_definitions where token_definitions.id = $1 and not token_definitions.deleted) and not m.deleted
`

type GetMediaByTokenDefinitionIDIgnoringStatusBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMediaByTokenDefinitionIDIgnoringStatusBatch(ctx context.Context, id []persist.DBID) *GetMediaByTokenDefinitionIDIgnoringStatusBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMediaByTokenDefinitionIDIgnoringStatusBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMediaByTokenDefinitionIDIgnoringStatusBatchBatchResults{br, len(id), false}
}

func (b *GetMediaByTokenDefinitionIDIgnoringStatusBatchBatchResults) QueryRow(f func(int, TokenMedia, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenMedia
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Version,
			&i.ContractIDDeprecated,
			&i.TokenIDDeprecated,
			&i.ChainDeprecated,
			&i.Active,
			&i.MetadataDeprecated,
			&i.Media,
			&i.NameDeprecated,
			&i.DescriptionDeprecated,
			&i.ProcessingJobID,
			&i.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMediaByTokenDefinitionIDIgnoringStatusBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMediaByTokenIDIgnoringStatusBatch = `-- name: GetMediaByTokenIDIgnoringStatusBatch :batchone
select m.id, m.created_at, m.last_updated, m.version, m.contract_id__deprecated, m.token_id__deprecated, m.chain__deprecated, m.active, m.metadata__deprecated, m.media, m.name__deprecated, m.description__deprecated, m.processing_job_id, m.deleted
from token_medias m
where m.id = (select token_media_id from tokens where tokens.id = $1) and not m.deleted
`

type GetMediaByTokenIDIgnoringStatusBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMediaByTokenIDIgnoringStatusBatch(ctx context.Context, id []persist.DBID) *GetMediaByTokenIDIgnoringStatusBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMediaByTokenIDIgnoringStatusBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMediaByTokenIDIgnoringStatusBatchBatchResults{br, len(id), false}
}

func (b *GetMediaByTokenIDIgnoringStatusBatchBatchResults) QueryRow(f func(int, TokenMedia, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenMedia
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Version,
			&i.ContractIDDeprecated,
			&i.TokenIDDeprecated,
			&i.ChainDeprecated,
			&i.Active,
			&i.MetadataDeprecated,
			&i.Media,
			&i.NameDeprecated,
			&i.DescriptionDeprecated,
			&i.ProcessingJobID,
			&i.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMediaByTokenIDIgnoringStatusBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMembershipByMembershipIdBatch = `-- name: GetMembershipByMembershipIdBatch :batchone
SELECT id, deleted, version, created_at, last_updated, token_id, name, asset_url, owners FROM membership WHERE id = $1 AND deleted = false
`

type GetMembershipByMembershipIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMembershipByMembershipIdBatch(ctx context.Context, id []persist.DBID) *GetMembershipByMembershipIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMembershipByMembershipIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMembershipByMembershipIdBatchBatchResults{br, len(id), false}
}

func (b *GetMembershipByMembershipIdBatchBatchResults) QueryRow(f func(int, Membership, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Membership
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.TokenID,
			&i.Name,
			&i.AssetUrl,
			&i.Owners,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetMembershipByMembershipIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMentionsByCommentID = `-- name: GetMentionsByCommentID :batchmany
select id, post_id, comment_id, user_id, contract_id, start, length, created_at, deleted from mentions where comment_id = $1 and not deleted
`

type GetMentionsByCommentIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMentionsByCommentID(ctx context.Context, commentID []persist.DBID) *GetMentionsByCommentIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range commentID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMentionsByCommentID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMentionsByCommentIDBatchResults{br, len(commentID), false}
}

func (b *GetMentionsByCommentIDBatchResults) Query(f func(int, []Mention, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Mention
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Mention
				if err := rows.Scan(
					&i.ID,
					&i.PostID,
					&i.CommentID,
					&i.UserID,
					&i.ContractID,
					&i.Start,
					&i.Length,
					&i.CreatedAt,
					&i.Deleted,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetMentionsByCommentIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getMentionsByPostID = `-- name: GetMentionsByPostID :batchmany
select id, post_id, comment_id, user_id, contract_id, start, length, created_at, deleted from mentions where post_id = $1 and not deleted
`

type GetMentionsByPostIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetMentionsByPostID(ctx context.Context, postID []persist.DBID) *GetMentionsByPostIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range postID {
		vals := []interface{}{
			a,
		}
		batch.Queue(getMentionsByPostID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetMentionsByPostIDBatchResults{br, len(postID), false}
}

func (b *GetMentionsByPostIDBatchResults) Query(f func(int, []Mention, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Mention
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Mention
				if err := rows.Scan(
					&i.ID,
					&i.PostID,
					&i.CommentID,
					&i.UserID,
					&i.ContractID,
					&i.Start,
					&i.Length,
					&i.CreatedAt,
					&i.Deleted,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetMentionsByPostIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getNewTokensByFeedEventIdBatch = `-- name: GetNewTokensByFeedEventIdBatch :batchmany
with new_tokens as (
    select added.id, row_number() over () added_order
    from (select jsonb_array_elements_text(data -> 'collection_new_token_ids') id from feed_events f where f.id = $1 and f.deleted = false) added
)
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name__deprecated, t.description__deprecated, t.collectors_note, t.token_uri__deprecated, t.token_type__deprecated, t.token_id, t.quantity, t.ownership_history__deprecated, t.external_url__deprecated, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract_id, t.is_user_marked_spam, t.is_provider_marked_spam__deprecated, t.last_synced, t.fallback_media__deprecated, t.token_media_id__deprecated, t.is_creator_token, t.is_holder_token, t.displayable, t.token_definition_id from new_tokens a join tokens t on a.id = t.id and t.displayable and t.deleted = false order by a.added_order
`

type GetNewTokensByFeedEventIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetNewTokensByFeedEventIdBatch(ctx context.Context, id []persist.DBID) *GetNewTokensByFeedEventIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getNewTokensByFeedEventIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetNewTokensByFeedEventIdBatchBatchResults{br, len(id), false}
}

func (b *GetNewTokensByFeedEventIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.NameDeprecated,
					&i.DescriptionDeprecated,
					&i.CollectorsNote,
					&i.TokenUriDeprecated,
					&i.TokenTypeDeprecated,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistoryDeprecated,
					&i.ExternalUrlDeprecated,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpamDeprecated,
					&i.LastSynced,
					&i.FallbackMediaDeprecated,
					&i.TokenMediaIDDeprecated,
					&i.IsCreatorToken,
					&i.IsHolderToken,
					&i.Displayable,
					&i.TokenDefinitionID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetNewTokensByFeedEventIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getNotificationByIDBatch = `-- name: GetNotificationByIDBatch :batchone
SELECT id, deleted, owner_id, version, last_updated, created_at, action, data, event_ids, feed_event_id, comment_id, gallery_id, seen, amount, post_id, token_id, contract_id, mention_id FROM notifications WHERE id = $1 AND deleted = false
`

type GetNotificationByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetNotificationByIDBatch(ctx context.Context, id []persist.DBID) *GetNotificationByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getNotificationByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetNotificationByIDBatchBatchResults{br, len(id), false}
}

func (b *GetNotificationByIDBatchBatchResults) QueryRow(f func(int, Notification, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Notification
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.OwnerID,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Action,
			&i.Data,
			&i.EventIds,
			&i.FeedEventID,
			&i.CommentID,
			&i.GalleryID,
			&i.Seen,
			&i.Amount,
			&i.PostID,
			&i.TokenID,
			&i.ContractID,
			&i.MentionID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetNotificationByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getOwnersByContractIdBatchPaginate = `-- name: GetOwnersByContractIdBatchPaginate :batchmany
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_verified, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id from (
    select distinct on (u.id) u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id from users u, tokens t, contracts c
        where t.owner_user_id = u.id
        and t.displayable
        and t.contract = c.id and (c.id = $1 or c.parent_id = $1)
        and (not $2::bool or u.universal = false)
        and t.deleted = false and u.deleted = false and c.deleted = false
    ) as users
    where (users.universal,users.created_at,users.id) < ($3, $4::timestamptz, $5)
    and (users.universal,users.created_at,users.id) > ($6, $7::timestamptz, $8)
    order by case when $9::bool then (users.universal,users.created_at,users.id) end asc,
         case when not $9::bool then (users.universal,users.created_at,users.id) end desc limit $10
`

type GetOwnersByContractIdBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetOwnersByContractIdBatchPaginateParams struct {
	ID                 persist.DBID  `json:"id"`
	GalleryUsersOnly   bool          `json:"gallery_users_only"`
	CurBeforeUniversal bool          `json:"cur_before_universal"`
	CurBeforeTime      time.Time     `json:"cur_before_time"`
	CurBeforeID        persist.DBID  `json:"cur_before_id"`
	CurAfterUniversal  bool          `json:"cur_after_universal"`
	CurAfterTime       time.Time     `json:"cur_after_time"`
	CurAfterID         persist.DBID  `json:"cur_after_id"`
	PagingForward      bool          `json:"paging_forward"`
	Limit              sql.NullInt32 `json:"limit"`
}

// Note: sqlc has trouble recognizing that the output of the "select distinct" subquery below will
//
//	return complete rows from the users table. As a workaround, aliasing the subquery to
//	"users" seems to fix the issue (along with aliasing the users table inside the subquery
//	to "u" to avoid confusion -- otherwise, sqlc creates a custom row type that includes
//	all users.* fields twice).
func (q *Queries) GetOwnersByContractIdBatchPaginate(ctx context.Context, arg []GetOwnersByContractIdBatchPaginateParams) *GetOwnersByContractIdBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.GalleryUsersOnly,
			a.CurBeforeUniversal,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterUniversal,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getOwnersByContractIdBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetOwnersByContractIdBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetOwnersByContractIdBatchPaginateBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetOwnersByContractIdBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getPostByIdBatch = `-- name: GetPostByIdBatch :batchone
SELECT id, version, token_ids, contract_ids, actor_id, caption, created_at, last_updated, deleted FROM posts WHERE id = $1 AND deleted = false
`

type GetPostByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetPostByIdBatch(ctx context.Context, id []persist.DBID) *GetPostByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getPostByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetPostByIdBatchBatchResults{br, len(id), false}
}

func (b *GetPostByIdBatchBatchResults) QueryRow(f func(int, Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Post
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Version,
			&i.TokenIds,
			&i.ContractIds,
			&i.ActorID,
			&i.Caption,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetPostByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getProfileImageByID = `-- name: GetProfileImageByID :batchone
select id, user_id, token_id, source_type, deleted, created_at, last_updated, wallet_id, ens_avatar_uri, ens_domain from profile_images pfp
where pfp.id = $1
	and not deleted
	and case
		when pfp.source_type = $2
		then exists(select 1 from wallets w where w.id = pfp.wallet_id and not w.deleted)
		when pfp.source_type = $3
		then exists(select 1 from tokens t where t.id = pfp.token_id and t.displayable and not t.deleted)
		else
		0 = 1
	end
`

type GetProfileImageByIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetProfileImageByIDParams struct {
	ID              persist.DBID               `json:"id"`
	EnsSourceType   persist.ProfileImageSource `json:"ens_source_type"`
	TokenSourceType persist.ProfileImageSource `json:"token_source_type"`
}

func (q *Queries) GetProfileImageByID(ctx context.Context, arg []GetProfileImageByIDParams) *GetProfileImageByIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ID,
			a.EnsSourceType,
			a.TokenSourceType,
		}
		batch.Queue(getProfileImageByID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetProfileImageByIDBatchResults{br, len(arg), false}
}

func (b *GetProfileImageByIDBatchResults) QueryRow(f func(int, ProfileImage, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i ProfileImage
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.UserID,
			&i.TokenID,
			&i.SourceType,
			&i.Deleted,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.WalletID,
			&i.EnsAvatarUri,
			&i.EnsDomain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetProfileImageByIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getSharedContractsBatchPaginate = `-- name: GetSharedContractsBatchPaginate :batchmany
select contracts.id, contracts.deleted, contracts.version, contracts.created_at, contracts.last_updated, contracts.name, contracts.symbol, contracts.address, contracts.creator_address, contracts.chain, contracts.profile_banner_url, contracts.profile_image_url, contracts.badge_url, contracts.description, contracts.owner_address, contracts.is_provider_marked_spam, contracts.parent_id, contracts.override_creator_user_id, a.displayed as displayed_by_user_a, b.displayed as displayed_by_user_b, a.owned_count
from owned_contracts a, owned_contracts b, contracts
left join marketplace_contracts on contracts.id = marketplace_contracts.contract_id
where a.user_id = $1
  and b.user_id = $2
  and a.contract_id = b.contract_id
  and a.contract_id = contracts.id
  and marketplace_contracts.contract_id is null
  and contracts.name is not null
  and contracts.name != ''
  and contracts.name != 'Unidentified contract'
  and (
    a.displayed,
    b.displayed,
    a.owned_count,
    contracts.id
  ) > (
    $3,
    $4,
    $5::int,
    $6
  )
  and (
    a.displayed,
    b.displayed,
    a.owned_count,
    contracts.id
  ) < (
    $7,
    $8,
    $9::int,
    $10
  )
order by case when $11::bool then (a.displayed, b.displayed, a.owned_count, contracts.id) end desc,
        case when not $11::bool then (a.displayed, b.displayed, a.owned_count, contracts.id) end asc
limit $12
`

type GetSharedContractsBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetSharedContractsBatchPaginateParams struct {
	UserAID                   persist.DBID `json:"user_a_id"`
	UserBID                   persist.DBID `json:"user_b_id"`
	CurBeforeDisplayedByUserA bool         `json:"cur_before_displayed_by_user_a"`
	CurBeforeDisplayedByUserB bool         `json:"cur_before_displayed_by_user_b"`
	CurBeforeOwnedCount       int32        `json:"cur_before_owned_count"`
	CurBeforeContractID       persist.DBID `json:"cur_before_contract_id"`
	CurAfterDisplayedByUserA  bool         `json:"cur_after_displayed_by_user_a"`
	CurAfterDisplayedByUserB  bool         `json:"cur_after_displayed_by_user_b"`
	CurAfterOwnedCount        int32        `json:"cur_after_owned_count"`
	CurAfterContractID        persist.DBID `json:"cur_after_contract_id"`
	PagingForward             bool         `json:"paging_forward"`
	Limit                     int32        `json:"limit"`
}

type GetSharedContractsBatchPaginateRow struct {
	ID                    persist.DBID    `json:"id"`
	Deleted               bool            `json:"deleted"`
	Version               sql.NullInt32   `json:"version"`
	CreatedAt             time.Time       `json:"created_at"`
	LastUpdated           time.Time       `json:"last_updated"`
	Name                  sql.NullString  `json:"name"`
	Symbol                sql.NullString  `json:"symbol"`
	Address               persist.Address `json:"address"`
	CreatorAddress        persist.Address `json:"creator_address"`
	Chain                 persist.Chain   `json:"chain"`
	ProfileBannerUrl      sql.NullString  `json:"profile_banner_url"`
	ProfileImageUrl       sql.NullString  `json:"profile_image_url"`
	BadgeUrl              sql.NullString  `json:"badge_url"`
	Description           sql.NullString  `json:"description"`
	OwnerAddress          persist.Address `json:"owner_address"`
	IsProviderMarkedSpam  bool            `json:"is_provider_marked_spam"`
	ParentID              persist.DBID    `json:"parent_id"`
	OverrideCreatorUserID persist.DBID    `json:"override_creator_user_id"`
	DisplayedByUserA      bool            `json:"displayed_by_user_a"`
	DisplayedByUserB      bool            `json:"displayed_by_user_b"`
	OwnedCount            int64           `json:"owned_count"`
}

func (q *Queries) GetSharedContractsBatchPaginate(ctx context.Context, arg []GetSharedContractsBatchPaginateParams) *GetSharedContractsBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.UserAID,
			a.UserBID,
			a.CurBeforeDisplayedByUserA,
			a.CurBeforeDisplayedByUserB,
			a.CurBeforeOwnedCount,
			a.CurBeforeContractID,
			a.CurAfterDisplayedByUserA,
			a.CurAfterDisplayedByUserB,
			a.CurAfterOwnedCount,
			a.CurAfterContractID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getSharedContractsBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetSharedContractsBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetSharedContractsBatchPaginateBatchResults) Query(f func(int, []GetSharedContractsBatchPaginateRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetSharedContractsBatchPaginateRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetSharedContractsBatchPaginateRow
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Name,
					&i.Symbol,
					&i.Address,
					&i.CreatorAddress,
					&i.Chain,
					&i.ProfileBannerUrl,
					&i.ProfileImageUrl,
					&i.BadgeUrl,
					&i.Description,
					&i.OwnerAddress,
					&i.IsProviderMarkedSpam,
					&i.ParentID,
					&i.OverrideCreatorUserID,
					&i.DisplayedByUserA,
					&i.DisplayedByUserB,
					&i.OwnedCount,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetSharedContractsBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getSharedFollowersBatchPaginate = `-- name: GetSharedFollowersBatchPaginate :batchmany
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_verified, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id, a.created_at followed_on
from users, follows a, follows b
where a.follower = $1
	and a.followee = b.follower
	and b.followee = $2
	and users.id = b.follower
	and a.deleted = false
	and b.deleted = false
	and users.deleted = false
  and (a.created_at, users.id) > ($3, $4)
  and (a.created_at, users.id) < ($5, $6)
order by case when $7::bool then (a.created_at, users.id) end desc,
        case when not $7::bool then (a.created_at, users.id) end asc
limit $8
`

type GetSharedFollowersBatchPaginateBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetSharedFollowersBatchPaginateParams struct {
	Follower      persist.DBID `json:"follower"`
	Followee      persist.DBID `json:"followee"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

type GetSharedFollowersBatchPaginateRow struct {
	ID                   persist.DBID                     `json:"id"`
	Deleted              bool                             `json:"deleted"`
	Version              sql.NullInt32                    `json:"version"`
	LastUpdated          time.Time                        `json:"last_updated"`
	CreatedAt            time.Time                        `json:"created_at"`
	Username             sql.NullString                   `json:"username"`
	UsernameIdempotent   sql.NullString                   `json:"username_idempotent"`
	Wallets              persist.WalletList               `json:"wallets"`
	Bio                  sql.NullString                   `json:"bio"`
	Traits               pgtype.JSONB                     `json:"traits"`
	Universal            bool                             `json:"universal"`
	NotificationSettings persist.UserNotificationSettings `json:"notification_settings"`
	EmailVerified        persist.EmailVerificationStatus  `json:"email_verified"`
	EmailUnsubscriptions persist.EmailUnsubscriptions     `json:"email_unsubscriptions"`
	FeaturedGallery      *persist.DBID                    `json:"featured_gallery"`
	PrimaryWalletID      persist.DBID                     `json:"primary_wallet_id"`
	UserExperiences      pgtype.JSONB                     `json:"user_experiences"`
	ProfileImageID       persist.DBID                     `json:"profile_image_id"`
	FollowedOn           time.Time                        `json:"followed_on"`
}

func (q *Queries) GetSharedFollowersBatchPaginate(ctx context.Context, arg []GetSharedFollowersBatchPaginateParams) *GetSharedFollowersBatchPaginateBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Follower,
			a.Followee,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getSharedFollowersBatchPaginate, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetSharedFollowersBatchPaginateBatchResults{br, len(arg), false}
}

func (b *GetSharedFollowersBatchPaginateBatchResults) Query(f func(int, []GetSharedFollowersBatchPaginateRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []GetSharedFollowersBatchPaginateRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i GetSharedFollowersBatchPaginateRow
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
					&i.FollowedOn,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetSharedFollowersBatchPaginateBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByIdBatch = `-- name: GetTokenByIdBatch :batchone
select id, deleted, version, created_at, last_updated, name__deprecated, description__deprecated, collectors_note, token_uri__deprecated, token_type__deprecated, token_id, quantity, ownership_history__deprecated, external_url__deprecated, block_number, owner_user_id, owned_by_wallets, chain, contract_id, is_user_marked_spam, is_provider_marked_spam__deprecated, last_synced, fallback_media__deprecated, token_media_id__deprecated, is_creator_token, is_holder_token, displayable, token_definition_id from tokens where id = $1 and displayable and deleted = false
`

type GetTokenByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenByIdBatch(ctx context.Context, id []persist.DBID) *GetTokenByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByIdBatchBatchResults{br, len(id), false}
}

func (b *GetTokenByIdBatchBatchResults) QueryRow(f func(int, Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Token
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.NameDeprecated,
			&i.DescriptionDeprecated,
			&i.CollectorsNote,
			&i.TokenUriDeprecated,
			&i.TokenTypeDeprecated,
			&i.TokenID,
			&i.Quantity,
			&i.OwnershipHistoryDeprecated,
			&i.ExternalUrlDeprecated,
			&i.BlockNumber,
			&i.OwnerUserID,
			&i.OwnedByWallets,
			&i.Chain,
			&i.ContractID,
			&i.IsUserMarkedSpam,
			&i.IsProviderMarkedSpamDeprecated,
			&i.LastSynced,
			&i.FallbackMediaDeprecated,
			&i.TokenMediaIDDeprecated,
			&i.IsCreatorToken,
			&i.IsHolderToken,
			&i.Displayable,
			&i.TokenDefinitionID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByIdIgnoreDisplayableBatch = `-- name: GetTokenByIdIgnoreDisplayableBatch :batchone
select id, deleted, version, created_at, last_updated, name__deprecated, description__deprecated, collectors_note, token_uri__deprecated, token_type__deprecated, token_id, quantity, ownership_history__deprecated, external_url__deprecated, block_number, owner_user_id, owned_by_wallets, chain, contract_id, is_user_marked_spam, is_provider_marked_spam__deprecated, last_synced, fallback_media__deprecated, token_media_id__deprecated, is_creator_token, is_holder_token, displayable, token_definition_id from tokens where id = $1 and deleted = false
`

type GetTokenByIdIgnoreDisplayableBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenByIdIgnoreDisplayableBatch(ctx context.Context, id []persist.DBID) *GetTokenByIdIgnoreDisplayableBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenByIdIgnoreDisplayableBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByIdIgnoreDisplayableBatchBatchResults{br, len(id), false}
}

func (b *GetTokenByIdIgnoreDisplayableBatchBatchResults) QueryRow(f func(int, Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Token
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.NameDeprecated,
			&i.DescriptionDeprecated,
			&i.CollectorsNote,
			&i.TokenUriDeprecated,
			&i.TokenTypeDeprecated,
			&i.TokenID,
			&i.Quantity,
			&i.OwnershipHistoryDeprecated,
			&i.ExternalUrlDeprecated,
			&i.BlockNumber,
			&i.OwnerUserID,
			&i.OwnedByWallets,
			&i.Chain,
			&i.ContractID,
			&i.IsUserMarkedSpam,
			&i.IsProviderMarkedSpamDeprecated,
			&i.LastSynced,
			&i.FallbackMediaDeprecated,
			&i.TokenMediaIDDeprecated,
			&i.IsCreatorToken,
			&i.IsHolderToken,
			&i.Displayable,
			&i.TokenDefinitionID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByIdIgnoreDisplayableBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenByUserTokenIdentifiersBatch = `-- name: GetTokenByUserTokenIdentifiersBatch :batchone
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name__deprecated, t.description__deprecated, t.collectors_note, t.token_uri__deprecated, t.token_type__deprecated, t.token_id, t.quantity, t.ownership_history__deprecated, t.external_url__deprecated, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract_id, t.is_user_marked_spam, t.is_provider_marked_spam__deprecated, t.last_synced, t.fallback_media__deprecated, t.token_media_id__deprecated, t.is_creator_token, t.is_holder_token, t.displayable, t.token_definition_id
from tokens t, token_definitions td, contracts c
where t.token_definition_id = td.token_definition_id
    and td.contract_id = c.id
    and t.owner_user_id = $1
    and td.token_id = $2
    and c.chain = $3
    and c.address = $4
    and t.displayable
    and not t.deleted
    and not c.deleted
    and not td.deleted
`

type GetTokenByUserTokenIdentifiersBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokenByUserTokenIdentifiersBatchParams struct {
	OwnerID         persist.DBID    `json:"owner_id"`
	TokenID         persist.TokenID `json:"token_id"`
	Chain           persist.Chain   `json:"chain"`
	ContractAddress persist.Address `json:"contract_address"`
}

func (q *Queries) GetTokenByUserTokenIdentifiersBatch(ctx context.Context, arg []GetTokenByUserTokenIdentifiersBatchParams) *GetTokenByUserTokenIdentifiersBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerID,
			a.TokenID,
			a.Chain,
			a.ContractAddress,
		}
		batch.Queue(getTokenByUserTokenIdentifiersBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenByUserTokenIdentifiersBatchBatchResults{br, len(arg), false}
}

func (b *GetTokenByUserTokenIdentifiersBatchBatchResults) QueryRow(f func(int, Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Token
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.NameDeprecated,
			&i.DescriptionDeprecated,
			&i.CollectorsNote,
			&i.TokenUriDeprecated,
			&i.TokenTypeDeprecated,
			&i.TokenID,
			&i.Quantity,
			&i.OwnershipHistoryDeprecated,
			&i.ExternalUrlDeprecated,
			&i.BlockNumber,
			&i.OwnerUserID,
			&i.OwnedByWallets,
			&i.Chain,
			&i.ContractID,
			&i.IsUserMarkedSpam,
			&i.IsProviderMarkedSpamDeprecated,
			&i.LastSynced,
			&i.FallbackMediaDeprecated,
			&i.TokenMediaIDDeprecated,
			&i.IsCreatorToken,
			&i.IsHolderToken,
			&i.Displayable,
			&i.TokenDefinitionID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenByUserTokenIdentifiersBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenDefinitionByIdBatch = `-- name: GetTokenDefinitionByIdBatch :batchone
select id, created_at, last_updated, deleted, name, description, token_type, token_id, external_url, chain, is_provider_marked_spam, metadata, fallback_media, contract_address, contract_id, token_media_id from token_definitions where id = $1 and not deleted
`

type GetTokenDefinitionByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenDefinitionByIdBatch(ctx context.Context, id []persist.DBID) *GetTokenDefinitionByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenDefinitionByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenDefinitionByIdBatchBatchResults{br, len(id), false}
}

func (b *GetTokenDefinitionByIdBatchBatchResults) QueryRow(f func(int, TokenDefinition, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i TokenDefinition
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Name,
			&i.Description,
			&i.TokenType,
			&i.TokenID,
			&i.ExternalUrl,
			&i.Chain,
			&i.IsProviderMarkedSpam,
			&i.Metadata,
			&i.FallbackMedia,
			&i.ContractAddress,
			&i.ContractID,
			&i.TokenMediaID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenDefinitionByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokenOwnerByIDBatch = `-- name: GetTokenOwnerByIDBatch :batchone
select u.id, u.deleted, u.version, u.last_updated, u.created_at, u.username, u.username_idempotent, u.wallets, u.bio, u.traits, u.universal, u.notification_settings, u.email_verified, u.email_unsubscriptions, u.featured_gallery, u.primary_wallet_id, u.user_experiences, u.profile_image_id from tokens t
    join users u on u.id = t.owner_user_id
    where t.id = $1 and t.displayable and t.deleted = false and u.deleted = false
`

type GetTokenOwnerByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokenOwnerByIDBatch(ctx context.Context, id []persist.DBID) *GetTokenOwnerByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokenOwnerByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokenOwnerByIDBatchBatchResults{br, len(id), false}
}

func (b *GetTokenOwnerByIDBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetTokenOwnerByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByCollectionIdBatch = `-- name: GetTokensByCollectionIdBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name__deprecated, t.description__deprecated, t.collectors_note, t.token_uri__deprecated, t.token_type__deprecated, t.token_id, t.quantity, t.ownership_history__deprecated, t.external_url__deprecated, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract_id, t.is_user_marked_spam, t.is_provider_marked_spam__deprecated, t.last_synced, t.fallback_media__deprecated, t.token_media_id__deprecated, t.is_creator_token, t.is_holder_token, t.displayable, t.token_definition_id from collections c,
    unnest(c.nfts) with ordinality as u(nft_id, nft_ord)
    join tokens t on t.id = u.nft_id
    where c.id = $1
      and c.owner_user_id = t.owner_user_id
      and t.displayable
      and c.deleted = false
      and t.deleted = false
    order by u.nft_ord
    limit $2
`

type GetTokensByCollectionIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByCollectionIdBatchParams struct {
	CollectionID persist.DBID  `json:"collection_id"`
	Limit        sql.NullInt32 `json:"limit"`
}

func (q *Queries) GetTokensByCollectionIdBatch(ctx context.Context, arg []GetTokensByCollectionIdBatchParams) *GetTokensByCollectionIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CollectionID,
			a.Limit,
		}
		batch.Queue(getTokensByCollectionIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByCollectionIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByCollectionIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.NameDeprecated,
					&i.DescriptionDeprecated,
					&i.CollectorsNote,
					&i.TokenUriDeprecated,
					&i.TokenTypeDeprecated,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistoryDeprecated,
					&i.ExternalUrlDeprecated,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpamDeprecated,
					&i.LastSynced,
					&i.FallbackMediaDeprecated,
					&i.TokenMediaIDDeprecated,
					&i.IsCreatorToken,
					&i.IsHolderToken,
					&i.Displayable,
					&i.TokenDefinitionID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByCollectionIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByUserIdAndChainBatch = `-- name: GetTokensByUserIdAndChainBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name__deprecated, t.description__deprecated, t.collectors_note, t.token_uri__deprecated, t.token_type__deprecated, t.token_id, t.quantity, t.ownership_history__deprecated, t.external_url__deprecated, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract_id, t.is_user_marked_spam, t.is_provider_marked_spam__deprecated, t.last_synced, t.fallback_media__deprecated, t.token_media_id__deprecated, t.is_creator_token, t.is_holder_token, t.displayable, t.token_definition_id from tokens t
    where t.owner_user_id = $1
      and t.chain = $2
      and t.displayable
      and t.deleted = false
    order by t.created_at desc, t.name desc, t.id desc
`

type GetTokensByUserIdAndChainBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByUserIdAndChainBatchParams struct {
	OwnerUserID persist.DBID  `json:"owner_user_id"`
	Chain       persist.Chain `json:"chain"`
}

func (q *Queries) GetTokensByUserIdAndChainBatch(ctx context.Context, arg []GetTokensByUserIdAndChainBatchParams) *GetTokensByUserIdAndChainBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerUserID,
			a.Chain,
		}
		batch.Queue(getTokensByUserIdAndChainBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByUserIdAndChainBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByUserIdAndChainBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.NameDeprecated,
					&i.DescriptionDeprecated,
					&i.CollectorsNote,
					&i.TokenUriDeprecated,
					&i.TokenTypeDeprecated,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistoryDeprecated,
					&i.ExternalUrlDeprecated,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpamDeprecated,
					&i.LastSynced,
					&i.FallbackMediaDeprecated,
					&i.TokenMediaIDDeprecated,
					&i.IsCreatorToken,
					&i.IsHolderToken,
					&i.Displayable,
					&i.TokenDefinitionID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByUserIdAndChainBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByUserIdBatch = `-- name: GetTokensByUserIdBatch :batchmany
select t.id, t.deleted, t.version, t.created_at, t.last_updated, t.name__deprecated, t.description__deprecated, t.collectors_note, t.token_uri__deprecated, t.token_type__deprecated, t.token_id, t.quantity, t.ownership_history__deprecated, t.external_url__deprecated, t.block_number, t.owner_user_id, t.owned_by_wallets, t.chain, t.contract_id, t.is_user_marked_spam, t.is_provider_marked_spam__deprecated, t.last_synced, t.fallback_media__deprecated, t.token_media_id__deprecated, t.is_creator_token, t.is_holder_token, t.displayable, t.token_definition_id from tokens t
    where t.owner_user_id = $1
      and t.deleted = false
      and t.displayable
      and (($2::bool and t.is_holder_token) or ($3::bool and t.is_creator_token))
    order by t.created_at desc, t.name desc, t.id desc
`

type GetTokensByUserIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetTokensByUserIdBatchParams struct {
	OwnerUserID    persist.DBID `json:"owner_user_id"`
	IncludeHolder  bool         `json:"include_holder"`
	IncludeCreator bool         `json:"include_creator"`
}

func (q *Queries) GetTokensByUserIdBatch(ctx context.Context, arg []GetTokensByUserIdBatchParams) *GetTokensByUserIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerUserID,
			a.IncludeHolder,
			a.IncludeCreator,
		}
		batch.Queue(getTokensByUserIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByUserIdBatchBatchResults{br, len(arg), false}
}

func (b *GetTokensByUserIdBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.NameDeprecated,
					&i.DescriptionDeprecated,
					&i.CollectorsNote,
					&i.TokenUriDeprecated,
					&i.TokenTypeDeprecated,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistoryDeprecated,
					&i.ExternalUrlDeprecated,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpamDeprecated,
					&i.LastSynced,
					&i.FallbackMediaDeprecated,
					&i.TokenMediaIDDeprecated,
					&i.IsCreatorToken,
					&i.IsHolderToken,
					&i.Displayable,
					&i.TokenDefinitionID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByUserIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getTokensByWalletIdsBatch = `-- name: GetTokensByWalletIdsBatch :batchmany
select id, deleted, version, created_at, last_updated, name__deprecated, description__deprecated, collectors_note, token_uri__deprecated, token_type__deprecated, token_id, quantity, ownership_history__deprecated, external_url__deprecated, block_number, owner_user_id, owned_by_wallets, chain, contract_id, is_user_marked_spam, is_provider_marked_spam__deprecated, last_synced, fallback_media__deprecated, token_media_id__deprecated, is_creator_token, is_holder_token, displayable, token_definition_id from tokens where owned_by_wallets && $1 and displayable and deleted = false
    order by tokens.created_at desc, tokens.name desc, tokens.id desc
`

type GetTokensByWalletIdsBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetTokensByWalletIdsBatch(ctx context.Context, ownedByWallets []persist.DBIDList) *GetTokensByWalletIdsBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range ownedByWallets {
		vals := []interface{}{
			a,
		}
		batch.Queue(getTokensByWalletIdsBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetTokensByWalletIdsBatchBatchResults{br, len(ownedByWallets), false}
}

func (b *GetTokensByWalletIdsBatchBatchResults) Query(f func(int, []Token, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Token
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Token
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.NameDeprecated,
					&i.DescriptionDeprecated,
					&i.CollectorsNote,
					&i.TokenUriDeprecated,
					&i.TokenTypeDeprecated,
					&i.TokenID,
					&i.Quantity,
					&i.OwnershipHistoryDeprecated,
					&i.ExternalUrlDeprecated,
					&i.BlockNumber,
					&i.OwnerUserID,
					&i.OwnedByWallets,
					&i.Chain,
					&i.ContractID,
					&i.IsUserMarkedSpam,
					&i.IsProviderMarkedSpamDeprecated,
					&i.LastSynced,
					&i.FallbackMediaDeprecated,
					&i.TokenMediaIDDeprecated,
					&i.IsCreatorToken,
					&i.IsHolderToken,
					&i.Displayable,
					&i.TokenDefinitionID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetTokensByWalletIdsBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByAddressBatch = `-- name: GetUserByAddressBatch :batchone
select users.id, users.deleted, users.version, users.last_updated, users.created_at, users.username, users.username_idempotent, users.wallets, users.bio, users.traits, users.universal, users.notification_settings, users.email_verified, users.email_unsubscriptions, users.featured_gallery, users.primary_wallet_id, users.user_experiences, users.profile_image_id
from users, wallets
where wallets.address = $1
	and wallets.chain = $2::int
	and array[wallets.id] <@ users.wallets
	and wallets.deleted = false
	and users.deleted = false
`

type GetUserByAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUserByAddressBatchParams struct {
	Address persist.Address `json:"address"`
	Chain   int32           `json:"chain"`
}

func (q *Queries) GetUserByAddressBatch(ctx context.Context, arg []GetUserByAddressBatchParams) *GetUserByAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getUserByAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetUserByAddressBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByIdBatch = `-- name: GetUserByIdBatch :batchone
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_verified, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id FROM users WHERE id = $1 AND deleted = false
`

type GetUserByIdBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUserByIdBatch(ctx context.Context, id []persist.DBID) *GetUserByIdBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUserByIdBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByIdBatchBatchResults{br, len(id), false}
}

func (b *GetUserByIdBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByIdBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserByUsernameBatch = `-- name: GetUserByUsernameBatch :batchone
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_verified, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id FROM users WHERE username_idempotent = lower($1) AND deleted = false
`

type GetUserByUsernameBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUserByUsernameBatch(ctx context.Context, lower []string) *GetUserByUsernameBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range lower {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUserByUsernameBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserByUsernameBatchBatchResults{br, len(lower), false}
}

func (b *GetUserByUsernameBatchBatchResults) QueryRow(f func(int, User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i User
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.Deleted,
			&i.Version,
			&i.LastUpdated,
			&i.CreatedAt,
			&i.Username,
			&i.UsernameIdempotent,
			&i.Wallets,
			&i.Bio,
			&i.Traits,
			&i.Universal,
			&i.NotificationSettings,
			&i.EmailVerified,
			&i.EmailUnsubscriptions,
			&i.FeaturedGallery,
			&i.PrimaryWalletID,
			&i.UserExperiences,
			&i.ProfileImageID,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetUserByUsernameBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUserNotificationsBatch = `-- name: GetUserNotificationsBatch :batchmany
SELECT id, deleted, owner_id, version, last_updated, created_at, action, data, event_ids, feed_event_id, comment_id, gallery_id, seen, amount, post_id, token_id, contract_id, mention_id FROM notifications WHERE owner_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type GetUserNotificationsBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetUserNotificationsBatchParams struct {
	OwnerID       persist.DBID `json:"owner_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) GetUserNotificationsBatch(ctx context.Context, arg []GetUserNotificationsBatchParams) *GetUserNotificationsBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.OwnerID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(getUserNotificationsBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUserNotificationsBatchBatchResults{br, len(arg), false}
}

func (b *GetUserNotificationsBatchBatchResults) Query(f func(int, []Notification, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Notification
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Notification
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.OwnerID,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Action,
					&i.Data,
					&i.EventIds,
					&i.FeedEventID,
					&i.CommentID,
					&i.GalleryID,
					&i.Seen,
					&i.Amount,
					&i.PostID,
					&i.TokenID,
					&i.ContractID,
					&i.MentionID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUserNotificationsBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getUsersWithTraitBatch = `-- name: GetUsersWithTraitBatch :batchmany
SELECT id, deleted, version, last_updated, created_at, username, username_idempotent, wallets, bio, traits, universal, notification_settings, email_verified, email_unsubscriptions, featured_gallery, primary_wallet_id, user_experiences, profile_image_id FROM users WHERE (traits->$1::string) IS NOT NULL AND deleted = false
`

type GetUsersWithTraitBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetUsersWithTraitBatch(ctx context.Context, dollar_1 []string) *GetUsersWithTraitBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range dollar_1 {
		vals := []interface{}{
			a,
		}
		batch.Queue(getUsersWithTraitBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetUsersWithTraitBatchBatchResults{br, len(dollar_1), false}
}

func (b *GetUsersWithTraitBatchBatchResults) Query(f func(int, []User, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []User
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i User
				if err := rows.Scan(
					&i.ID,
					&i.Deleted,
					&i.Version,
					&i.LastUpdated,
					&i.CreatedAt,
					&i.Username,
					&i.UsernameIdempotent,
					&i.Wallets,
					&i.Bio,
					&i.Traits,
					&i.Universal,
					&i.NotificationSettings,
					&i.EmailVerified,
					&i.EmailUnsubscriptions,
					&i.FeaturedGallery,
					&i.PrimaryWalletID,
					&i.UserExperiences,
					&i.ProfileImageID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetUsersWithTraitBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletByChainAddressBatch = `-- name: GetWalletByChainAddressBatch :batchone
SELECT wallets.id, wallets.created_at, wallets.last_updated, wallets.deleted, wallets.version, wallets.address, wallets.wallet_type, wallets.chain FROM wallets WHERE address = $1 AND chain = $2 AND deleted = false
`

type GetWalletByChainAddressBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type GetWalletByChainAddressBatchParams struct {
	Address persist.Address `json:"address"`
	Chain   persist.Chain   `json:"chain"`
}

func (q *Queries) GetWalletByChainAddressBatch(ctx context.Context, arg []GetWalletByChainAddressBatchParams) *GetWalletByChainAddressBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.Address,
			a.Chain,
		}
		batch.Queue(getWalletByChainAddressBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletByChainAddressBatchBatchResults{br, len(arg), false}
}

func (b *GetWalletByChainAddressBatchBatchResults) QueryRow(f func(int, Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Wallet
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Version,
			&i.Address,
			&i.WalletType,
			&i.Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetWalletByChainAddressBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletByIDBatch = `-- name: GetWalletByIDBatch :batchone
SELECT id, created_at, last_updated, deleted, version, address, wallet_type, chain FROM wallets WHERE id = $1 AND deleted = false
`

type GetWalletByIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetWalletByIDBatch(ctx context.Context, id []persist.DBID) *GetWalletByIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getWalletByIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletByIDBatchBatchResults{br, len(id), false}
}

func (b *GetWalletByIDBatchBatchResults) QueryRow(f func(int, Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var i Wallet
		if b.closed {
			if f != nil {
				f(t, i, ErrBatchAlreadyClosed)
			}
			continue
		}
		row := b.br.QueryRow()
		err := row.Scan(
			&i.ID,
			&i.CreatedAt,
			&i.LastUpdated,
			&i.Deleted,
			&i.Version,
			&i.Address,
			&i.WalletType,
			&i.Chain,
		)
		if f != nil {
			f(t, i, err)
		}
	}
}

func (b *GetWalletByIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const getWalletsByUserIDBatch = `-- name: GetWalletsByUserIDBatch :batchmany
SELECT w.id, w.created_at, w.last_updated, w.deleted, w.version, w.address, w.wallet_type, w.chain FROM users u, unnest(u.wallets) WITH ORDINALITY AS a(wallet_id, wallet_ord)INNER JOIN wallets w on w.id = a.wallet_id WHERE u.id = $1 AND u.deleted = false AND w.deleted = false ORDER BY a.wallet_ord
`

type GetWalletsByUserIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

func (q *Queries) GetWalletsByUserIDBatch(ctx context.Context, id []persist.DBID) *GetWalletsByUserIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range id {
		vals := []interface{}{
			a,
		}
		batch.Queue(getWalletsByUserIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &GetWalletsByUserIDBatchBatchResults{br, len(id), false}
}

func (b *GetWalletsByUserIDBatchBatchResults) Query(f func(int, []Wallet, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Wallet
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Wallet
				if err := rows.Scan(
					&i.ID,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
					&i.Version,
					&i.Address,
					&i.WalletType,
					&i.Chain,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *GetWalletsByUserIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByFeedEventIDBatch = `-- name: PaginateAdmiresByFeedEventIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE feed_event_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3) AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateAdmiresByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByFeedEventIDBatchParams struct {
	FeedEventID   persist.DBID `json:"feed_event_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateAdmiresByFeedEventIDBatch(ctx context.Context, arg []PaginateAdmiresByFeedEventIDBatchParams) *PaginateAdmiresByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.FeedEventID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByFeedEventIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByPostIDBatch = `-- name: PaginateAdmiresByPostIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE post_id = $1 AND deleted = false
    AND (created_at, id) < ($2, $3) AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateAdmiresByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByPostIDBatchParams struct {
	PostID        persist.DBID `json:"post_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateAdmiresByPostIDBatch(ctx context.Context, arg []PaginateAdmiresByPostIDBatchParams) *PaginateAdmiresByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByPostIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateAdmiresByTokenIDBatch = `-- name: PaginateAdmiresByTokenIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, deleted, created_at, last_updated, post_id, token_id FROM admires WHERE token_id = $1 AND (not $2::bool or actor_id = $3) AND deleted = false
    AND (created_at, id) < ($4, $5) AND (created_at, id) > ($6, $7)
    ORDER BY CASE WHEN $8::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $8::bool THEN (created_at, id) END DESC
    LIMIT $9
`

type PaginateAdmiresByTokenIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateAdmiresByTokenIDBatchParams struct {
	TokenID       persist.DBID `json:"token_id"`
	OnlyForActor  bool         `json:"only_for_actor"`
	ActorID       persist.DBID `json:"actor_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateAdmiresByTokenIDBatch(ctx context.Context, arg []PaginateAdmiresByTokenIDBatchParams) *PaginateAdmiresByTokenIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.TokenID,
			a.OnlyForActor,
			a.ActorID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateAdmiresByTokenIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateAdmiresByTokenIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateAdmiresByTokenIDBatchBatchResults) Query(f func(int, []Admire, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Admire
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Admire
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.TokenID,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateAdmiresByTokenIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateCommentsByFeedEventIDBatch = `-- name: PaginateCommentsByFeedEventIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed FROM comments WHERE feed_event_id = $1 AND reply_to is null AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateCommentsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateCommentsByFeedEventIDBatchParams struct {
	FeedEventID   persist.DBID `json:"feed_event_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateCommentsByFeedEventIDBatch(ctx context.Context, arg []PaginateCommentsByFeedEventIDBatchParams) *PaginateCommentsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.FeedEventID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateCommentsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateCommentsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateCommentsByFeedEventIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.Removed,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateCommentsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateCommentsByPostIDBatch = `-- name: PaginateCommentsByPostIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed FROM comments WHERE post_id = $1 AND reply_to is null AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateCommentsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateCommentsByPostIDBatchParams struct {
	PostID        persist.DBID `json:"post_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateCommentsByPostIDBatch(ctx context.Context, arg []PaginateCommentsByPostIDBatchParams) *PaginateCommentsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.PostID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateCommentsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateCommentsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateCommentsByPostIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.Removed,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateCommentsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateInteractionsByFeedEventIDBatch = `-- name: PaginateInteractionsByFeedEventIDBatch :batchmany
SELECT interactions.created_At, interactions.id, interactions.tag FROM (
    SELECT t.created_at, t.id, $1::int as tag FROM admires t WHERE $1 != 0 AND t.feed_event_id = $2 AND t.deleted = false
        AND ($1, t.created_at, t.id) < ($3::int, $4, $5) AND ($1, t.created_at, t.id) > ($6::int, $7, $8)
                                                                    UNION
    SELECT t.created_at, t.id, $9::int as tag FROM comments t WHERE $9 != 0 AND t.feed_event_id = $2 AND t.reply_to is null AND t.deleted = false
        AND ($9, t.created_at, t.id) < ($3::int, $4, $5) AND ($9, t.created_at, t.id) > ($6::int, $7, $8)
) as interactions

ORDER BY CASE WHEN $10::bool THEN (tag, created_at, id) END ASC,
         CASE WHEN NOT $10::bool THEN (tag, created_at, id) END DESC
LIMIT $11
`

type PaginateInteractionsByFeedEventIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateInteractionsByFeedEventIDBatchParams struct {
	AdmireTag     int32        `json:"admire_tag"`
	FeedEventID   persist.DBID `json:"feed_event_id"`
	CurBeforeTag  int32        `json:"cur_before_tag"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTag   int32        `json:"cur_after_tag"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	CommentTag    int32        `json:"comment_tag"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

type PaginateInteractionsByFeedEventIDBatchRow struct {
	CreatedAt time.Time    `json:"created_at"`
	ID        persist.DBID `json:"id"`
	Tag       int32        `json:"tag"`
}

func (q *Queries) PaginateInteractionsByFeedEventIDBatch(ctx context.Context, arg []PaginateInteractionsByFeedEventIDBatchParams) *PaginateInteractionsByFeedEventIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.FeedEventID,
			a.CurBeforeTag,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTag,
			a.CurAfterTime,
			a.CurAfterID,
			a.CommentTag,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateInteractionsByFeedEventIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateInteractionsByFeedEventIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateInteractionsByFeedEventIDBatchBatchResults) Query(f func(int, []PaginateInteractionsByFeedEventIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateInteractionsByFeedEventIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateInteractionsByFeedEventIDBatchRow
				if err := rows.Scan(&i.CreatedAt, &i.ID, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateInteractionsByFeedEventIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateInteractionsByPostIDBatch = `-- name: PaginateInteractionsByPostIDBatch :batchmany
SELECT interactions.created_At, interactions.id, interactions.tag FROM (
    SELECT t.created_at, t.id, $1::int as tag FROM admires t WHERE $1 != 0 AND t.post_id = $2 AND t.deleted = false
        AND ($1, t.created_at, t.id) < ($3::int, $4, $5) AND ($1, t.created_at, t.id) > ($6::int, $7, $8)
                                                                    UNION
    SELECT t.created_at, t.id, $9::int as tag FROM comments t WHERE $9 != 0 AND t.post_id = $2 AND t.reply_to is null AND t.deleted = false
        AND ($9, t.created_at, t.id) < ($3::int, $4, $5) AND ($9, t.created_at, t.id) > ($6::int, $7, $8)
) as interactions

ORDER BY CASE WHEN $10::bool THEN (tag, created_at, id) END ASC,
         CASE WHEN NOT $10::bool THEN (tag, created_at, id) END DESC
LIMIT $11
`

type PaginateInteractionsByPostIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateInteractionsByPostIDBatchParams struct {
	AdmireTag     int32        `json:"admire_tag"`
	PostID        persist.DBID `json:"post_id"`
	CurBeforeTag  int32        `json:"cur_before_tag"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTag   int32        `json:"cur_after_tag"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	CommentTag    int32        `json:"comment_tag"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

type PaginateInteractionsByPostIDBatchRow struct {
	CreatedAt time.Time    `json:"created_at"`
	ID        persist.DBID `json:"id"`
	Tag       int32        `json:"tag"`
}

func (q *Queries) PaginateInteractionsByPostIDBatch(ctx context.Context, arg []PaginateInteractionsByPostIDBatchParams) *PaginateInteractionsByPostIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.AdmireTag,
			a.PostID,
			a.CurBeforeTag,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTag,
			a.CurAfterTime,
			a.CurAfterID,
			a.CommentTag,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateInteractionsByPostIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateInteractionsByPostIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateInteractionsByPostIDBatchBatchResults) Query(f func(int, []PaginateInteractionsByPostIDBatchRow, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []PaginateInteractionsByPostIDBatchRow
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i PaginateInteractionsByPostIDBatchRow
				if err := rows.Scan(&i.CreatedAt, &i.ID, &i.Tag); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateInteractionsByPostIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginatePostsByContractID = `-- name: PaginatePostsByContractID :batchmany
SELECT posts.id, posts.version, posts.token_ids, posts.contract_ids, posts.actor_id, posts.caption, posts.created_at, posts.last_updated, posts.deleted
FROM posts
WHERE $1 = ANY(posts.contract_ids)
AND posts.deleted = false
AND (posts.created_at, posts.id) < ($2, $3)
AND (posts.created_at, posts.id) > ($4, $5)
ORDER BY
    CASE WHEN $6::bool THEN (posts.created_at, posts.id) END ASC,
    CASE WHEN NOT $6::bool THEN (posts.created_at, posts.id) END DESC
LIMIT $7
`

type PaginatePostsByContractIDBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginatePostsByContractIDParams struct {
	ContractID    persist.DBID `json:"contract_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginatePostsByContractID(ctx context.Context, arg []PaginatePostsByContractIDParams) *PaginatePostsByContractIDBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.ContractID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginatePostsByContractID, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginatePostsByContractIDBatchResults{br, len(arg), false}
}

func (b *PaginatePostsByContractIDBatchResults) Query(f func(int, []Post, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Post
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Post
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.TokenIds,
					&i.ContractIds,
					&i.ActorID,
					&i.Caption,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.Deleted,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginatePostsByContractIDBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}

const paginateRepliesByCommentIDBatch = `-- name: PaginateRepliesByCommentIDBatch :batchmany
SELECT id, version, feed_event_id, actor_id, reply_to, comment, deleted, created_at, last_updated, post_id, removed FROM comments WHERE reply_to = $1 AND deleted = false
    AND (created_at, id) < ($2, $3)
    AND (created_at, id) > ($4, $5)
    ORDER BY CASE WHEN $6::bool THEN (created_at, id) END ASC,
             CASE WHEN NOT $6::bool THEN (created_at, id) END DESC
    LIMIT $7
`

type PaginateRepliesByCommentIDBatchBatchResults struct {
	br     pgx.BatchResults
	tot    int
	closed bool
}

type PaginateRepliesByCommentIDBatchParams struct {
	CommentID     persist.DBID `json:"comment_id"`
	CurBeforeTime time.Time    `json:"cur_before_time"`
	CurBeforeID   persist.DBID `json:"cur_before_id"`
	CurAfterTime  time.Time    `json:"cur_after_time"`
	CurAfterID    persist.DBID `json:"cur_after_id"`
	PagingForward bool         `json:"paging_forward"`
	Limit         int32        `json:"limit"`
}

func (q *Queries) PaginateRepliesByCommentIDBatch(ctx context.Context, arg []PaginateRepliesByCommentIDBatchParams) *PaginateRepliesByCommentIDBatchBatchResults {
	batch := &pgx.Batch{}
	for _, a := range arg {
		vals := []interface{}{
			a.CommentID,
			a.CurBeforeTime,
			a.CurBeforeID,
			a.CurAfterTime,
			a.CurAfterID,
			a.PagingForward,
			a.Limit,
		}
		batch.Queue(paginateRepliesByCommentIDBatch, vals...)
	}
	br := q.db.SendBatch(ctx, batch)
	return &PaginateRepliesByCommentIDBatchBatchResults{br, len(arg), false}
}

func (b *PaginateRepliesByCommentIDBatchBatchResults) Query(f func(int, []Comment, error)) {
	defer b.br.Close()
	for t := 0; t < b.tot; t++ {
		var items []Comment
		if b.closed {
			if f != nil {
				f(t, items, ErrBatchAlreadyClosed)
			}
			continue
		}
		err := func() error {
			rows, err := b.br.Query()
			defer rows.Close()
			if err != nil {
				return err
			}
			for rows.Next() {
				var i Comment
				if err := rows.Scan(
					&i.ID,
					&i.Version,
					&i.FeedEventID,
					&i.ActorID,
					&i.ReplyTo,
					&i.Comment,
					&i.Deleted,
					&i.CreatedAt,
					&i.LastUpdated,
					&i.PostID,
					&i.Removed,
				); err != nil {
					return err
				}
				items = append(items, i)
			}
			return rows.Err()
		}()
		if f != nil {
			f(t, items, err)
		}
	}
}

func (b *PaginateRepliesByCommentIDBatchBatchResults) Close() error {
	b.closed = true
	return b.br.Close()
}
